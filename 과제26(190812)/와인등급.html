<!DOCTYPE html>
<html>
<head><meta charset="utf-8" />

<title>와인등급</title>

<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>



<style type="text/css">
    /*!
*
* Twitter Bootstrap
*
*/
/*!
 * Bootstrap v3.3.7 (http://getbootstrap.com)
 * Copyright 2011-2016 Twitter, Inc.
 * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
 */
/*! normalize.css v3.0.3 | MIT License | github.com/necolas/normalize.css */
html {
  font-family: sans-serif;
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
}
body {
  margin: 0;
}
article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
menu,
nav,
section,
summary {
  display: block;
}
audio,
canvas,
progress,
video {
  display: inline-block;
  vertical-align: baseline;
}
audio:not([controls]) {
  display: none;
  height: 0;
}
[hidden],
template {
  display: none;
}
a {
  background-color: transparent;
}
a:active,
a:hover {
  outline: 0;
}
abbr[title] {
  border-bottom: 1px dotted;
}
b,
strong {
  font-weight: bold;
}
dfn {
  font-style: italic;
}
h1 {
  font-size: 2em;
  margin: 0.67em 0;
}
mark {
  background: #ff0;
  color: #000;
}
small {
  font-size: 80%;
}
sub,
sup {
  font-size: 75%;
  line-height: 0;
  position: relative;
  vertical-align: baseline;
}
sup {
  top: -0.5em;
}
sub {
  bottom: -0.25em;
}
img {
  border: 0;
}
svg:not(:root) {
  overflow: hidden;
}
figure {
  margin: 1em 40px;
}
hr {
  box-sizing: content-box;
  height: 0;
}
pre {
  overflow: auto;
}
code,
kbd,
pre,
samp {
  font-family: monospace, monospace;
  font-size: 1em;
}
button,
input,
optgroup,
select,
textarea {
  color: inherit;
  font: inherit;
  margin: 0;
}
button {
  overflow: visible;
}
button,
select {
  text-transform: none;
}
button,
html input[type="button"],
input[type="reset"],
input[type="submit"] {
  -webkit-appearance: button;
  cursor: pointer;
}
button[disabled],
html input[disabled] {
  cursor: default;
}
button::-moz-focus-inner,
input::-moz-focus-inner {
  border: 0;
  padding: 0;
}
input {
  line-height: normal;
}
input[type="checkbox"],
input[type="radio"] {
  box-sizing: border-box;
  padding: 0;
}
input[type="number"]::-webkit-inner-spin-button,
input[type="number"]::-webkit-outer-spin-button {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: textfield;
  box-sizing: content-box;
}
input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
  -webkit-appearance: none;
}
fieldset {
  border: 1px solid #c0c0c0;
  margin: 0 2px;
  padding: 0.35em 0.625em 0.75em;
}
legend {
  border: 0;
  padding: 0;
}
textarea {
  overflow: auto;
}
optgroup {
  font-weight: bold;
}
table {
  border-collapse: collapse;
  border-spacing: 0;
}
td,
th {
  padding: 0;
}
/*! Source: https://github.com/h5bp/html5-boilerplate/blob/master/src/css/main.css */
@media print {
  *,
  *:before,
  *:after {
    background: transparent !important;
    box-shadow: none !important;
    text-shadow: none !important;
  }
  a,
  a:visited {
    text-decoration: underline;
  }
  a[href]:after {
    content: " (" attr(href) ")";
  }
  abbr[title]:after {
    content: " (" attr(title) ")";
  }
  a[href^="#"]:after,
  a[href^="javascript:"]:after {
    content: "";
  }
  pre,
  blockquote {
    border: 1px solid #999;
    page-break-inside: avoid;
  }
  thead {
    display: table-header-group;
  }
  tr,
  img {
    page-break-inside: avoid;
  }
  img {
    max-width: 100% !important;
  }
  p,
  h2,
  h3 {
    orphans: 3;
    widows: 3;
  }
  h2,
  h3 {
    page-break-after: avoid;
  }
  .navbar {
    display: none;
  }
  .btn > .caret,
  .dropup > .btn > .caret {
    border-top-color: #000 !important;
  }
  .label {
    border: 1px solid #000;
  }
  .table {
    border-collapse: collapse !important;
  }
  .table td,
  .table th {
    background-color: #fff !important;
  }
  .table-bordered th,
  .table-bordered td {
    border: 1px solid #ddd !important;
  }
}
@font-face {
  font-family: 'Glyphicons Halflings';
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot');
  src: url('../components/bootstrap/fonts/glyphicons-halflings-regular.eot?#iefix') format('embedded-opentype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff2') format('woff2'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.woff') format('woff'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.ttf') format('truetype'), url('../components/bootstrap/fonts/glyphicons-halflings-regular.svg#glyphicons_halflingsregular') format('svg');
}
.glyphicon {
  position: relative;
  top: 1px;
  display: inline-block;
  font-family: 'Glyphicons Halflings';
  font-style: normal;
  font-weight: normal;
  line-height: 1;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
.glyphicon-asterisk:before {
  content: "\002a";
}
.glyphicon-plus:before {
  content: "\002b";
}
.glyphicon-euro:before,
.glyphicon-eur:before {
  content: "\20ac";
}
.glyphicon-minus:before {
  content: "\2212";
}
.glyphicon-cloud:before {
  content: "\2601";
}
.glyphicon-envelope:before {
  content: "\2709";
}
.glyphicon-pencil:before {
  content: "\270f";
}
.glyphicon-glass:before {
  content: "\e001";
}
.glyphicon-music:before {
  content: "\e002";
}
.glyphicon-search:before {
  content: "\e003";
}
.glyphicon-heart:before {
  content: "\e005";
}
.glyphicon-star:before {
  content: "\e006";
}
.glyphicon-star-empty:before {
  content: "\e007";
}
.glyphicon-user:before {
  content: "\e008";
}
.glyphicon-film:before {
  content: "\e009";
}
.glyphicon-th-large:before {
  content: "\e010";
}
.glyphicon-th:before {
  content: "\e011";
}
.glyphicon-th-list:before {
  content: "\e012";
}
.glyphicon-ok:before {
  content: "\e013";
}
.glyphicon-remove:before {
  content: "\e014";
}
.glyphicon-zoom-in:before {
  content: "\e015";
}
.glyphicon-zoom-out:before {
  content: "\e016";
}
.glyphicon-off:before {
  content: "\e017";
}
.glyphicon-signal:before {
  content: "\e018";
}
.glyphicon-cog:before {
  content: "\e019";
}
.glyphicon-trash:before {
  content: "\e020";
}
.glyphicon-home:before {
  content: "\e021";
}
.glyphicon-file:before {
  content: "\e022";
}
.glyphicon-time:before {
  content: "\e023";
}
.glyphicon-road:before {
  content: "\e024";
}
.glyphicon-download-alt:before {
  content: "\e025";
}
.glyphicon-download:before {
  content: "\e026";
}
.glyphicon-upload:before {
  content: "\e027";
}
.glyphicon-inbox:before {
  content: "\e028";
}
.glyphicon-play-circle:before {
  content: "\e029";
}
.glyphicon-repeat:before {
  content: "\e030";
}
.glyphicon-refresh:before {
  content: "\e031";
}
.glyphicon-list-alt:before {
  content: "\e032";
}
.glyphicon-lock:before {
  content: "\e033";
}
.glyphicon-flag:before {
  content: "\e034";
}
.glyphicon-headphones:before {
  content: "\e035";
}
.glyphicon-volume-off:before {
  content: "\e036";
}
.glyphicon-volume-down:before {
  content: "\e037";
}
.glyphicon-volume-up:before {
  content: "\e038";
}
.glyphicon-qrcode:before {
  content: "\e039";
}
.glyphicon-barcode:before {
  content: "\e040";
}
.glyphicon-tag:before {
  content: "\e041";
}
.glyphicon-tags:before {
  content: "\e042";
}
.glyphicon-book:before {
  content: "\e043";
}
.glyphicon-bookmark:before {
  content: "\e044";
}
.glyphicon-print:before {
  content: "\e045";
}
.glyphicon-camera:before {
  content: "\e046";
}
.glyphicon-font:before {
  content: "\e047";
}
.glyphicon-bold:before {
  content: "\e048";
}
.glyphicon-italic:before {
  content: "\e049";
}
.glyphicon-text-height:before {
  content: "\e050";
}
.glyphicon-text-width:before {
  content: "\e051";
}
.glyphicon-align-left:before {
  content: "\e052";
}
.glyphicon-align-center:before {
  content: "\e053";
}
.glyphicon-align-right:before {
  content: "\e054";
}
.glyphicon-align-justify:before {
  content: "\e055";
}
.glyphicon-list:before {
  content: "\e056";
}
.glyphicon-indent-left:before {
  content: "\e057";
}
.glyphicon-indent-right:before {
  content: "\e058";
}
.glyphicon-facetime-video:before {
  content: "\e059";
}
.glyphicon-picture:before {
  content: "\e060";
}
.glyphicon-map-marker:before {
  content: "\e062";
}
.glyphicon-adjust:before {
  content: "\e063";
}
.glyphicon-tint:before {
  content: "\e064";
}
.glyphicon-edit:before {
  content: "\e065";
}
.glyphicon-share:before {
  content: "\e066";
}
.glyphicon-check:before {
  content: "\e067";
}
.glyphicon-move:before {
  content: "\e068";
}
.glyphicon-step-backward:before {
  content: "\e069";
}
.glyphicon-fast-backward:before {
  content: "\e070";
}
.glyphicon-backward:before {
  content: "\e071";
}
.glyphicon-play:before {
  content: "\e072";
}
.glyphicon-pause:before {
  content: "\e073";
}
.glyphicon-stop:before {
  content: "\e074";
}
.glyphicon-forward:before {
  content: "\e075";
}
.glyphicon-fast-forward:before {
  content: "\e076";
}
.glyphicon-step-forward:before {
  content: "\e077";
}
.glyphicon-eject:before {
  content: "\e078";
}
.glyphicon-chevron-left:before {
  content: "\e079";
}
.glyphicon-chevron-right:before {
  content: "\e080";
}
.glyphicon-plus-sign:before {
  content: "\e081";
}
.glyphicon-minus-sign:before {
  content: "\e082";
}
.glyphicon-remove-sign:before {
  content: "\e083";
}
.glyphicon-ok-sign:before {
  content: "\e084";
}
.glyphicon-question-sign:before {
  content: "\e085";
}
.glyphicon-info-sign:before {
  content: "\e086";
}
.glyphicon-screenshot:before {
  content: "\e087";
}
.glyphicon-remove-circle:before {
  content: "\e088";
}
.glyphicon-ok-circle:before {
  content: "\e089";
}
.glyphicon-ban-circle:before {
  content: "\e090";
}
.glyphicon-arrow-left:before {
  content: "\e091";
}
.glyphicon-arrow-right:before {
  content: "\e092";
}
.glyphicon-arrow-up:before {
  content: "\e093";
}
.glyphicon-arrow-down:before {
  content: "\e094";
}
.glyphicon-share-alt:before {
  content: "\e095";
}
.glyphicon-resize-full:before {
  content: "\e096";
}
.glyphicon-resize-small:before {
  content: "\e097";
}
.glyphicon-exclamation-sign:before {
  content: "\e101";
}
.glyphicon-gift:before {
  content: "\e102";
}
.glyphicon-leaf:before {
  content: "\e103";
}
.glyphicon-fire:before {
  content: "\e104";
}
.glyphicon-eye-open:before {
  content: "\e105";
}
.glyphicon-eye-close:before {
  content: "\e106";
}
.glyphicon-warning-sign:before {
  content: "\e107";
}
.glyphicon-plane:before {
  content: "\e108";
}
.glyphicon-calendar:before {
  content: "\e109";
}
.glyphicon-random:before {
  content: "\e110";
}
.glyphicon-comment:before {
  content: "\e111";
}
.glyphicon-magnet:before {
  content: "\e112";
}
.glyphicon-chevron-up:before {
  content: "\e113";
}
.glyphicon-chevron-down:before {
  content: "\e114";
}
.glyphicon-retweet:before {
  content: "\e115";
}
.glyphicon-shopping-cart:before {
  content: "\e116";
}
.glyphicon-folder-close:before {
  content: "\e117";
}
.glyphicon-folder-open:before {
  content: "\e118";
}
.glyphicon-resize-vertical:before {
  content: "\e119";
}
.glyphicon-resize-horizontal:before {
  content: "\e120";
}
.glyphicon-hdd:before {
  content: "\e121";
}
.glyphicon-bullhorn:before {
  content: "\e122";
}
.glyphicon-bell:before {
  content: "\e123";
}
.glyphicon-certificate:before {
  content: "\e124";
}
.glyphicon-thumbs-up:before {
  content: "\e125";
}
.glyphicon-thumbs-down:before {
  content: "\e126";
}
.glyphicon-hand-right:before {
  content: "\e127";
}
.glyphicon-hand-left:before {
  content: "\e128";
}
.glyphicon-hand-up:before {
  content: "\e129";
}
.glyphicon-hand-down:before {
  content: "\e130";
}
.glyphicon-circle-arrow-right:before {
  content: "\e131";
}
.glyphicon-circle-arrow-left:before {
  content: "\e132";
}
.glyphicon-circle-arrow-up:before {
  content: "\e133";
}
.glyphicon-circle-arrow-down:before {
  content: "\e134";
}
.glyphicon-globe:before {
  content: "\e135";
}
.glyphicon-wrench:before {
  content: "\e136";
}
.glyphicon-tasks:before {
  content: "\e137";
}
.glyphicon-filter:before {
  content: "\e138";
}
.glyphicon-briefcase:before {
  content: "\e139";
}
.glyphicon-fullscreen:before {
  content: "\e140";
}
.glyphicon-dashboard:before {
  content: "\e141";
}
.glyphicon-paperclip:before {
  content: "\e142";
}
.glyphicon-heart-empty:before {
  content: "\e143";
}
.glyphicon-link:before {
  content: "\e144";
}
.glyphicon-phone:before {
  content: "\e145";
}
.glyphicon-pushpin:before {
  content: "\e146";
}
.glyphicon-usd:before {
  content: "\e148";
}
.glyphicon-gbp:before {
  content: "\e149";
}
.glyphicon-sort:before {
  content: "\e150";
}
.glyphicon-sort-by-alphabet:before {
  content: "\e151";
}
.glyphicon-sort-by-alphabet-alt:before {
  content: "\e152";
}
.glyphicon-sort-by-order:before {
  content: "\e153";
}
.glyphicon-sort-by-order-alt:before {
  content: "\e154";
}
.glyphicon-sort-by-attributes:before {
  content: "\e155";
}
.glyphicon-sort-by-attributes-alt:before {
  content: "\e156";
}
.glyphicon-unchecked:before {
  content: "\e157";
}
.glyphicon-expand:before {
  content: "\e158";
}
.glyphicon-collapse-down:before {
  content: "\e159";
}
.glyphicon-collapse-up:before {
  content: "\e160";
}
.glyphicon-log-in:before {
  content: "\e161";
}
.glyphicon-flash:before {
  content: "\e162";
}
.glyphicon-log-out:before {
  content: "\e163";
}
.glyphicon-new-window:before {
  content: "\e164";
}
.glyphicon-record:before {
  content: "\e165";
}
.glyphicon-save:before {
  content: "\e166";
}
.glyphicon-open:before {
  content: "\e167";
}
.glyphicon-saved:before {
  content: "\e168";
}
.glyphicon-import:before {
  content: "\e169";
}
.glyphicon-export:before {
  content: "\e170";
}
.glyphicon-send:before {
  content: "\e171";
}
.glyphicon-floppy-disk:before {
  content: "\e172";
}
.glyphicon-floppy-saved:before {
  content: "\e173";
}
.glyphicon-floppy-remove:before {
  content: "\e174";
}
.glyphicon-floppy-save:before {
  content: "\e175";
}
.glyphicon-floppy-open:before {
  content: "\e176";
}
.glyphicon-credit-card:before {
  content: "\e177";
}
.glyphicon-transfer:before {
  content: "\e178";
}
.glyphicon-cutlery:before {
  content: "\e179";
}
.glyphicon-header:before {
  content: "\e180";
}
.glyphicon-compressed:before {
  content: "\e181";
}
.glyphicon-earphone:before {
  content: "\e182";
}
.glyphicon-phone-alt:before {
  content: "\e183";
}
.glyphicon-tower:before {
  content: "\e184";
}
.glyphicon-stats:before {
  content: "\e185";
}
.glyphicon-sd-video:before {
  content: "\e186";
}
.glyphicon-hd-video:before {
  content: "\e187";
}
.glyphicon-subtitles:before {
  content: "\e188";
}
.glyphicon-sound-stereo:before {
  content: "\e189";
}
.glyphicon-sound-dolby:before {
  content: "\e190";
}
.glyphicon-sound-5-1:before {
  content: "\e191";
}
.glyphicon-sound-6-1:before {
  content: "\e192";
}
.glyphicon-sound-7-1:before {
  content: "\e193";
}
.glyphicon-copyright-mark:before {
  content: "\e194";
}
.glyphicon-registration-mark:before {
  content: "\e195";
}
.glyphicon-cloud-download:before {
  content: "\e197";
}
.glyphicon-cloud-upload:before {
  content: "\e198";
}
.glyphicon-tree-conifer:before {
  content: "\e199";
}
.glyphicon-tree-deciduous:before {
  content: "\e200";
}
.glyphicon-cd:before {
  content: "\e201";
}
.glyphicon-save-file:before {
  content: "\e202";
}
.glyphicon-open-file:before {
  content: "\e203";
}
.glyphicon-level-up:before {
  content: "\e204";
}
.glyphicon-copy:before {
  content: "\e205";
}
.glyphicon-paste:before {
  content: "\e206";
}
.glyphicon-alert:before {
  content: "\e209";
}
.glyphicon-equalizer:before {
  content: "\e210";
}
.glyphicon-king:before {
  content: "\e211";
}
.glyphicon-queen:before {
  content: "\e212";
}
.glyphicon-pawn:before {
  content: "\e213";
}
.glyphicon-bishop:before {
  content: "\e214";
}
.glyphicon-knight:before {
  content: "\e215";
}
.glyphicon-baby-formula:before {
  content: "\e216";
}
.glyphicon-tent:before {
  content: "\26fa";
}
.glyphicon-blackboard:before {
  content: "\e218";
}
.glyphicon-bed:before {
  content: "\e219";
}
.glyphicon-apple:before {
  content: "\f8ff";
}
.glyphicon-erase:before {
  content: "\e221";
}
.glyphicon-hourglass:before {
  content: "\231b";
}
.glyphicon-lamp:before {
  content: "\e223";
}
.glyphicon-duplicate:before {
  content: "\e224";
}
.glyphicon-piggy-bank:before {
  content: "\e225";
}
.glyphicon-scissors:before {
  content: "\e226";
}
.glyphicon-bitcoin:before {
  content: "\e227";
}
.glyphicon-btc:before {
  content: "\e227";
}
.glyphicon-xbt:before {
  content: "\e227";
}
.glyphicon-yen:before {
  content: "\00a5";
}
.glyphicon-jpy:before {
  content: "\00a5";
}
.glyphicon-ruble:before {
  content: "\20bd";
}
.glyphicon-rub:before {
  content: "\20bd";
}
.glyphicon-scale:before {
  content: "\e230";
}
.glyphicon-ice-lolly:before {
  content: "\e231";
}
.glyphicon-ice-lolly-tasted:before {
  content: "\e232";
}
.glyphicon-education:before {
  content: "\e233";
}
.glyphicon-option-horizontal:before {
  content: "\e234";
}
.glyphicon-option-vertical:before {
  content: "\e235";
}
.glyphicon-menu-hamburger:before {
  content: "\e236";
}
.glyphicon-modal-window:before {
  content: "\e237";
}
.glyphicon-oil:before {
  content: "\e238";
}
.glyphicon-grain:before {
  content: "\e239";
}
.glyphicon-sunglasses:before {
  content: "\e240";
}
.glyphicon-text-size:before {
  content: "\e241";
}
.glyphicon-text-color:before {
  content: "\e242";
}
.glyphicon-text-background:before {
  content: "\e243";
}
.glyphicon-object-align-top:before {
  content: "\e244";
}
.glyphicon-object-align-bottom:before {
  content: "\e245";
}
.glyphicon-object-align-horizontal:before {
  content: "\e246";
}
.glyphicon-object-align-left:before {
  content: "\e247";
}
.glyphicon-object-align-vertical:before {
  content: "\e248";
}
.glyphicon-object-align-right:before {
  content: "\e249";
}
.glyphicon-triangle-right:before {
  content: "\e250";
}
.glyphicon-triangle-left:before {
  content: "\e251";
}
.glyphicon-triangle-bottom:before {
  content: "\e252";
}
.glyphicon-triangle-top:before {
  content: "\e253";
}
.glyphicon-console:before {
  content: "\e254";
}
.glyphicon-superscript:before {
  content: "\e255";
}
.glyphicon-subscript:before {
  content: "\e256";
}
.glyphicon-menu-left:before {
  content: "\e257";
}
.glyphicon-menu-right:before {
  content: "\e258";
}
.glyphicon-menu-down:before {
  content: "\e259";
}
.glyphicon-menu-up:before {
  content: "\e260";
}
* {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
*:before,
*:after {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
html {
  font-size: 10px;
  -webkit-tap-highlight-color: rgba(0, 0, 0, 0);
}
body {
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 13px;
  line-height: 1.42857143;
  color: #000;
  background-color: #fff;
}
input,
button,
select,
textarea {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}
a {
  color: #337ab7;
  text-decoration: none;
}
a:hover,
a:focus {
  color: #23527c;
  text-decoration: underline;
}
a:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
figure {
  margin: 0;
}
img {
  vertical-align: middle;
}
.img-responsive,
.thumbnail > img,
.thumbnail a > img,
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  display: block;
  max-width: 100%;
  height: auto;
}
.img-rounded {
  border-radius: 3px;
}
.img-thumbnail {
  padding: 4px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: all 0.2s ease-in-out;
  -o-transition: all 0.2s ease-in-out;
  transition: all 0.2s ease-in-out;
  display: inline-block;
  max-width: 100%;
  height: auto;
}
.img-circle {
  border-radius: 50%;
}
hr {
  margin-top: 18px;
  margin-bottom: 18px;
  border: 0;
  border-top: 1px solid #eeeeee;
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  margin: -1px;
  padding: 0;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
[role="button"] {
  cursor: pointer;
}
h1,
h2,
h3,
h4,
h5,
h6,
.h1,
.h2,
.h3,
.h4,
.h5,
.h6 {
  font-family: inherit;
  font-weight: 500;
  line-height: 1.1;
  color: inherit;
}
h1 small,
h2 small,
h3 small,
h4 small,
h5 small,
h6 small,
.h1 small,
.h2 small,
.h3 small,
.h4 small,
.h5 small,
.h6 small,
h1 .small,
h2 .small,
h3 .small,
h4 .small,
h5 .small,
h6 .small,
.h1 .small,
.h2 .small,
.h3 .small,
.h4 .small,
.h5 .small,
.h6 .small {
  font-weight: normal;
  line-height: 1;
  color: #777777;
}
h1,
.h1,
h2,
.h2,
h3,
.h3 {
  margin-top: 18px;
  margin-bottom: 9px;
}
h1 small,
.h1 small,
h2 small,
.h2 small,
h3 small,
.h3 small,
h1 .small,
.h1 .small,
h2 .small,
.h2 .small,
h3 .small,
.h3 .small {
  font-size: 65%;
}
h4,
.h4,
h5,
.h5,
h6,
.h6 {
  margin-top: 9px;
  margin-bottom: 9px;
}
h4 small,
.h4 small,
h5 small,
.h5 small,
h6 small,
.h6 small,
h4 .small,
.h4 .small,
h5 .small,
.h5 .small,
h6 .small,
.h6 .small {
  font-size: 75%;
}
h1,
.h1 {
  font-size: 33px;
}
h2,
.h2 {
  font-size: 27px;
}
h3,
.h3 {
  font-size: 23px;
}
h4,
.h4 {
  font-size: 17px;
}
h5,
.h5 {
  font-size: 13px;
}
h6,
.h6 {
  font-size: 12px;
}
p {
  margin: 0 0 9px;
}
.lead {
  margin-bottom: 18px;
  font-size: 14px;
  font-weight: 300;
  line-height: 1.4;
}
@media (min-width: 768px) {
  .lead {
    font-size: 19.5px;
  }
}
small,
.small {
  font-size: 92%;
}
mark,
.mark {
  background-color: #fcf8e3;
  padding: .2em;
}
.text-left {
  text-align: left;
}
.text-right {
  text-align: right;
}
.text-center {
  text-align: center;
}
.text-justify {
  text-align: justify;
}
.text-nowrap {
  white-space: nowrap;
}
.text-lowercase {
  text-transform: lowercase;
}
.text-uppercase {
  text-transform: uppercase;
}
.text-capitalize {
  text-transform: capitalize;
}
.text-muted {
  color: #777777;
}
.text-primary {
  color: #337ab7;
}
a.text-primary:hover,
a.text-primary:focus {
  color: #286090;
}
.text-success {
  color: #3c763d;
}
a.text-success:hover,
a.text-success:focus {
  color: #2b542c;
}
.text-info {
  color: #31708f;
}
a.text-info:hover,
a.text-info:focus {
  color: #245269;
}
.text-warning {
  color: #8a6d3b;
}
a.text-warning:hover,
a.text-warning:focus {
  color: #66512c;
}
.text-danger {
  color: #a94442;
}
a.text-danger:hover,
a.text-danger:focus {
  color: #843534;
}
.bg-primary {
  color: #fff;
  background-color: #337ab7;
}
a.bg-primary:hover,
a.bg-primary:focus {
  background-color: #286090;
}
.bg-success {
  background-color: #dff0d8;
}
a.bg-success:hover,
a.bg-success:focus {
  background-color: #c1e2b3;
}
.bg-info {
  background-color: #d9edf7;
}
a.bg-info:hover,
a.bg-info:focus {
  background-color: #afd9ee;
}
.bg-warning {
  background-color: #fcf8e3;
}
a.bg-warning:hover,
a.bg-warning:focus {
  background-color: #f7ecb5;
}
.bg-danger {
  background-color: #f2dede;
}
a.bg-danger:hover,
a.bg-danger:focus {
  background-color: #e4b9b9;
}
.page-header {
  padding-bottom: 8px;
  margin: 36px 0 18px;
  border-bottom: 1px solid #eeeeee;
}
ul,
ol {
  margin-top: 0;
  margin-bottom: 9px;
}
ul ul,
ol ul,
ul ol,
ol ol {
  margin-bottom: 0;
}
.list-unstyled {
  padding-left: 0;
  list-style: none;
}
.list-inline {
  padding-left: 0;
  list-style: none;
  margin-left: -5px;
}
.list-inline > li {
  display: inline-block;
  padding-left: 5px;
  padding-right: 5px;
}
dl {
  margin-top: 0;
  margin-bottom: 18px;
}
dt,
dd {
  line-height: 1.42857143;
}
dt {
  font-weight: bold;
}
dd {
  margin-left: 0;
}
@media (min-width: 541px) {
  .dl-horizontal dt {
    float: left;
    width: 160px;
    clear: left;
    text-align: right;
    overflow: hidden;
    text-overflow: ellipsis;
    white-space: nowrap;
  }
  .dl-horizontal dd {
    margin-left: 180px;
  }
}
abbr[title],
abbr[data-original-title] {
  cursor: help;
  border-bottom: 1px dotted #777777;
}
.initialism {
  font-size: 90%;
  text-transform: uppercase;
}
blockquote {
  padding: 9px 18px;
  margin: 0 0 18px;
  font-size: inherit;
  border-left: 5px solid #eeeeee;
}
blockquote p:last-child,
blockquote ul:last-child,
blockquote ol:last-child {
  margin-bottom: 0;
}
blockquote footer,
blockquote small,
blockquote .small {
  display: block;
  font-size: 80%;
  line-height: 1.42857143;
  color: #777777;
}
blockquote footer:before,
blockquote small:before,
blockquote .small:before {
  content: '\2014 \00A0';
}
.blockquote-reverse,
blockquote.pull-right {
  padding-right: 15px;
  padding-left: 0;
  border-right: 5px solid #eeeeee;
  border-left: 0;
  text-align: right;
}
.blockquote-reverse footer:before,
blockquote.pull-right footer:before,
.blockquote-reverse small:before,
blockquote.pull-right small:before,
.blockquote-reverse .small:before,
blockquote.pull-right .small:before {
  content: '';
}
.blockquote-reverse footer:after,
blockquote.pull-right footer:after,
.blockquote-reverse small:after,
blockquote.pull-right small:after,
.blockquote-reverse .small:after,
blockquote.pull-right .small:after {
  content: '\00A0 \2014';
}
address {
  margin-bottom: 18px;
  font-style: normal;
  line-height: 1.42857143;
}
code,
kbd,
pre,
samp {
  font-family: monospace;
}
code {
  padding: 2px 4px;
  font-size: 90%;
  color: #c7254e;
  background-color: #f9f2f4;
  border-radius: 2px;
}
kbd {
  padding: 2px 4px;
  font-size: 90%;
  color: #888;
  background-color: transparent;
  border-radius: 1px;
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.25);
}
kbd kbd {
  padding: 0;
  font-size: 100%;
  font-weight: bold;
  box-shadow: none;
}
pre {
  display: block;
  padding: 8.5px;
  margin: 0 0 9px;
  font-size: 12px;
  line-height: 1.42857143;
  word-break: break-all;
  word-wrap: break-word;
  color: #333333;
  background-color: #f5f5f5;
  border: 1px solid #ccc;
  border-radius: 2px;
}
pre code {
  padding: 0;
  font-size: inherit;
  color: inherit;
  white-space: pre-wrap;
  background-color: transparent;
  border-radius: 0;
}
.pre-scrollable {
  max-height: 340px;
  overflow-y: scroll;
}
.container {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
@media (min-width: 768px) {
  .container {
    width: 768px;
  }
}
@media (min-width: 992px) {
  .container {
    width: 940px;
  }
}
@media (min-width: 1200px) {
  .container {
    width: 1140px;
  }
}
.container-fluid {
  margin-right: auto;
  margin-left: auto;
  padding-left: 0px;
  padding-right: 0px;
}
.row {
  margin-left: 0px;
  margin-right: 0px;
}
.col-xs-1, .col-sm-1, .col-md-1, .col-lg-1, .col-xs-2, .col-sm-2, .col-md-2, .col-lg-2, .col-xs-3, .col-sm-3, .col-md-3, .col-lg-3, .col-xs-4, .col-sm-4, .col-md-4, .col-lg-4, .col-xs-5, .col-sm-5, .col-md-5, .col-lg-5, .col-xs-6, .col-sm-6, .col-md-6, .col-lg-6, .col-xs-7, .col-sm-7, .col-md-7, .col-lg-7, .col-xs-8, .col-sm-8, .col-md-8, .col-lg-8, .col-xs-9, .col-sm-9, .col-md-9, .col-lg-9, .col-xs-10, .col-sm-10, .col-md-10, .col-lg-10, .col-xs-11, .col-sm-11, .col-md-11, .col-lg-11, .col-xs-12, .col-sm-12, .col-md-12, .col-lg-12 {
  position: relative;
  min-height: 1px;
  padding-left: 0px;
  padding-right: 0px;
}
.col-xs-1, .col-xs-2, .col-xs-3, .col-xs-4, .col-xs-5, .col-xs-6, .col-xs-7, .col-xs-8, .col-xs-9, .col-xs-10, .col-xs-11, .col-xs-12 {
  float: left;
}
.col-xs-12 {
  width: 100%;
}
.col-xs-11 {
  width: 91.66666667%;
}
.col-xs-10 {
  width: 83.33333333%;
}
.col-xs-9 {
  width: 75%;
}
.col-xs-8 {
  width: 66.66666667%;
}
.col-xs-7 {
  width: 58.33333333%;
}
.col-xs-6 {
  width: 50%;
}
.col-xs-5 {
  width: 41.66666667%;
}
.col-xs-4 {
  width: 33.33333333%;
}
.col-xs-3 {
  width: 25%;
}
.col-xs-2 {
  width: 16.66666667%;
}
.col-xs-1 {
  width: 8.33333333%;
}
.col-xs-pull-12 {
  right: 100%;
}
.col-xs-pull-11 {
  right: 91.66666667%;
}
.col-xs-pull-10 {
  right: 83.33333333%;
}
.col-xs-pull-9 {
  right: 75%;
}
.col-xs-pull-8 {
  right: 66.66666667%;
}
.col-xs-pull-7 {
  right: 58.33333333%;
}
.col-xs-pull-6 {
  right: 50%;
}
.col-xs-pull-5 {
  right: 41.66666667%;
}
.col-xs-pull-4 {
  right: 33.33333333%;
}
.col-xs-pull-3 {
  right: 25%;
}
.col-xs-pull-2 {
  right: 16.66666667%;
}
.col-xs-pull-1 {
  right: 8.33333333%;
}
.col-xs-pull-0 {
  right: auto;
}
.col-xs-push-12 {
  left: 100%;
}
.col-xs-push-11 {
  left: 91.66666667%;
}
.col-xs-push-10 {
  left: 83.33333333%;
}
.col-xs-push-9 {
  left: 75%;
}
.col-xs-push-8 {
  left: 66.66666667%;
}
.col-xs-push-7 {
  left: 58.33333333%;
}
.col-xs-push-6 {
  left: 50%;
}
.col-xs-push-5 {
  left: 41.66666667%;
}
.col-xs-push-4 {
  left: 33.33333333%;
}
.col-xs-push-3 {
  left: 25%;
}
.col-xs-push-2 {
  left: 16.66666667%;
}
.col-xs-push-1 {
  left: 8.33333333%;
}
.col-xs-push-0 {
  left: auto;
}
.col-xs-offset-12 {
  margin-left: 100%;
}
.col-xs-offset-11 {
  margin-left: 91.66666667%;
}
.col-xs-offset-10 {
  margin-left: 83.33333333%;
}
.col-xs-offset-9 {
  margin-left: 75%;
}
.col-xs-offset-8 {
  margin-left: 66.66666667%;
}
.col-xs-offset-7 {
  margin-left: 58.33333333%;
}
.col-xs-offset-6 {
  margin-left: 50%;
}
.col-xs-offset-5 {
  margin-left: 41.66666667%;
}
.col-xs-offset-4 {
  margin-left: 33.33333333%;
}
.col-xs-offset-3 {
  margin-left: 25%;
}
.col-xs-offset-2 {
  margin-left: 16.66666667%;
}
.col-xs-offset-1 {
  margin-left: 8.33333333%;
}
.col-xs-offset-0 {
  margin-left: 0%;
}
@media (min-width: 768px) {
  .col-sm-1, .col-sm-2, .col-sm-3, .col-sm-4, .col-sm-5, .col-sm-6, .col-sm-7, .col-sm-8, .col-sm-9, .col-sm-10, .col-sm-11, .col-sm-12 {
    float: left;
  }
  .col-sm-12 {
    width: 100%;
  }
  .col-sm-11 {
    width: 91.66666667%;
  }
  .col-sm-10 {
    width: 83.33333333%;
  }
  .col-sm-9 {
    width: 75%;
  }
  .col-sm-8 {
    width: 66.66666667%;
  }
  .col-sm-7 {
    width: 58.33333333%;
  }
  .col-sm-6 {
    width: 50%;
  }
  .col-sm-5 {
    width: 41.66666667%;
  }
  .col-sm-4 {
    width: 33.33333333%;
  }
  .col-sm-3 {
    width: 25%;
  }
  .col-sm-2 {
    width: 16.66666667%;
  }
  .col-sm-1 {
    width: 8.33333333%;
  }
  .col-sm-pull-12 {
    right: 100%;
  }
  .col-sm-pull-11 {
    right: 91.66666667%;
  }
  .col-sm-pull-10 {
    right: 83.33333333%;
  }
  .col-sm-pull-9 {
    right: 75%;
  }
  .col-sm-pull-8 {
    right: 66.66666667%;
  }
  .col-sm-pull-7 {
    right: 58.33333333%;
  }
  .col-sm-pull-6 {
    right: 50%;
  }
  .col-sm-pull-5 {
    right: 41.66666667%;
  }
  .col-sm-pull-4 {
    right: 33.33333333%;
  }
  .col-sm-pull-3 {
    right: 25%;
  }
  .col-sm-pull-2 {
    right: 16.66666667%;
  }
  .col-sm-pull-1 {
    right: 8.33333333%;
  }
  .col-sm-pull-0 {
    right: auto;
  }
  .col-sm-push-12 {
    left: 100%;
  }
  .col-sm-push-11 {
    left: 91.66666667%;
  }
  .col-sm-push-10 {
    left: 83.33333333%;
  }
  .col-sm-push-9 {
    left: 75%;
  }
  .col-sm-push-8 {
    left: 66.66666667%;
  }
  .col-sm-push-7 {
    left: 58.33333333%;
  }
  .col-sm-push-6 {
    left: 50%;
  }
  .col-sm-push-5 {
    left: 41.66666667%;
  }
  .col-sm-push-4 {
    left: 33.33333333%;
  }
  .col-sm-push-3 {
    left: 25%;
  }
  .col-sm-push-2 {
    left: 16.66666667%;
  }
  .col-sm-push-1 {
    left: 8.33333333%;
  }
  .col-sm-push-0 {
    left: auto;
  }
  .col-sm-offset-12 {
    margin-left: 100%;
  }
  .col-sm-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-sm-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-sm-offset-9 {
    margin-left: 75%;
  }
  .col-sm-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-sm-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-sm-offset-6 {
    margin-left: 50%;
  }
  .col-sm-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-sm-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-sm-offset-3 {
    margin-left: 25%;
  }
  .col-sm-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-sm-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-sm-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 992px) {
  .col-md-1, .col-md-2, .col-md-3, .col-md-4, .col-md-5, .col-md-6, .col-md-7, .col-md-8, .col-md-9, .col-md-10, .col-md-11, .col-md-12 {
    float: left;
  }
  .col-md-12 {
    width: 100%;
  }
  .col-md-11 {
    width: 91.66666667%;
  }
  .col-md-10 {
    width: 83.33333333%;
  }
  .col-md-9 {
    width: 75%;
  }
  .col-md-8 {
    width: 66.66666667%;
  }
  .col-md-7 {
    width: 58.33333333%;
  }
  .col-md-6 {
    width: 50%;
  }
  .col-md-5 {
    width: 41.66666667%;
  }
  .col-md-4 {
    width: 33.33333333%;
  }
  .col-md-3 {
    width: 25%;
  }
  .col-md-2 {
    width: 16.66666667%;
  }
  .col-md-1 {
    width: 8.33333333%;
  }
  .col-md-pull-12 {
    right: 100%;
  }
  .col-md-pull-11 {
    right: 91.66666667%;
  }
  .col-md-pull-10 {
    right: 83.33333333%;
  }
  .col-md-pull-9 {
    right: 75%;
  }
  .col-md-pull-8 {
    right: 66.66666667%;
  }
  .col-md-pull-7 {
    right: 58.33333333%;
  }
  .col-md-pull-6 {
    right: 50%;
  }
  .col-md-pull-5 {
    right: 41.66666667%;
  }
  .col-md-pull-4 {
    right: 33.33333333%;
  }
  .col-md-pull-3 {
    right: 25%;
  }
  .col-md-pull-2 {
    right: 16.66666667%;
  }
  .col-md-pull-1 {
    right: 8.33333333%;
  }
  .col-md-pull-0 {
    right: auto;
  }
  .col-md-push-12 {
    left: 100%;
  }
  .col-md-push-11 {
    left: 91.66666667%;
  }
  .col-md-push-10 {
    left: 83.33333333%;
  }
  .col-md-push-9 {
    left: 75%;
  }
  .col-md-push-8 {
    left: 66.66666667%;
  }
  .col-md-push-7 {
    left: 58.33333333%;
  }
  .col-md-push-6 {
    left: 50%;
  }
  .col-md-push-5 {
    left: 41.66666667%;
  }
  .col-md-push-4 {
    left: 33.33333333%;
  }
  .col-md-push-3 {
    left: 25%;
  }
  .col-md-push-2 {
    left: 16.66666667%;
  }
  .col-md-push-1 {
    left: 8.33333333%;
  }
  .col-md-push-0 {
    left: auto;
  }
  .col-md-offset-12 {
    margin-left: 100%;
  }
  .col-md-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-md-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-md-offset-9 {
    margin-left: 75%;
  }
  .col-md-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-md-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-md-offset-6 {
    margin-left: 50%;
  }
  .col-md-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-md-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-md-offset-3 {
    margin-left: 25%;
  }
  .col-md-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-md-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-md-offset-0 {
    margin-left: 0%;
  }
}
@media (min-width: 1200px) {
  .col-lg-1, .col-lg-2, .col-lg-3, .col-lg-4, .col-lg-5, .col-lg-6, .col-lg-7, .col-lg-8, .col-lg-9, .col-lg-10, .col-lg-11, .col-lg-12 {
    float: left;
  }
  .col-lg-12 {
    width: 100%;
  }
  .col-lg-11 {
    width: 91.66666667%;
  }
  .col-lg-10 {
    width: 83.33333333%;
  }
  .col-lg-9 {
    width: 75%;
  }
  .col-lg-8 {
    width: 66.66666667%;
  }
  .col-lg-7 {
    width: 58.33333333%;
  }
  .col-lg-6 {
    width: 50%;
  }
  .col-lg-5 {
    width: 41.66666667%;
  }
  .col-lg-4 {
    width: 33.33333333%;
  }
  .col-lg-3 {
    width: 25%;
  }
  .col-lg-2 {
    width: 16.66666667%;
  }
  .col-lg-1 {
    width: 8.33333333%;
  }
  .col-lg-pull-12 {
    right: 100%;
  }
  .col-lg-pull-11 {
    right: 91.66666667%;
  }
  .col-lg-pull-10 {
    right: 83.33333333%;
  }
  .col-lg-pull-9 {
    right: 75%;
  }
  .col-lg-pull-8 {
    right: 66.66666667%;
  }
  .col-lg-pull-7 {
    right: 58.33333333%;
  }
  .col-lg-pull-6 {
    right: 50%;
  }
  .col-lg-pull-5 {
    right: 41.66666667%;
  }
  .col-lg-pull-4 {
    right: 33.33333333%;
  }
  .col-lg-pull-3 {
    right: 25%;
  }
  .col-lg-pull-2 {
    right: 16.66666667%;
  }
  .col-lg-pull-1 {
    right: 8.33333333%;
  }
  .col-lg-pull-0 {
    right: auto;
  }
  .col-lg-push-12 {
    left: 100%;
  }
  .col-lg-push-11 {
    left: 91.66666667%;
  }
  .col-lg-push-10 {
    left: 83.33333333%;
  }
  .col-lg-push-9 {
    left: 75%;
  }
  .col-lg-push-8 {
    left: 66.66666667%;
  }
  .col-lg-push-7 {
    left: 58.33333333%;
  }
  .col-lg-push-6 {
    left: 50%;
  }
  .col-lg-push-5 {
    left: 41.66666667%;
  }
  .col-lg-push-4 {
    left: 33.33333333%;
  }
  .col-lg-push-3 {
    left: 25%;
  }
  .col-lg-push-2 {
    left: 16.66666667%;
  }
  .col-lg-push-1 {
    left: 8.33333333%;
  }
  .col-lg-push-0 {
    left: auto;
  }
  .col-lg-offset-12 {
    margin-left: 100%;
  }
  .col-lg-offset-11 {
    margin-left: 91.66666667%;
  }
  .col-lg-offset-10 {
    margin-left: 83.33333333%;
  }
  .col-lg-offset-9 {
    margin-left: 75%;
  }
  .col-lg-offset-8 {
    margin-left: 66.66666667%;
  }
  .col-lg-offset-7 {
    margin-left: 58.33333333%;
  }
  .col-lg-offset-6 {
    margin-left: 50%;
  }
  .col-lg-offset-5 {
    margin-left: 41.66666667%;
  }
  .col-lg-offset-4 {
    margin-left: 33.33333333%;
  }
  .col-lg-offset-3 {
    margin-left: 25%;
  }
  .col-lg-offset-2 {
    margin-left: 16.66666667%;
  }
  .col-lg-offset-1 {
    margin-left: 8.33333333%;
  }
  .col-lg-offset-0 {
    margin-left: 0%;
  }
}
table {
  background-color: transparent;
}
caption {
  padding-top: 8px;
  padding-bottom: 8px;
  color: #777777;
  text-align: left;
}
th {
  text-align: left;
}
.table {
  width: 100%;
  max-width: 100%;
  margin-bottom: 18px;
}
.table > thead > tr > th,
.table > tbody > tr > th,
.table > tfoot > tr > th,
.table > thead > tr > td,
.table > tbody > tr > td,
.table > tfoot > tr > td {
  padding: 8px;
  line-height: 1.42857143;
  vertical-align: top;
  border-top: 1px solid #ddd;
}
.table > thead > tr > th {
  vertical-align: bottom;
  border-bottom: 2px solid #ddd;
}
.table > caption + thead > tr:first-child > th,
.table > colgroup + thead > tr:first-child > th,
.table > thead:first-child > tr:first-child > th,
.table > caption + thead > tr:first-child > td,
.table > colgroup + thead > tr:first-child > td,
.table > thead:first-child > tr:first-child > td {
  border-top: 0;
}
.table > tbody + tbody {
  border-top: 2px solid #ddd;
}
.table .table {
  background-color: #fff;
}
.table-condensed > thead > tr > th,
.table-condensed > tbody > tr > th,
.table-condensed > tfoot > tr > th,
.table-condensed > thead > tr > td,
.table-condensed > tbody > tr > td,
.table-condensed > tfoot > tr > td {
  padding: 5px;
}
.table-bordered {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > tbody > tr > th,
.table-bordered > tfoot > tr > th,
.table-bordered > thead > tr > td,
.table-bordered > tbody > tr > td,
.table-bordered > tfoot > tr > td {
  border: 1px solid #ddd;
}
.table-bordered > thead > tr > th,
.table-bordered > thead > tr > td {
  border-bottom-width: 2px;
}
.table-striped > tbody > tr:nth-of-type(odd) {
  background-color: #f9f9f9;
}
.table-hover > tbody > tr:hover {
  background-color: #f5f5f5;
}
table col[class*="col-"] {
  position: static;
  float: none;
  display: table-column;
}
table td[class*="col-"],
table th[class*="col-"] {
  position: static;
  float: none;
  display: table-cell;
}
.table > thead > tr > td.active,
.table > tbody > tr > td.active,
.table > tfoot > tr > td.active,
.table > thead > tr > th.active,
.table > tbody > tr > th.active,
.table > tfoot > tr > th.active,
.table > thead > tr.active > td,
.table > tbody > tr.active > td,
.table > tfoot > tr.active > td,
.table > thead > tr.active > th,
.table > tbody > tr.active > th,
.table > tfoot > tr.active > th {
  background-color: #f5f5f5;
}
.table-hover > tbody > tr > td.active:hover,
.table-hover > tbody > tr > th.active:hover,
.table-hover > tbody > tr.active:hover > td,
.table-hover > tbody > tr:hover > .active,
.table-hover > tbody > tr.active:hover > th {
  background-color: #e8e8e8;
}
.table > thead > tr > td.success,
.table > tbody > tr > td.success,
.table > tfoot > tr > td.success,
.table > thead > tr > th.success,
.table > tbody > tr > th.success,
.table > tfoot > tr > th.success,
.table > thead > tr.success > td,
.table > tbody > tr.success > td,
.table > tfoot > tr.success > td,
.table > thead > tr.success > th,
.table > tbody > tr.success > th,
.table > tfoot > tr.success > th {
  background-color: #dff0d8;
}
.table-hover > tbody > tr > td.success:hover,
.table-hover > tbody > tr > th.success:hover,
.table-hover > tbody > tr.success:hover > td,
.table-hover > tbody > tr:hover > .success,
.table-hover > tbody > tr.success:hover > th {
  background-color: #d0e9c6;
}
.table > thead > tr > td.info,
.table > tbody > tr > td.info,
.table > tfoot > tr > td.info,
.table > thead > tr > th.info,
.table > tbody > tr > th.info,
.table > tfoot > tr > th.info,
.table > thead > tr.info > td,
.table > tbody > tr.info > td,
.table > tfoot > tr.info > td,
.table > thead > tr.info > th,
.table > tbody > tr.info > th,
.table > tfoot > tr.info > th {
  background-color: #d9edf7;
}
.table-hover > tbody > tr > td.info:hover,
.table-hover > tbody > tr > th.info:hover,
.table-hover > tbody > tr.info:hover > td,
.table-hover > tbody > tr:hover > .info,
.table-hover > tbody > tr.info:hover > th {
  background-color: #c4e3f3;
}
.table > thead > tr > td.warning,
.table > tbody > tr > td.warning,
.table > tfoot > tr > td.warning,
.table > thead > tr > th.warning,
.table > tbody > tr > th.warning,
.table > tfoot > tr > th.warning,
.table > thead > tr.warning > td,
.table > tbody > tr.warning > td,
.table > tfoot > tr.warning > td,
.table > thead > tr.warning > th,
.table > tbody > tr.warning > th,
.table > tfoot > tr.warning > th {
  background-color: #fcf8e3;
}
.table-hover > tbody > tr > td.warning:hover,
.table-hover > tbody > tr > th.warning:hover,
.table-hover > tbody > tr.warning:hover > td,
.table-hover > tbody > tr:hover > .warning,
.table-hover > tbody > tr.warning:hover > th {
  background-color: #faf2cc;
}
.table > thead > tr > td.danger,
.table > tbody > tr > td.danger,
.table > tfoot > tr > td.danger,
.table > thead > tr > th.danger,
.table > tbody > tr > th.danger,
.table > tfoot > tr > th.danger,
.table > thead > tr.danger > td,
.table > tbody > tr.danger > td,
.table > tfoot > tr.danger > td,
.table > thead > tr.danger > th,
.table > tbody > tr.danger > th,
.table > tfoot > tr.danger > th {
  background-color: #f2dede;
}
.table-hover > tbody > tr > td.danger:hover,
.table-hover > tbody > tr > th.danger:hover,
.table-hover > tbody > tr.danger:hover > td,
.table-hover > tbody > tr:hover > .danger,
.table-hover > tbody > tr.danger:hover > th {
  background-color: #ebcccc;
}
.table-responsive {
  overflow-x: auto;
  min-height: 0.01%;
}
@media screen and (max-width: 767px) {
  .table-responsive {
    width: 100%;
    margin-bottom: 13.5px;
    overflow-y: hidden;
    -ms-overflow-style: -ms-autohiding-scrollbar;
    border: 1px solid #ddd;
  }
  .table-responsive > .table {
    margin-bottom: 0;
  }
  .table-responsive > .table > thead > tr > th,
  .table-responsive > .table > tbody > tr > th,
  .table-responsive > .table > tfoot > tr > th,
  .table-responsive > .table > thead > tr > td,
  .table-responsive > .table > tbody > tr > td,
  .table-responsive > .table > tfoot > tr > td {
    white-space: nowrap;
  }
  .table-responsive > .table-bordered {
    border: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:first-child,
  .table-responsive > .table-bordered > tbody > tr > th:first-child,
  .table-responsive > .table-bordered > tfoot > tr > th:first-child,
  .table-responsive > .table-bordered > thead > tr > td:first-child,
  .table-responsive > .table-bordered > tbody > tr > td:first-child,
  .table-responsive > .table-bordered > tfoot > tr > td:first-child {
    border-left: 0;
  }
  .table-responsive > .table-bordered > thead > tr > th:last-child,
  .table-responsive > .table-bordered > tbody > tr > th:last-child,
  .table-responsive > .table-bordered > tfoot > tr > th:last-child,
  .table-responsive > .table-bordered > thead > tr > td:last-child,
  .table-responsive > .table-bordered > tbody > tr > td:last-child,
  .table-responsive > .table-bordered > tfoot > tr > td:last-child {
    border-right: 0;
  }
  .table-responsive > .table-bordered > tbody > tr:last-child > th,
  .table-responsive > .table-bordered > tfoot > tr:last-child > th,
  .table-responsive > .table-bordered > tbody > tr:last-child > td,
  .table-responsive > .table-bordered > tfoot > tr:last-child > td {
    border-bottom: 0;
  }
}
fieldset {
  padding: 0;
  margin: 0;
  border: 0;
  min-width: 0;
}
legend {
  display: block;
  width: 100%;
  padding: 0;
  margin-bottom: 18px;
  font-size: 19.5px;
  line-height: inherit;
  color: #333333;
  border: 0;
  border-bottom: 1px solid #e5e5e5;
}
label {
  display: inline-block;
  max-width: 100%;
  margin-bottom: 5px;
  font-weight: bold;
}
input[type="search"] {
  -webkit-box-sizing: border-box;
  -moz-box-sizing: border-box;
  box-sizing: border-box;
}
input[type="radio"],
input[type="checkbox"] {
  margin: 4px 0 0;
  margin-top: 1px \9;
  line-height: normal;
}
input[type="file"] {
  display: block;
}
input[type="range"] {
  display: block;
  width: 100%;
}
select[multiple],
select[size] {
  height: auto;
}
input[type="file"]:focus,
input[type="radio"]:focus,
input[type="checkbox"]:focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
output {
  display: block;
  padding-top: 7px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
}
.form-control {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
}
.form-control:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.form-control::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.form-control:-ms-input-placeholder {
  color: #999;
}
.form-control::-webkit-input-placeholder {
  color: #999;
}
.form-control::-ms-expand {
  border: 0;
  background-color: transparent;
}
.form-control[disabled],
.form-control[readonly],
fieldset[disabled] .form-control {
  background-color: #eeeeee;
  opacity: 1;
}
.form-control[disabled],
fieldset[disabled] .form-control {
  cursor: not-allowed;
}
textarea.form-control {
  height: auto;
}
input[type="search"] {
  -webkit-appearance: none;
}
@media screen and (-webkit-min-device-pixel-ratio: 0) {
  input[type="date"].form-control,
  input[type="time"].form-control,
  input[type="datetime-local"].form-control,
  input[type="month"].form-control {
    line-height: 32px;
  }
  input[type="date"].input-sm,
  input[type="time"].input-sm,
  input[type="datetime-local"].input-sm,
  input[type="month"].input-sm,
  .input-group-sm input[type="date"],
  .input-group-sm input[type="time"],
  .input-group-sm input[type="datetime-local"],
  .input-group-sm input[type="month"] {
    line-height: 30px;
  }
  input[type="date"].input-lg,
  input[type="time"].input-lg,
  input[type="datetime-local"].input-lg,
  input[type="month"].input-lg,
  .input-group-lg input[type="date"],
  .input-group-lg input[type="time"],
  .input-group-lg input[type="datetime-local"],
  .input-group-lg input[type="month"] {
    line-height: 45px;
  }
}
.form-group {
  margin-bottom: 15px;
}
.radio,
.checkbox {
  position: relative;
  display: block;
  margin-top: 10px;
  margin-bottom: 10px;
}
.radio label,
.checkbox label {
  min-height: 18px;
  padding-left: 20px;
  margin-bottom: 0;
  font-weight: normal;
  cursor: pointer;
}
.radio input[type="radio"],
.radio-inline input[type="radio"],
.checkbox input[type="checkbox"],
.checkbox-inline input[type="checkbox"] {
  position: absolute;
  margin-left: -20px;
  margin-top: 4px \9;
}
.radio + .radio,
.checkbox + .checkbox {
  margin-top: -5px;
}
.radio-inline,
.checkbox-inline {
  position: relative;
  display: inline-block;
  padding-left: 20px;
  margin-bottom: 0;
  vertical-align: middle;
  font-weight: normal;
  cursor: pointer;
}
.radio-inline + .radio-inline,
.checkbox-inline + .checkbox-inline {
  margin-top: 0;
  margin-left: 10px;
}
input[type="radio"][disabled],
input[type="checkbox"][disabled],
input[type="radio"].disabled,
input[type="checkbox"].disabled,
fieldset[disabled] input[type="radio"],
fieldset[disabled] input[type="checkbox"] {
  cursor: not-allowed;
}
.radio-inline.disabled,
.checkbox-inline.disabled,
fieldset[disabled] .radio-inline,
fieldset[disabled] .checkbox-inline {
  cursor: not-allowed;
}
.radio.disabled label,
.checkbox.disabled label,
fieldset[disabled] .radio label,
fieldset[disabled] .checkbox label {
  cursor: not-allowed;
}
.form-control-static {
  padding-top: 7px;
  padding-bottom: 7px;
  margin-bottom: 0;
  min-height: 31px;
}
.form-control-static.input-lg,
.form-control-static.input-sm {
  padding-left: 0;
  padding-right: 0;
}
.input-sm {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-sm {
  height: 30px;
  line-height: 30px;
}
textarea.input-sm,
select[multiple].input-sm {
  height: auto;
}
.form-group-sm .form-control {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.form-group-sm select.form-control {
  height: 30px;
  line-height: 30px;
}
.form-group-sm textarea.form-control,
.form-group-sm select[multiple].form-control {
  height: auto;
}
.form-group-sm .form-control-static {
  height: 30px;
  min-height: 30px;
  padding: 6px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.input-lg {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-lg {
  height: 45px;
  line-height: 45px;
}
textarea.input-lg,
select[multiple].input-lg {
  height: auto;
}
.form-group-lg .form-control {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.form-group-lg select.form-control {
  height: 45px;
  line-height: 45px;
}
.form-group-lg textarea.form-control,
.form-group-lg select[multiple].form-control {
  height: auto;
}
.form-group-lg .form-control-static {
  height: 45px;
  min-height: 35px;
  padding: 11px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.has-feedback {
  position: relative;
}
.has-feedback .form-control {
  padding-right: 40px;
}
.form-control-feedback {
  position: absolute;
  top: 0;
  right: 0;
  z-index: 2;
  display: block;
  width: 32px;
  height: 32px;
  line-height: 32px;
  text-align: center;
  pointer-events: none;
}
.input-lg + .form-control-feedback,
.input-group-lg + .form-control-feedback,
.form-group-lg .form-control + .form-control-feedback {
  width: 45px;
  height: 45px;
  line-height: 45px;
}
.input-sm + .form-control-feedback,
.input-group-sm + .form-control-feedback,
.form-group-sm .form-control + .form-control-feedback {
  width: 30px;
  height: 30px;
  line-height: 30px;
}
.has-success .help-block,
.has-success .control-label,
.has-success .radio,
.has-success .checkbox,
.has-success .radio-inline,
.has-success .checkbox-inline,
.has-success.radio label,
.has-success.checkbox label,
.has-success.radio-inline label,
.has-success.checkbox-inline label {
  color: #3c763d;
}
.has-success .form-control {
  border-color: #3c763d;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-success .form-control:focus {
  border-color: #2b542c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #67b168;
}
.has-success .input-group-addon {
  color: #3c763d;
  border-color: #3c763d;
  background-color: #dff0d8;
}
.has-success .form-control-feedback {
  color: #3c763d;
}
.has-warning .help-block,
.has-warning .control-label,
.has-warning .radio,
.has-warning .checkbox,
.has-warning .radio-inline,
.has-warning .checkbox-inline,
.has-warning.radio label,
.has-warning.checkbox label,
.has-warning.radio-inline label,
.has-warning.checkbox-inline label {
  color: #8a6d3b;
}
.has-warning .form-control {
  border-color: #8a6d3b;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-warning .form-control:focus {
  border-color: #66512c;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #c0a16b;
}
.has-warning .input-group-addon {
  color: #8a6d3b;
  border-color: #8a6d3b;
  background-color: #fcf8e3;
}
.has-warning .form-control-feedback {
  color: #8a6d3b;
}
.has-error .help-block,
.has-error .control-label,
.has-error .radio,
.has-error .checkbox,
.has-error .radio-inline,
.has-error .checkbox-inline,
.has-error.radio label,
.has-error.checkbox label,
.has-error.radio-inline label,
.has-error.checkbox-inline label {
  color: #a94442;
}
.has-error .form-control {
  border-color: #a94442;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
}
.has-error .form-control:focus {
  border-color: #843534;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075), 0 0 6px #ce8483;
}
.has-error .input-group-addon {
  color: #a94442;
  border-color: #a94442;
  background-color: #f2dede;
}
.has-error .form-control-feedback {
  color: #a94442;
}
.has-feedback label ~ .form-control-feedback {
  top: 23px;
}
.has-feedback label.sr-only ~ .form-control-feedback {
  top: 0;
}
.help-block {
  display: block;
  margin-top: 5px;
  margin-bottom: 10px;
  color: #404040;
}
@media (min-width: 768px) {
  .form-inline .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .form-inline .form-control-static {
    display: inline-block;
  }
  .form-inline .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .form-inline .input-group .input-group-addon,
  .form-inline .input-group .input-group-btn,
  .form-inline .input-group .form-control {
    width: auto;
  }
  .form-inline .input-group > .form-control {
    width: 100%;
  }
  .form-inline .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio,
  .form-inline .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .form-inline .radio label,
  .form-inline .checkbox label {
    padding-left: 0;
  }
  .form-inline .radio input[type="radio"],
  .form-inline .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .form-inline .has-feedback .form-control-feedback {
    top: 0;
  }
}
.form-horizontal .radio,
.form-horizontal .checkbox,
.form-horizontal .radio-inline,
.form-horizontal .checkbox-inline {
  margin-top: 0;
  margin-bottom: 0;
  padding-top: 7px;
}
.form-horizontal .radio,
.form-horizontal .checkbox {
  min-height: 25px;
}
.form-horizontal .form-group {
  margin-left: 0px;
  margin-right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .control-label {
    text-align: right;
    margin-bottom: 0;
    padding-top: 7px;
  }
}
.form-horizontal .has-feedback .form-control-feedback {
  right: 0px;
}
@media (min-width: 768px) {
  .form-horizontal .form-group-lg .control-label {
    padding-top: 11px;
    font-size: 17px;
  }
}
@media (min-width: 768px) {
  .form-horizontal .form-group-sm .control-label {
    padding-top: 6px;
    font-size: 12px;
  }
}
.btn {
  display: inline-block;
  margin-bottom: 0;
  font-weight: normal;
  text-align: center;
  vertical-align: middle;
  touch-action: manipulation;
  cursor: pointer;
  background-image: none;
  border: 1px solid transparent;
  white-space: nowrap;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  border-radius: 2px;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
}
.btn:focus,
.btn:active:focus,
.btn.active:focus,
.btn.focus,
.btn:active.focus,
.btn.active.focus {
  outline: 5px auto -webkit-focus-ring-color;
  outline-offset: -2px;
}
.btn:hover,
.btn:focus,
.btn.focus {
  color: #333;
  text-decoration: none;
}
.btn:active,
.btn.active {
  outline: 0;
  background-image: none;
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn.disabled,
.btn[disabled],
fieldset[disabled] .btn {
  cursor: not-allowed;
  opacity: 0.65;
  filter: alpha(opacity=65);
  -webkit-box-shadow: none;
  box-shadow: none;
}
a.btn.disabled,
fieldset[disabled] a.btn {
  pointer-events: none;
}
.btn-default {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.btn-default:focus,
.btn-default.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.btn-default:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.btn-default:active:hover,
.btn-default.active:hover,
.open > .dropdown-toggle.btn-default:hover,
.btn-default:active:focus,
.btn-default.active:focus,
.open > .dropdown-toggle.btn-default:focus,
.btn-default:active.focus,
.btn-default.active.focus,
.open > .dropdown-toggle.btn-default.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.btn-default:active,
.btn-default.active,
.open > .dropdown-toggle.btn-default {
  background-image: none;
}
.btn-default.disabled:hover,
.btn-default[disabled]:hover,
fieldset[disabled] .btn-default:hover,
.btn-default.disabled:focus,
.btn-default[disabled]:focus,
fieldset[disabled] .btn-default:focus,
.btn-default.disabled.focus,
.btn-default[disabled].focus,
fieldset[disabled] .btn-default.focus {
  background-color: #fff;
  border-color: #ccc;
}
.btn-default .badge {
  color: #fff;
  background-color: #333;
}
.btn-primary {
  color: #fff;
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary:focus,
.btn-primary.focus {
  color: #fff;
  background-color: #286090;
  border-color: #122b40;
}
.btn-primary:hover {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  color: #fff;
  background-color: #286090;
  border-color: #204d74;
}
.btn-primary:active:hover,
.btn-primary.active:hover,
.open > .dropdown-toggle.btn-primary:hover,
.btn-primary:active:focus,
.btn-primary.active:focus,
.open > .dropdown-toggle.btn-primary:focus,
.btn-primary:active.focus,
.btn-primary.active.focus,
.open > .dropdown-toggle.btn-primary.focus {
  color: #fff;
  background-color: #204d74;
  border-color: #122b40;
}
.btn-primary:active,
.btn-primary.active,
.open > .dropdown-toggle.btn-primary {
  background-image: none;
}
.btn-primary.disabled:hover,
.btn-primary[disabled]:hover,
fieldset[disabled] .btn-primary:hover,
.btn-primary.disabled:focus,
.btn-primary[disabled]:focus,
fieldset[disabled] .btn-primary:focus,
.btn-primary.disabled.focus,
.btn-primary[disabled].focus,
fieldset[disabled] .btn-primary.focus {
  background-color: #337ab7;
  border-color: #2e6da4;
}
.btn-primary .badge {
  color: #337ab7;
  background-color: #fff;
}
.btn-success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success:focus,
.btn-success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.btn-success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.btn-success:active:hover,
.btn-success.active:hover,
.open > .dropdown-toggle.btn-success:hover,
.btn-success:active:focus,
.btn-success.active:focus,
.open > .dropdown-toggle.btn-success:focus,
.btn-success:active.focus,
.btn-success.active.focus,
.open > .dropdown-toggle.btn-success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.btn-success:active,
.btn-success.active,
.open > .dropdown-toggle.btn-success {
  background-image: none;
}
.btn-success.disabled:hover,
.btn-success[disabled]:hover,
fieldset[disabled] .btn-success:hover,
.btn-success.disabled:focus,
.btn-success[disabled]:focus,
fieldset[disabled] .btn-success:focus,
.btn-success.disabled.focus,
.btn-success[disabled].focus,
fieldset[disabled] .btn-success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.btn-success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.btn-info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info:focus,
.btn-info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.btn-info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.btn-info:active:hover,
.btn-info.active:hover,
.open > .dropdown-toggle.btn-info:hover,
.btn-info:active:focus,
.btn-info.active:focus,
.open > .dropdown-toggle.btn-info:focus,
.btn-info:active.focus,
.btn-info.active.focus,
.open > .dropdown-toggle.btn-info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.btn-info:active,
.btn-info.active,
.open > .dropdown-toggle.btn-info {
  background-image: none;
}
.btn-info.disabled:hover,
.btn-info[disabled]:hover,
fieldset[disabled] .btn-info:hover,
.btn-info.disabled:focus,
.btn-info[disabled]:focus,
fieldset[disabled] .btn-info:focus,
.btn-info.disabled.focus,
.btn-info[disabled].focus,
fieldset[disabled] .btn-info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.btn-info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.btn-warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning:focus,
.btn-warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.btn-warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.btn-warning:active:hover,
.btn-warning.active:hover,
.open > .dropdown-toggle.btn-warning:hover,
.btn-warning:active:focus,
.btn-warning.active:focus,
.open > .dropdown-toggle.btn-warning:focus,
.btn-warning:active.focus,
.btn-warning.active.focus,
.open > .dropdown-toggle.btn-warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.btn-warning:active,
.btn-warning.active,
.open > .dropdown-toggle.btn-warning {
  background-image: none;
}
.btn-warning.disabled:hover,
.btn-warning[disabled]:hover,
fieldset[disabled] .btn-warning:hover,
.btn-warning.disabled:focus,
.btn-warning[disabled]:focus,
fieldset[disabled] .btn-warning:focus,
.btn-warning.disabled.focus,
.btn-warning[disabled].focus,
fieldset[disabled] .btn-warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.btn-warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.btn-danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger:focus,
.btn-danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.btn-danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.btn-danger:active:hover,
.btn-danger.active:hover,
.open > .dropdown-toggle.btn-danger:hover,
.btn-danger:active:focus,
.btn-danger.active:focus,
.open > .dropdown-toggle.btn-danger:focus,
.btn-danger:active.focus,
.btn-danger.active.focus,
.open > .dropdown-toggle.btn-danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.btn-danger:active,
.btn-danger.active,
.open > .dropdown-toggle.btn-danger {
  background-image: none;
}
.btn-danger.disabled:hover,
.btn-danger[disabled]:hover,
fieldset[disabled] .btn-danger:hover,
.btn-danger.disabled:focus,
.btn-danger[disabled]:focus,
fieldset[disabled] .btn-danger:focus,
.btn-danger.disabled.focus,
.btn-danger[disabled].focus,
fieldset[disabled] .btn-danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.btn-danger .badge {
  color: #d9534f;
  background-color: #fff;
}
.btn-link {
  color: #337ab7;
  font-weight: normal;
  border-radius: 0;
}
.btn-link,
.btn-link:active,
.btn-link.active,
.btn-link[disabled],
fieldset[disabled] .btn-link {
  background-color: transparent;
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn-link,
.btn-link:hover,
.btn-link:focus,
.btn-link:active {
  border-color: transparent;
}
.btn-link:hover,
.btn-link:focus {
  color: #23527c;
  text-decoration: underline;
  background-color: transparent;
}
.btn-link[disabled]:hover,
fieldset[disabled] .btn-link:hover,
.btn-link[disabled]:focus,
fieldset[disabled] .btn-link:focus {
  color: #777777;
  text-decoration: none;
}
.btn-lg,
.btn-group-lg > .btn {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
.btn-sm,
.btn-group-sm > .btn {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-xs,
.btn-group-xs > .btn {
  padding: 1px 5px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
.btn-block {
  display: block;
  width: 100%;
}
.btn-block + .btn-block {
  margin-top: 5px;
}
input[type="submit"].btn-block,
input[type="reset"].btn-block,
input[type="button"].btn-block {
  width: 100%;
}
.fade {
  opacity: 0;
  -webkit-transition: opacity 0.15s linear;
  -o-transition: opacity 0.15s linear;
  transition: opacity 0.15s linear;
}
.fade.in {
  opacity: 1;
}
.collapse {
  display: none;
}
.collapse.in {
  display: block;
}
tr.collapse.in {
  display: table-row;
}
tbody.collapse.in {
  display: table-row-group;
}
.collapsing {
  position: relative;
  height: 0;
  overflow: hidden;
  -webkit-transition-property: height, visibility;
  transition-property: height, visibility;
  -webkit-transition-duration: 0.35s;
  transition-duration: 0.35s;
  -webkit-transition-timing-function: ease;
  transition-timing-function: ease;
}
.caret {
  display: inline-block;
  width: 0;
  height: 0;
  margin-left: 2px;
  vertical-align: middle;
  border-top: 4px dashed;
  border-top: 4px solid \9;
  border-right: 4px solid transparent;
  border-left: 4px solid transparent;
}
.dropup,
.dropdown {
  position: relative;
}
.dropdown-toggle:focus {
  outline: 0;
}
.dropdown-menu {
  position: absolute;
  top: 100%;
  left: 0;
  z-index: 1000;
  display: none;
  float: left;
  min-width: 160px;
  padding: 5px 0;
  margin: 2px 0 0;
  list-style: none;
  font-size: 13px;
  text-align: left;
  background-color: #fff;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.15);
  border-radius: 2px;
  -webkit-box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  box-shadow: 0 6px 12px rgba(0, 0, 0, 0.175);
  background-clip: padding-box;
}
.dropdown-menu.pull-right {
  right: 0;
  left: auto;
}
.dropdown-menu .divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.dropdown-menu > li > a {
  display: block;
  padding: 3px 20px;
  clear: both;
  font-weight: normal;
  line-height: 1.42857143;
  color: #333333;
  white-space: nowrap;
}
.dropdown-menu > li > a:hover,
.dropdown-menu > li > a:focus {
  text-decoration: none;
  color: #262626;
  background-color: #f5f5f5;
}
.dropdown-menu > .active > a,
.dropdown-menu > .active > a:hover,
.dropdown-menu > .active > a:focus {
  color: #fff;
  text-decoration: none;
  outline: 0;
  background-color: #337ab7;
}
.dropdown-menu > .disabled > a,
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  color: #777777;
}
.dropdown-menu > .disabled > a:hover,
.dropdown-menu > .disabled > a:focus {
  text-decoration: none;
  background-color: transparent;
  background-image: none;
  filter: progid:DXImageTransform.Microsoft.gradient(enabled = false);
  cursor: not-allowed;
}
.open > .dropdown-menu {
  display: block;
}
.open > a {
  outline: 0;
}
.dropdown-menu-right {
  left: auto;
  right: 0;
}
.dropdown-menu-left {
  left: 0;
  right: auto;
}
.dropdown-header {
  display: block;
  padding: 3px 20px;
  font-size: 12px;
  line-height: 1.42857143;
  color: #777777;
  white-space: nowrap;
}
.dropdown-backdrop {
  position: fixed;
  left: 0;
  right: 0;
  bottom: 0;
  top: 0;
  z-index: 990;
}
.pull-right > .dropdown-menu {
  right: 0;
  left: auto;
}
.dropup .caret,
.navbar-fixed-bottom .dropdown .caret {
  border-top: 0;
  border-bottom: 4px dashed;
  border-bottom: 4px solid \9;
  content: "";
}
.dropup .dropdown-menu,
.navbar-fixed-bottom .dropdown .dropdown-menu {
  top: auto;
  bottom: 100%;
  margin-bottom: 2px;
}
@media (min-width: 541px) {
  .navbar-right .dropdown-menu {
    left: auto;
    right: 0;
  }
  .navbar-right .dropdown-menu-left {
    left: 0;
    right: auto;
  }
}
.btn-group,
.btn-group-vertical {
  position: relative;
  display: inline-block;
  vertical-align: middle;
}
.btn-group > .btn,
.btn-group-vertical > .btn {
  position: relative;
  float: left;
}
.btn-group > .btn:hover,
.btn-group-vertical > .btn:hover,
.btn-group > .btn:focus,
.btn-group-vertical > .btn:focus,
.btn-group > .btn:active,
.btn-group-vertical > .btn:active,
.btn-group > .btn.active,
.btn-group-vertical > .btn.active {
  z-index: 2;
}
.btn-group .btn + .btn,
.btn-group .btn + .btn-group,
.btn-group .btn-group + .btn,
.btn-group .btn-group + .btn-group {
  margin-left: -1px;
}
.btn-toolbar {
  margin-left: -5px;
}
.btn-toolbar .btn,
.btn-toolbar .btn-group,
.btn-toolbar .input-group {
  float: left;
}
.btn-toolbar > .btn,
.btn-toolbar > .btn-group,
.btn-toolbar > .input-group {
  margin-left: 5px;
}
.btn-group > .btn:not(:first-child):not(:last-child):not(.dropdown-toggle) {
  border-radius: 0;
}
.btn-group > .btn:first-child {
  margin-left: 0;
}
.btn-group > .btn:first-child:not(:last-child):not(.dropdown-toggle) {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn:last-child:not(:first-child),
.btn-group > .dropdown-toggle:not(:first-child) {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group > .btn-group {
  float: left;
}
.btn-group > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.btn-group > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.btn-group .dropdown-toggle:active,
.btn-group.open .dropdown-toggle {
  outline: 0;
}
.btn-group > .btn + .dropdown-toggle {
  padding-left: 8px;
  padding-right: 8px;
}
.btn-group > .btn-lg + .dropdown-toggle {
  padding-left: 12px;
  padding-right: 12px;
}
.btn-group.open .dropdown-toggle {
  -webkit-box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
  box-shadow: inset 0 3px 5px rgba(0, 0, 0, 0.125);
}
.btn-group.open .dropdown-toggle.btn-link {
  -webkit-box-shadow: none;
  box-shadow: none;
}
.btn .caret {
  margin-left: 0;
}
.btn-lg .caret {
  border-width: 5px 5px 0;
  border-bottom-width: 0;
}
.dropup .btn-lg .caret {
  border-width: 0 5px 5px;
}
.btn-group-vertical > .btn,
.btn-group-vertical > .btn-group,
.btn-group-vertical > .btn-group > .btn {
  display: block;
  float: none;
  width: 100%;
  max-width: 100%;
}
.btn-group-vertical > .btn-group > .btn {
  float: none;
}
.btn-group-vertical > .btn + .btn,
.btn-group-vertical > .btn + .btn-group,
.btn-group-vertical > .btn-group + .btn,
.btn-group-vertical > .btn-group + .btn-group {
  margin-top: -1px;
  margin-left: 0;
}
.btn-group-vertical > .btn:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.btn-group-vertical > .btn:first-child:not(:last-child) {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn:last-child:not(:first-child) {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
.btn-group-vertical > .btn-group:not(:first-child):not(:last-child) > .btn {
  border-radius: 0;
}
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .btn:last-child,
.btn-group-vertical > .btn-group:first-child:not(:last-child) > .dropdown-toggle {
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.btn-group-vertical > .btn-group:last-child:not(:first-child) > .btn:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.btn-group-justified {
  display: table;
  width: 100%;
  table-layout: fixed;
  border-collapse: separate;
}
.btn-group-justified > .btn,
.btn-group-justified > .btn-group {
  float: none;
  display: table-cell;
  width: 1%;
}
.btn-group-justified > .btn-group .btn {
  width: 100%;
}
.btn-group-justified > .btn-group .dropdown-menu {
  left: auto;
}
[data-toggle="buttons"] > .btn input[type="radio"],
[data-toggle="buttons"] > .btn-group > .btn input[type="radio"],
[data-toggle="buttons"] > .btn input[type="checkbox"],
[data-toggle="buttons"] > .btn-group > .btn input[type="checkbox"] {
  position: absolute;
  clip: rect(0, 0, 0, 0);
  pointer-events: none;
}
.input-group {
  position: relative;
  display: table;
  border-collapse: separate;
}
.input-group[class*="col-"] {
  float: none;
  padding-left: 0;
  padding-right: 0;
}
.input-group .form-control {
  position: relative;
  z-index: 2;
  float: left;
  width: 100%;
  margin-bottom: 0;
}
.input-group .form-control:focus {
  z-index: 3;
}
.input-group-lg > .form-control,
.input-group-lg > .input-group-addon,
.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
  border-radius: 3px;
}
select.input-group-lg > .form-control,
select.input-group-lg > .input-group-addon,
select.input-group-lg > .input-group-btn > .btn {
  height: 45px;
  line-height: 45px;
}
textarea.input-group-lg > .form-control,
textarea.input-group-lg > .input-group-addon,
textarea.input-group-lg > .input-group-btn > .btn,
select[multiple].input-group-lg > .form-control,
select[multiple].input-group-lg > .input-group-addon,
select[multiple].input-group-lg > .input-group-btn > .btn {
  height: auto;
}
.input-group-sm > .form-control,
.input-group-sm > .input-group-addon,
.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
}
select.input-group-sm > .form-control,
select.input-group-sm > .input-group-addon,
select.input-group-sm > .input-group-btn > .btn {
  height: 30px;
  line-height: 30px;
}
textarea.input-group-sm > .form-control,
textarea.input-group-sm > .input-group-addon,
textarea.input-group-sm > .input-group-btn > .btn,
select[multiple].input-group-sm > .form-control,
select[multiple].input-group-sm > .input-group-addon,
select[multiple].input-group-sm > .input-group-btn > .btn {
  height: auto;
}
.input-group-addon,
.input-group-btn,
.input-group .form-control {
  display: table-cell;
}
.input-group-addon:not(:first-child):not(:last-child),
.input-group-btn:not(:first-child):not(:last-child),
.input-group .form-control:not(:first-child):not(:last-child) {
  border-radius: 0;
}
.input-group-addon,
.input-group-btn {
  width: 1%;
  white-space: nowrap;
  vertical-align: middle;
}
.input-group-addon {
  padding: 6px 12px;
  font-size: 13px;
  font-weight: normal;
  line-height: 1;
  color: #555555;
  text-align: center;
  background-color: #eeeeee;
  border: 1px solid #ccc;
  border-radius: 2px;
}
.input-group-addon.input-sm {
  padding: 5px 10px;
  font-size: 12px;
  border-radius: 1px;
}
.input-group-addon.input-lg {
  padding: 10px 16px;
  font-size: 17px;
  border-radius: 3px;
}
.input-group-addon input[type="radio"],
.input-group-addon input[type="checkbox"] {
  margin-top: 0;
}
.input-group .form-control:first-child,
.input-group-addon:first-child,
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group > .btn,
.input-group-btn:first-child > .dropdown-toggle,
.input-group-btn:last-child > .btn:not(:last-child):not(.dropdown-toggle),
.input-group-btn:last-child > .btn-group:not(:last-child) > .btn {
  border-bottom-right-radius: 0;
  border-top-right-radius: 0;
}
.input-group-addon:first-child {
  border-right: 0;
}
.input-group .form-control:last-child,
.input-group-addon:last-child,
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group > .btn,
.input-group-btn:last-child > .dropdown-toggle,
.input-group-btn:first-child > .btn:not(:first-child),
.input-group-btn:first-child > .btn-group:not(:first-child) > .btn {
  border-bottom-left-radius: 0;
  border-top-left-radius: 0;
}
.input-group-addon:last-child {
  border-left: 0;
}
.input-group-btn {
  position: relative;
  font-size: 0;
  white-space: nowrap;
}
.input-group-btn > .btn {
  position: relative;
}
.input-group-btn > .btn + .btn {
  margin-left: -1px;
}
.input-group-btn > .btn:hover,
.input-group-btn > .btn:focus,
.input-group-btn > .btn:active {
  z-index: 2;
}
.input-group-btn:first-child > .btn,
.input-group-btn:first-child > .btn-group {
  margin-right: -1px;
}
.input-group-btn:last-child > .btn,
.input-group-btn:last-child > .btn-group {
  z-index: 2;
  margin-left: -1px;
}
.nav {
  margin-bottom: 0;
  padding-left: 0;
  list-style: none;
}
.nav > li {
  position: relative;
  display: block;
}
.nav > li > a {
  position: relative;
  display: block;
  padding: 10px 15px;
}
.nav > li > a:hover,
.nav > li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.nav > li.disabled > a {
  color: #777777;
}
.nav > li.disabled > a:hover,
.nav > li.disabled > a:focus {
  color: #777777;
  text-decoration: none;
  background-color: transparent;
  cursor: not-allowed;
}
.nav .open > a,
.nav .open > a:hover,
.nav .open > a:focus {
  background-color: #eeeeee;
  border-color: #337ab7;
}
.nav .nav-divider {
  height: 1px;
  margin: 8px 0;
  overflow: hidden;
  background-color: #e5e5e5;
}
.nav > li > a > img {
  max-width: none;
}
.nav-tabs {
  border-bottom: 1px solid #ddd;
}
.nav-tabs > li {
  float: left;
  margin-bottom: -1px;
}
.nav-tabs > li > a {
  margin-right: 2px;
  line-height: 1.42857143;
  border: 1px solid transparent;
  border-radius: 2px 2px 0 0;
}
.nav-tabs > li > a:hover {
  border-color: #eeeeee #eeeeee #ddd;
}
.nav-tabs > li.active > a,
.nav-tabs > li.active > a:hover,
.nav-tabs > li.active > a:focus {
  color: #555555;
  background-color: #fff;
  border: 1px solid #ddd;
  border-bottom-color: transparent;
  cursor: default;
}
.nav-tabs.nav-justified {
  width: 100%;
  border-bottom: 0;
}
.nav-tabs.nav-justified > li {
  float: none;
}
.nav-tabs.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-tabs.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-tabs.nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs.nav-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs.nav-justified > .active > a,
.nav-tabs.nav-justified > .active > a:hover,
.nav-tabs.nav-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs.nav-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs.nav-justified > .active > a,
  .nav-tabs.nav-justified > .active > a:hover,
  .nav-tabs.nav-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.nav-pills > li {
  float: left;
}
.nav-pills > li > a {
  border-radius: 2px;
}
.nav-pills > li + li {
  margin-left: 2px;
}
.nav-pills > li.active > a,
.nav-pills > li.active > a:hover,
.nav-pills > li.active > a:focus {
  color: #fff;
  background-color: #337ab7;
}
.nav-stacked > li {
  float: none;
}
.nav-stacked > li + li {
  margin-top: 2px;
  margin-left: 0;
}
.nav-justified {
  width: 100%;
}
.nav-justified > li {
  float: none;
}
.nav-justified > li > a {
  text-align: center;
  margin-bottom: 5px;
}
.nav-justified > .dropdown .dropdown-menu {
  top: auto;
  left: auto;
}
@media (min-width: 768px) {
  .nav-justified > li {
    display: table-cell;
    width: 1%;
  }
  .nav-justified > li > a {
    margin-bottom: 0;
  }
}
.nav-tabs-justified {
  border-bottom: 0;
}
.nav-tabs-justified > li > a {
  margin-right: 0;
  border-radius: 2px;
}
.nav-tabs-justified > .active > a,
.nav-tabs-justified > .active > a:hover,
.nav-tabs-justified > .active > a:focus {
  border: 1px solid #ddd;
}
@media (min-width: 768px) {
  .nav-tabs-justified > li > a {
    border-bottom: 1px solid #ddd;
    border-radius: 2px 2px 0 0;
  }
  .nav-tabs-justified > .active > a,
  .nav-tabs-justified > .active > a:hover,
  .nav-tabs-justified > .active > a:focus {
    border-bottom-color: #fff;
  }
}
.tab-content > .tab-pane {
  display: none;
}
.tab-content > .active {
  display: block;
}
.nav-tabs .dropdown-menu {
  margin-top: -1px;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar {
  position: relative;
  min-height: 30px;
  margin-bottom: 18px;
  border: 1px solid transparent;
}
@media (min-width: 541px) {
  .navbar {
    border-radius: 2px;
  }
}
@media (min-width: 541px) {
  .navbar-header {
    float: left;
  }
}
.navbar-collapse {
  overflow-x: visible;
  padding-right: 0px;
  padding-left: 0px;
  border-top: 1px solid transparent;
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1);
  -webkit-overflow-scrolling: touch;
}
.navbar-collapse.in {
  overflow-y: auto;
}
@media (min-width: 541px) {
  .navbar-collapse {
    width: auto;
    border-top: 0;
    box-shadow: none;
  }
  .navbar-collapse.collapse {
    display: block !important;
    height: auto !important;
    padding-bottom: 0;
    overflow: visible !important;
  }
  .navbar-collapse.in {
    overflow-y: visible;
  }
  .navbar-fixed-top .navbar-collapse,
  .navbar-static-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    padding-left: 0;
    padding-right: 0;
  }
}
.navbar-fixed-top .navbar-collapse,
.navbar-fixed-bottom .navbar-collapse {
  max-height: 340px;
}
@media (max-device-width: 540px) and (orientation: landscape) {
  .navbar-fixed-top .navbar-collapse,
  .navbar-fixed-bottom .navbar-collapse {
    max-height: 200px;
  }
}
.container > .navbar-header,
.container-fluid > .navbar-header,
.container > .navbar-collapse,
.container-fluid > .navbar-collapse {
  margin-right: 0px;
  margin-left: 0px;
}
@media (min-width: 541px) {
  .container > .navbar-header,
  .container-fluid > .navbar-header,
  .container > .navbar-collapse,
  .container-fluid > .navbar-collapse {
    margin-right: 0;
    margin-left: 0;
  }
}
.navbar-static-top {
  z-index: 1000;
  border-width: 0 0 1px;
}
@media (min-width: 541px) {
  .navbar-static-top {
    border-radius: 0;
  }
}
.navbar-fixed-top,
.navbar-fixed-bottom {
  position: fixed;
  right: 0;
  left: 0;
  z-index: 1030;
}
@media (min-width: 541px) {
  .navbar-fixed-top,
  .navbar-fixed-bottom {
    border-radius: 0;
  }
}
.navbar-fixed-top {
  top: 0;
  border-width: 0 0 1px;
}
.navbar-fixed-bottom {
  bottom: 0;
  margin-bottom: 0;
  border-width: 1px 0 0;
}
.navbar-brand {
  float: left;
  padding: 6px 0px;
  font-size: 17px;
  line-height: 18px;
  height: 30px;
}
.navbar-brand:hover,
.navbar-brand:focus {
  text-decoration: none;
}
.navbar-brand > img {
  display: block;
}
@media (min-width: 541px) {
  .navbar > .container .navbar-brand,
  .navbar > .container-fluid .navbar-brand {
    margin-left: 0px;
  }
}
.navbar-toggle {
  position: relative;
  float: right;
  margin-right: 0px;
  padding: 9px 10px;
  margin-top: -2px;
  margin-bottom: -2px;
  background-color: transparent;
  background-image: none;
  border: 1px solid transparent;
  border-radius: 2px;
}
.navbar-toggle:focus {
  outline: 0;
}
.navbar-toggle .icon-bar {
  display: block;
  width: 22px;
  height: 2px;
  border-radius: 1px;
}
.navbar-toggle .icon-bar + .icon-bar {
  margin-top: 4px;
}
@media (min-width: 541px) {
  .navbar-toggle {
    display: none;
  }
}
.navbar-nav {
  margin: 3px 0px;
}
.navbar-nav > li > a {
  padding-top: 10px;
  padding-bottom: 10px;
  line-height: 18px;
}
@media (max-width: 540px) {
  .navbar-nav .open .dropdown-menu {
    position: static;
    float: none;
    width: auto;
    margin-top: 0;
    background-color: transparent;
    border: 0;
    box-shadow: none;
  }
  .navbar-nav .open .dropdown-menu > li > a,
  .navbar-nav .open .dropdown-menu .dropdown-header {
    padding: 5px 15px 5px 25px;
  }
  .navbar-nav .open .dropdown-menu > li > a {
    line-height: 18px;
  }
  .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-nav .open .dropdown-menu > li > a:focus {
    background-image: none;
  }
}
@media (min-width: 541px) {
  .navbar-nav {
    float: left;
    margin: 0;
  }
  .navbar-nav > li {
    float: left;
  }
  .navbar-nav > li > a {
    padding-top: 6px;
    padding-bottom: 6px;
  }
}
.navbar-form {
  margin-left: 0px;
  margin-right: 0px;
  padding: 10px 0px;
  border-top: 1px solid transparent;
  border-bottom: 1px solid transparent;
  -webkit-box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  box-shadow: inset 0 1px 0 rgba(255, 255, 255, 0.1), 0 1px 0 rgba(255, 255, 255, 0.1);
  margin-top: -1px;
  margin-bottom: -1px;
}
@media (min-width: 768px) {
  .navbar-form .form-group {
    display: inline-block;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .form-control {
    display: inline-block;
    width: auto;
    vertical-align: middle;
  }
  .navbar-form .form-control-static {
    display: inline-block;
  }
  .navbar-form .input-group {
    display: inline-table;
    vertical-align: middle;
  }
  .navbar-form .input-group .input-group-addon,
  .navbar-form .input-group .input-group-btn,
  .navbar-form .input-group .form-control {
    width: auto;
  }
  .navbar-form .input-group > .form-control {
    width: 100%;
  }
  .navbar-form .control-label {
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio,
  .navbar-form .checkbox {
    display: inline-block;
    margin-top: 0;
    margin-bottom: 0;
    vertical-align: middle;
  }
  .navbar-form .radio label,
  .navbar-form .checkbox label {
    padding-left: 0;
  }
  .navbar-form .radio input[type="radio"],
  .navbar-form .checkbox input[type="checkbox"] {
    position: relative;
    margin-left: 0;
  }
  .navbar-form .has-feedback .form-control-feedback {
    top: 0;
  }
}
@media (max-width: 540px) {
  .navbar-form .form-group {
    margin-bottom: 5px;
  }
  .navbar-form .form-group:last-child {
    margin-bottom: 0;
  }
}
@media (min-width: 541px) {
  .navbar-form {
    width: auto;
    border: 0;
    margin-left: 0;
    margin-right: 0;
    padding-top: 0;
    padding-bottom: 0;
    -webkit-box-shadow: none;
    box-shadow: none;
  }
}
.navbar-nav > li > .dropdown-menu {
  margin-top: 0;
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.navbar-fixed-bottom .navbar-nav > li > .dropdown-menu {
  margin-bottom: 0;
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
  border-bottom-right-radius: 0;
  border-bottom-left-radius: 0;
}
.navbar-btn {
  margin-top: -1px;
  margin-bottom: -1px;
}
.navbar-btn.btn-sm {
  margin-top: 0px;
  margin-bottom: 0px;
}
.navbar-btn.btn-xs {
  margin-top: 4px;
  margin-bottom: 4px;
}
.navbar-text {
  margin-top: 6px;
  margin-bottom: 6px;
}
@media (min-width: 541px) {
  .navbar-text {
    float: left;
    margin-left: 0px;
    margin-right: 0px;
  }
}
@media (min-width: 541px) {
  .navbar-left {
    float: left !important;
    float: left;
  }
  .navbar-right {
    float: right !important;
    float: right;
    margin-right: 0px;
  }
  .navbar-right ~ .navbar-right {
    margin-right: 0;
  }
}
.navbar-default {
  background-color: #f8f8f8;
  border-color: #e7e7e7;
}
.navbar-default .navbar-brand {
  color: #777;
}
.navbar-default .navbar-brand:hover,
.navbar-default .navbar-brand:focus {
  color: #5e5e5e;
  background-color: transparent;
}
.navbar-default .navbar-text {
  color: #777;
}
.navbar-default .navbar-nav > li > a {
  color: #777;
}
.navbar-default .navbar-nav > li > a:hover,
.navbar-default .navbar-nav > li > a:focus {
  color: #333;
  background-color: transparent;
}
.navbar-default .navbar-nav > .active > a,
.navbar-default .navbar-nav > .active > a:hover,
.navbar-default .navbar-nav > .active > a:focus {
  color: #555;
  background-color: #e7e7e7;
}
.navbar-default .navbar-nav > .disabled > a,
.navbar-default .navbar-nav > .disabled > a:hover,
.navbar-default .navbar-nav > .disabled > a:focus {
  color: #ccc;
  background-color: transparent;
}
.navbar-default .navbar-toggle {
  border-color: #ddd;
}
.navbar-default .navbar-toggle:hover,
.navbar-default .navbar-toggle:focus {
  background-color: #ddd;
}
.navbar-default .navbar-toggle .icon-bar {
  background-color: #888;
}
.navbar-default .navbar-collapse,
.navbar-default .navbar-form {
  border-color: #e7e7e7;
}
.navbar-default .navbar-nav > .open > a,
.navbar-default .navbar-nav > .open > a:hover,
.navbar-default .navbar-nav > .open > a:focus {
  background-color: #e7e7e7;
  color: #555;
}
@media (max-width: 540px) {
  .navbar-default .navbar-nav .open .dropdown-menu > li > a {
    color: #777;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #333;
    background-color: transparent;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #555;
    background-color: #e7e7e7;
  }
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-default .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #ccc;
    background-color: transparent;
  }
}
.navbar-default .navbar-link {
  color: #777;
}
.navbar-default .navbar-link:hover {
  color: #333;
}
.navbar-default .btn-link {
  color: #777;
}
.navbar-default .btn-link:hover,
.navbar-default .btn-link:focus {
  color: #333;
}
.navbar-default .btn-link[disabled]:hover,
fieldset[disabled] .navbar-default .btn-link:hover,
.navbar-default .btn-link[disabled]:focus,
fieldset[disabled] .navbar-default .btn-link:focus {
  color: #ccc;
}
.navbar-inverse {
  background-color: #222;
  border-color: #080808;
}
.navbar-inverse .navbar-brand {
  color: #9d9d9d;
}
.navbar-inverse .navbar-brand:hover,
.navbar-inverse .navbar-brand:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-text {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a {
  color: #9d9d9d;
}
.navbar-inverse .navbar-nav > li > a:hover,
.navbar-inverse .navbar-nav > li > a:focus {
  color: #fff;
  background-color: transparent;
}
.navbar-inverse .navbar-nav > .active > a,
.navbar-inverse .navbar-nav > .active > a:hover,
.navbar-inverse .navbar-nav > .active > a:focus {
  color: #fff;
  background-color: #080808;
}
.navbar-inverse .navbar-nav > .disabled > a,
.navbar-inverse .navbar-nav > .disabled > a:hover,
.navbar-inverse .navbar-nav > .disabled > a:focus {
  color: #444;
  background-color: transparent;
}
.navbar-inverse .navbar-toggle {
  border-color: #333;
}
.navbar-inverse .navbar-toggle:hover,
.navbar-inverse .navbar-toggle:focus {
  background-color: #333;
}
.navbar-inverse .navbar-toggle .icon-bar {
  background-color: #fff;
}
.navbar-inverse .navbar-collapse,
.navbar-inverse .navbar-form {
  border-color: #101010;
}
.navbar-inverse .navbar-nav > .open > a,
.navbar-inverse .navbar-nav > .open > a:hover,
.navbar-inverse .navbar-nav > .open > a:focus {
  background-color: #080808;
  color: #fff;
}
@media (max-width: 540px) {
  .navbar-inverse .navbar-nav .open .dropdown-menu > .dropdown-header {
    border-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu .divider {
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a {
    color: #9d9d9d;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > li > a:focus {
    color: #fff;
    background-color: transparent;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .active > a:focus {
    color: #fff;
    background-color: #080808;
  }
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:hover,
  .navbar-inverse .navbar-nav .open .dropdown-menu > .disabled > a:focus {
    color: #444;
    background-color: transparent;
  }
}
.navbar-inverse .navbar-link {
  color: #9d9d9d;
}
.navbar-inverse .navbar-link:hover {
  color: #fff;
}
.navbar-inverse .btn-link {
  color: #9d9d9d;
}
.navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link:focus {
  color: #fff;
}
.navbar-inverse .btn-link[disabled]:hover,
fieldset[disabled] .navbar-inverse .btn-link:hover,
.navbar-inverse .btn-link[disabled]:focus,
fieldset[disabled] .navbar-inverse .btn-link:focus {
  color: #444;
}
.breadcrumb {
  padding: 8px 15px;
  margin-bottom: 18px;
  list-style: none;
  background-color: #f5f5f5;
  border-radius: 2px;
}
.breadcrumb > li {
  display: inline-block;
}
.breadcrumb > li + li:before {
  content: "/\00a0";
  padding: 0 5px;
  color: #5e5e5e;
}
.breadcrumb > .active {
  color: #777777;
}
.pagination {
  display: inline-block;
  padding-left: 0;
  margin: 18px 0;
  border-radius: 2px;
}
.pagination > li {
  display: inline;
}
.pagination > li > a,
.pagination > li > span {
  position: relative;
  float: left;
  padding: 6px 12px;
  line-height: 1.42857143;
  text-decoration: none;
  color: #337ab7;
  background-color: #fff;
  border: 1px solid #ddd;
  margin-left: -1px;
}
.pagination > li:first-child > a,
.pagination > li:first-child > span {
  margin-left: 0;
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.pagination > li:last-child > a,
.pagination > li:last-child > span {
  border-bottom-right-radius: 2px;
  border-top-right-radius: 2px;
}
.pagination > li > a:hover,
.pagination > li > span:hover,
.pagination > li > a:focus,
.pagination > li > span:focus {
  z-index: 2;
  color: #23527c;
  background-color: #eeeeee;
  border-color: #ddd;
}
.pagination > .active > a,
.pagination > .active > span,
.pagination > .active > a:hover,
.pagination > .active > span:hover,
.pagination > .active > a:focus,
.pagination > .active > span:focus {
  z-index: 3;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
  cursor: default;
}
.pagination > .disabled > span,
.pagination > .disabled > span:hover,
.pagination > .disabled > span:focus,
.pagination > .disabled > a,
.pagination > .disabled > a:hover,
.pagination > .disabled > a:focus {
  color: #777777;
  background-color: #fff;
  border-color: #ddd;
  cursor: not-allowed;
}
.pagination-lg > li > a,
.pagination-lg > li > span {
  padding: 10px 16px;
  font-size: 17px;
  line-height: 1.3333333;
}
.pagination-lg > li:first-child > a,
.pagination-lg > li:first-child > span {
  border-bottom-left-radius: 3px;
  border-top-left-radius: 3px;
}
.pagination-lg > li:last-child > a,
.pagination-lg > li:last-child > span {
  border-bottom-right-radius: 3px;
  border-top-right-radius: 3px;
}
.pagination-sm > li > a,
.pagination-sm > li > span {
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
}
.pagination-sm > li:first-child > a,
.pagination-sm > li:first-child > span {
  border-bottom-left-radius: 1px;
  border-top-left-radius: 1px;
}
.pagination-sm > li:last-child > a,
.pagination-sm > li:last-child > span {
  border-bottom-right-radius: 1px;
  border-top-right-radius: 1px;
}
.pager {
  padding-left: 0;
  margin: 18px 0;
  list-style: none;
  text-align: center;
}
.pager li {
  display: inline;
}
.pager li > a,
.pager li > span {
  display: inline-block;
  padding: 5px 14px;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 15px;
}
.pager li > a:hover,
.pager li > a:focus {
  text-decoration: none;
  background-color: #eeeeee;
}
.pager .next > a,
.pager .next > span {
  float: right;
}
.pager .previous > a,
.pager .previous > span {
  float: left;
}
.pager .disabled > a,
.pager .disabled > a:hover,
.pager .disabled > a:focus,
.pager .disabled > span {
  color: #777777;
  background-color: #fff;
  cursor: not-allowed;
}
.label {
  display: inline;
  padding: .2em .6em .3em;
  font-size: 75%;
  font-weight: bold;
  line-height: 1;
  color: #fff;
  text-align: center;
  white-space: nowrap;
  vertical-align: baseline;
  border-radius: .25em;
}
a.label:hover,
a.label:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.label:empty {
  display: none;
}
.btn .label {
  position: relative;
  top: -1px;
}
.label-default {
  background-color: #777777;
}
.label-default[href]:hover,
.label-default[href]:focus {
  background-color: #5e5e5e;
}
.label-primary {
  background-color: #337ab7;
}
.label-primary[href]:hover,
.label-primary[href]:focus {
  background-color: #286090;
}
.label-success {
  background-color: #5cb85c;
}
.label-success[href]:hover,
.label-success[href]:focus {
  background-color: #449d44;
}
.label-info {
  background-color: #5bc0de;
}
.label-info[href]:hover,
.label-info[href]:focus {
  background-color: #31b0d5;
}
.label-warning {
  background-color: #f0ad4e;
}
.label-warning[href]:hover,
.label-warning[href]:focus {
  background-color: #ec971f;
}
.label-danger {
  background-color: #d9534f;
}
.label-danger[href]:hover,
.label-danger[href]:focus {
  background-color: #c9302c;
}
.badge {
  display: inline-block;
  min-width: 10px;
  padding: 3px 7px;
  font-size: 12px;
  font-weight: bold;
  color: #fff;
  line-height: 1;
  vertical-align: middle;
  white-space: nowrap;
  text-align: center;
  background-color: #777777;
  border-radius: 10px;
}
.badge:empty {
  display: none;
}
.btn .badge {
  position: relative;
  top: -1px;
}
.btn-xs .badge,
.btn-group-xs > .btn .badge {
  top: 0;
  padding: 1px 5px;
}
a.badge:hover,
a.badge:focus {
  color: #fff;
  text-decoration: none;
  cursor: pointer;
}
.list-group-item.active > .badge,
.nav-pills > .active > a > .badge {
  color: #337ab7;
  background-color: #fff;
}
.list-group-item > .badge {
  float: right;
}
.list-group-item > .badge + .badge {
  margin-right: 5px;
}
.nav-pills > li > a > .badge {
  margin-left: 3px;
}
.jumbotron {
  padding-top: 30px;
  padding-bottom: 30px;
  margin-bottom: 30px;
  color: inherit;
  background-color: #eeeeee;
}
.jumbotron h1,
.jumbotron .h1 {
  color: inherit;
}
.jumbotron p {
  margin-bottom: 15px;
  font-size: 20px;
  font-weight: 200;
}
.jumbotron > hr {
  border-top-color: #d5d5d5;
}
.container .jumbotron,
.container-fluid .jumbotron {
  border-radius: 3px;
  padding-left: 0px;
  padding-right: 0px;
}
.jumbotron .container {
  max-width: 100%;
}
@media screen and (min-width: 768px) {
  .jumbotron {
    padding-top: 48px;
    padding-bottom: 48px;
  }
  .container .jumbotron,
  .container-fluid .jumbotron {
    padding-left: 60px;
    padding-right: 60px;
  }
  .jumbotron h1,
  .jumbotron .h1 {
    font-size: 59px;
  }
}
.thumbnail {
  display: block;
  padding: 4px;
  margin-bottom: 18px;
  line-height: 1.42857143;
  background-color: #fff;
  border: 1px solid #ddd;
  border-radius: 2px;
  -webkit-transition: border 0.2s ease-in-out;
  -o-transition: border 0.2s ease-in-out;
  transition: border 0.2s ease-in-out;
}
.thumbnail > img,
.thumbnail a > img {
  margin-left: auto;
  margin-right: auto;
}
a.thumbnail:hover,
a.thumbnail:focus,
a.thumbnail.active {
  border-color: #337ab7;
}
.thumbnail .caption {
  padding: 9px;
  color: #000;
}
.alert {
  padding: 15px;
  margin-bottom: 18px;
  border: 1px solid transparent;
  border-radius: 2px;
}
.alert h4 {
  margin-top: 0;
  color: inherit;
}
.alert .alert-link {
  font-weight: bold;
}
.alert > p,
.alert > ul {
  margin-bottom: 0;
}
.alert > p + p {
  margin-top: 5px;
}
.alert-dismissable,
.alert-dismissible {
  padding-right: 35px;
}
.alert-dismissable .close,
.alert-dismissible .close {
  position: relative;
  top: -2px;
  right: -21px;
  color: inherit;
}
.alert-success {
  background-color: #dff0d8;
  border-color: #d6e9c6;
  color: #3c763d;
}
.alert-success hr {
  border-top-color: #c9e2b3;
}
.alert-success .alert-link {
  color: #2b542c;
}
.alert-info {
  background-color: #d9edf7;
  border-color: #bce8f1;
  color: #31708f;
}
.alert-info hr {
  border-top-color: #a6e1ec;
}
.alert-info .alert-link {
  color: #245269;
}
.alert-warning {
  background-color: #fcf8e3;
  border-color: #faebcc;
  color: #8a6d3b;
}
.alert-warning hr {
  border-top-color: #f7e1b5;
}
.alert-warning .alert-link {
  color: #66512c;
}
.alert-danger {
  background-color: #f2dede;
  border-color: #ebccd1;
  color: #a94442;
}
.alert-danger hr {
  border-top-color: #e4b9c0;
}
.alert-danger .alert-link {
  color: #843534;
}
@-webkit-keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
@keyframes progress-bar-stripes {
  from {
    background-position: 40px 0;
  }
  to {
    background-position: 0 0;
  }
}
.progress {
  overflow: hidden;
  height: 18px;
  margin-bottom: 18px;
  background-color: #f5f5f5;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
  box-shadow: inset 0 1px 2px rgba(0, 0, 0, 0.1);
}
.progress-bar {
  float: left;
  width: 0%;
  height: 100%;
  font-size: 12px;
  line-height: 18px;
  color: #fff;
  text-align: center;
  background-color: #337ab7;
  -webkit-box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  box-shadow: inset 0 -1px 0 rgba(0, 0, 0, 0.15);
  -webkit-transition: width 0.6s ease;
  -o-transition: width 0.6s ease;
  transition: width 0.6s ease;
}
.progress-striped .progress-bar,
.progress-bar-striped {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-size: 40px 40px;
}
.progress.active .progress-bar,
.progress-bar.active {
  -webkit-animation: progress-bar-stripes 2s linear infinite;
  -o-animation: progress-bar-stripes 2s linear infinite;
  animation: progress-bar-stripes 2s linear infinite;
}
.progress-bar-success {
  background-color: #5cb85c;
}
.progress-striped .progress-bar-success {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-info {
  background-color: #5bc0de;
}
.progress-striped .progress-bar-info {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-warning {
  background-color: #f0ad4e;
}
.progress-striped .progress-bar-warning {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.progress-bar-danger {
  background-color: #d9534f;
}
.progress-striped .progress-bar-danger {
  background-image: -webkit-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: -o-linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
  background-image: linear-gradient(45deg, rgba(255, 255, 255, 0.15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, 0.15) 50%, rgba(255, 255, 255, 0.15) 75%, transparent 75%, transparent);
}
.media {
  margin-top: 15px;
}
.media:first-child {
  margin-top: 0;
}
.media,
.media-body {
  zoom: 1;
  overflow: hidden;
}
.media-body {
  width: 10000px;
}
.media-object {
  display: block;
}
.media-object.img-thumbnail {
  max-width: none;
}
.media-right,
.media > .pull-right {
  padding-left: 10px;
}
.media-left,
.media > .pull-left {
  padding-right: 10px;
}
.media-left,
.media-right,
.media-body {
  display: table-cell;
  vertical-align: top;
}
.media-middle {
  vertical-align: middle;
}
.media-bottom {
  vertical-align: bottom;
}
.media-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.media-list {
  padding-left: 0;
  list-style: none;
}
.list-group {
  margin-bottom: 20px;
  padding-left: 0;
}
.list-group-item {
  position: relative;
  display: block;
  padding: 10px 15px;
  margin-bottom: -1px;
  background-color: #fff;
  border: 1px solid #ddd;
}
.list-group-item:first-child {
  border-top-right-radius: 2px;
  border-top-left-radius: 2px;
}
.list-group-item:last-child {
  margin-bottom: 0;
  border-bottom-right-radius: 2px;
  border-bottom-left-radius: 2px;
}
a.list-group-item,
button.list-group-item {
  color: #555;
}
a.list-group-item .list-group-item-heading,
button.list-group-item .list-group-item-heading {
  color: #333;
}
a.list-group-item:hover,
button.list-group-item:hover,
a.list-group-item:focus,
button.list-group-item:focus {
  text-decoration: none;
  color: #555;
  background-color: #f5f5f5;
}
button.list-group-item {
  width: 100%;
  text-align: left;
}
.list-group-item.disabled,
.list-group-item.disabled:hover,
.list-group-item.disabled:focus {
  background-color: #eeeeee;
  color: #777777;
  cursor: not-allowed;
}
.list-group-item.disabled .list-group-item-heading,
.list-group-item.disabled:hover .list-group-item-heading,
.list-group-item.disabled:focus .list-group-item-heading {
  color: inherit;
}
.list-group-item.disabled .list-group-item-text,
.list-group-item.disabled:hover .list-group-item-text,
.list-group-item.disabled:focus .list-group-item-text {
  color: #777777;
}
.list-group-item.active,
.list-group-item.active:hover,
.list-group-item.active:focus {
  z-index: 2;
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.list-group-item.active .list-group-item-heading,
.list-group-item.active:hover .list-group-item-heading,
.list-group-item.active:focus .list-group-item-heading,
.list-group-item.active .list-group-item-heading > small,
.list-group-item.active:hover .list-group-item-heading > small,
.list-group-item.active:focus .list-group-item-heading > small,
.list-group-item.active .list-group-item-heading > .small,
.list-group-item.active:hover .list-group-item-heading > .small,
.list-group-item.active:focus .list-group-item-heading > .small {
  color: inherit;
}
.list-group-item.active .list-group-item-text,
.list-group-item.active:hover .list-group-item-text,
.list-group-item.active:focus .list-group-item-text {
  color: #c7ddef;
}
.list-group-item-success {
  color: #3c763d;
  background-color: #dff0d8;
}
a.list-group-item-success,
button.list-group-item-success {
  color: #3c763d;
}
a.list-group-item-success .list-group-item-heading,
button.list-group-item-success .list-group-item-heading {
  color: inherit;
}
a.list-group-item-success:hover,
button.list-group-item-success:hover,
a.list-group-item-success:focus,
button.list-group-item-success:focus {
  color: #3c763d;
  background-color: #d0e9c6;
}
a.list-group-item-success.active,
button.list-group-item-success.active,
a.list-group-item-success.active:hover,
button.list-group-item-success.active:hover,
a.list-group-item-success.active:focus,
button.list-group-item-success.active:focus {
  color: #fff;
  background-color: #3c763d;
  border-color: #3c763d;
}
.list-group-item-info {
  color: #31708f;
  background-color: #d9edf7;
}
a.list-group-item-info,
button.list-group-item-info {
  color: #31708f;
}
a.list-group-item-info .list-group-item-heading,
button.list-group-item-info .list-group-item-heading {
  color: inherit;
}
a.list-group-item-info:hover,
button.list-group-item-info:hover,
a.list-group-item-info:focus,
button.list-group-item-info:focus {
  color: #31708f;
  background-color: #c4e3f3;
}
a.list-group-item-info.active,
button.list-group-item-info.active,
a.list-group-item-info.active:hover,
button.list-group-item-info.active:hover,
a.list-group-item-info.active:focus,
button.list-group-item-info.active:focus {
  color: #fff;
  background-color: #31708f;
  border-color: #31708f;
}
.list-group-item-warning {
  color: #8a6d3b;
  background-color: #fcf8e3;
}
a.list-group-item-warning,
button.list-group-item-warning {
  color: #8a6d3b;
}
a.list-group-item-warning .list-group-item-heading,
button.list-group-item-warning .list-group-item-heading {
  color: inherit;
}
a.list-group-item-warning:hover,
button.list-group-item-warning:hover,
a.list-group-item-warning:focus,
button.list-group-item-warning:focus {
  color: #8a6d3b;
  background-color: #faf2cc;
}
a.list-group-item-warning.active,
button.list-group-item-warning.active,
a.list-group-item-warning.active:hover,
button.list-group-item-warning.active:hover,
a.list-group-item-warning.active:focus,
button.list-group-item-warning.active:focus {
  color: #fff;
  background-color: #8a6d3b;
  border-color: #8a6d3b;
}
.list-group-item-danger {
  color: #a94442;
  background-color: #f2dede;
}
a.list-group-item-danger,
button.list-group-item-danger {
  color: #a94442;
}
a.list-group-item-danger .list-group-item-heading,
button.list-group-item-danger .list-group-item-heading {
  color: inherit;
}
a.list-group-item-danger:hover,
button.list-group-item-danger:hover,
a.list-group-item-danger:focus,
button.list-group-item-danger:focus {
  color: #a94442;
  background-color: #ebcccc;
}
a.list-group-item-danger.active,
button.list-group-item-danger.active,
a.list-group-item-danger.active:hover,
button.list-group-item-danger.active:hover,
a.list-group-item-danger.active:focus,
button.list-group-item-danger.active:focus {
  color: #fff;
  background-color: #a94442;
  border-color: #a94442;
}
.list-group-item-heading {
  margin-top: 0;
  margin-bottom: 5px;
}
.list-group-item-text {
  margin-bottom: 0;
  line-height: 1.3;
}
.panel {
  margin-bottom: 18px;
  background-color: #fff;
  border: 1px solid transparent;
  border-radius: 2px;
  -webkit-box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: 0 1px 1px rgba(0, 0, 0, 0.05);
}
.panel-body {
  padding: 15px;
}
.panel-heading {
  padding: 10px 15px;
  border-bottom: 1px solid transparent;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel-heading > .dropdown .dropdown-toggle {
  color: inherit;
}
.panel-title {
  margin-top: 0;
  margin-bottom: 0;
  font-size: 15px;
  color: inherit;
}
.panel-title > a,
.panel-title > small,
.panel-title > .small,
.panel-title > small > a,
.panel-title > .small > a {
  color: inherit;
}
.panel-footer {
  padding: 10px 15px;
  background-color: #f5f5f5;
  border-top: 1px solid #ddd;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .list-group,
.panel > .panel-collapse > .list-group {
  margin-bottom: 0;
}
.panel > .list-group .list-group-item,
.panel > .panel-collapse > .list-group .list-group-item {
  border-width: 1px 0;
  border-radius: 0;
}
.panel > .list-group:first-child .list-group-item:first-child,
.panel > .panel-collapse > .list-group:first-child .list-group-item:first-child {
  border-top: 0;
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .list-group:last-child .list-group-item:last-child,
.panel > .panel-collapse > .list-group:last-child .list-group-item:last-child {
  border-bottom: 0;
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .panel-heading + .panel-collapse > .list-group .list-group-item:first-child {
  border-top-right-radius: 0;
  border-top-left-radius: 0;
}
.panel-heading + .list-group .list-group-item:first-child {
  border-top-width: 0;
}
.list-group + .panel-footer {
  border-top-width: 0;
}
.panel > .table,
.panel > .table-responsive > .table,
.panel > .panel-collapse > .table {
  margin-bottom: 0;
}
.panel > .table caption,
.panel > .table-responsive > .table caption,
.panel > .panel-collapse > .table caption {
  padding-left: 15px;
  padding-right: 15px;
}
.panel > .table:first-child,
.panel > .table-responsive:first-child > .table:first-child {
  border-top-right-radius: 1px;
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child {
  border-top-left-radius: 1px;
  border-top-right-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:first-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:first-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:first-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:first-child {
  border-top-left-radius: 1px;
}
.panel > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child td:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child td:last-child,
.panel > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > thead:first-child > tr:first-child th:last-child,
.panel > .table:first-child > tbody:first-child > tr:first-child th:last-child,
.panel > .table-responsive:first-child > .table:first-child > tbody:first-child > tr:first-child th:last-child {
  border-top-right-radius: 1px;
}
.panel > .table:last-child,
.panel > .table-responsive:last-child > .table:last-child {
  border-bottom-right-radius: 1px;
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child {
  border-bottom-left-radius: 1px;
  border-bottom-right-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:first-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:first-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:first-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:first-child {
  border-bottom-left-radius: 1px;
}
.panel > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child td:last-child,
.panel > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tbody:last-child > tr:last-child th:last-child,
.panel > .table:last-child > tfoot:last-child > tr:last-child th:last-child,
.panel > .table-responsive:last-child > .table:last-child > tfoot:last-child > tr:last-child th:last-child {
  border-bottom-right-radius: 1px;
}
.panel > .panel-body + .table,
.panel > .panel-body + .table-responsive,
.panel > .table + .panel-body,
.panel > .table-responsive + .panel-body {
  border-top: 1px solid #ddd;
}
.panel > .table > tbody:first-child > tr:first-child th,
.panel > .table > tbody:first-child > tr:first-child td {
  border-top: 0;
}
.panel > .table-bordered,
.panel > .table-responsive > .table-bordered {
  border: 0;
}
.panel > .table-bordered > thead > tr > th:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:first-child,
.panel > .table-bordered > tbody > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:first-child,
.panel > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:first-child,
.panel > .table-bordered > thead > tr > td:first-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:first-child,
.panel > .table-bordered > tbody > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:first-child,
.panel > .table-bordered > tfoot > tr > td:first-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:first-child {
  border-left: 0;
}
.panel > .table-bordered > thead > tr > th:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > th:last-child,
.panel > .table-bordered > tbody > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > th:last-child,
.panel > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > th:last-child,
.panel > .table-bordered > thead > tr > td:last-child,
.panel > .table-responsive > .table-bordered > thead > tr > td:last-child,
.panel > .table-bordered > tbody > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tbody > tr > td:last-child,
.panel > .table-bordered > tfoot > tr > td:last-child,
.panel > .table-responsive > .table-bordered > tfoot > tr > td:last-child {
  border-right: 0;
}
.panel > .table-bordered > thead > tr:first-child > td,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > td,
.panel > .table-bordered > tbody > tr:first-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > td,
.panel > .table-bordered > thead > tr:first-child > th,
.panel > .table-responsive > .table-bordered > thead > tr:first-child > th,
.panel > .table-bordered > tbody > tr:first-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:first-child > th {
  border-bottom: 0;
}
.panel > .table-bordered > tbody > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > td,
.panel > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > td,
.panel > .table-bordered > tbody > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tbody > tr:last-child > th,
.panel > .table-bordered > tfoot > tr:last-child > th,
.panel > .table-responsive > .table-bordered > tfoot > tr:last-child > th {
  border-bottom: 0;
}
.panel > .table-responsive {
  border: 0;
  margin-bottom: 0;
}
.panel-group {
  margin-bottom: 18px;
}
.panel-group .panel {
  margin-bottom: 0;
  border-radius: 2px;
}
.panel-group .panel + .panel {
  margin-top: 5px;
}
.panel-group .panel-heading {
  border-bottom: 0;
}
.panel-group .panel-heading + .panel-collapse > .panel-body,
.panel-group .panel-heading + .panel-collapse > .list-group {
  border-top: 1px solid #ddd;
}
.panel-group .panel-footer {
  border-top: 0;
}
.panel-group .panel-footer + .panel-collapse .panel-body {
  border-bottom: 1px solid #ddd;
}
.panel-default {
  border-color: #ddd;
}
.panel-default > .panel-heading {
  color: #333333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.panel-default > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ddd;
}
.panel-default > .panel-heading .badge {
  color: #f5f5f5;
  background-color: #333333;
}
.panel-default > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ddd;
}
.panel-primary {
  border-color: #337ab7;
}
.panel-primary > .panel-heading {
  color: #fff;
  background-color: #337ab7;
  border-color: #337ab7;
}
.panel-primary > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #337ab7;
}
.panel-primary > .panel-heading .badge {
  color: #337ab7;
  background-color: #fff;
}
.panel-primary > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #337ab7;
}
.panel-success {
  border-color: #d6e9c6;
}
.panel-success > .panel-heading {
  color: #3c763d;
  background-color: #dff0d8;
  border-color: #d6e9c6;
}
.panel-success > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #d6e9c6;
}
.panel-success > .panel-heading .badge {
  color: #dff0d8;
  background-color: #3c763d;
}
.panel-success > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #d6e9c6;
}
.panel-info {
  border-color: #bce8f1;
}
.panel-info > .panel-heading {
  color: #31708f;
  background-color: #d9edf7;
  border-color: #bce8f1;
}
.panel-info > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #bce8f1;
}
.panel-info > .panel-heading .badge {
  color: #d9edf7;
  background-color: #31708f;
}
.panel-info > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #bce8f1;
}
.panel-warning {
  border-color: #faebcc;
}
.panel-warning > .panel-heading {
  color: #8a6d3b;
  background-color: #fcf8e3;
  border-color: #faebcc;
}
.panel-warning > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #faebcc;
}
.panel-warning > .panel-heading .badge {
  color: #fcf8e3;
  background-color: #8a6d3b;
}
.panel-warning > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #faebcc;
}
.panel-danger {
  border-color: #ebccd1;
}
.panel-danger > .panel-heading {
  color: #a94442;
  background-color: #f2dede;
  border-color: #ebccd1;
}
.panel-danger > .panel-heading + .panel-collapse > .panel-body {
  border-top-color: #ebccd1;
}
.panel-danger > .panel-heading .badge {
  color: #f2dede;
  background-color: #a94442;
}
.panel-danger > .panel-footer + .panel-collapse > .panel-body {
  border-bottom-color: #ebccd1;
}
.embed-responsive {
  position: relative;
  display: block;
  height: 0;
  padding: 0;
  overflow: hidden;
}
.embed-responsive .embed-responsive-item,
.embed-responsive iframe,
.embed-responsive embed,
.embed-responsive object,
.embed-responsive video {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  height: 100%;
  width: 100%;
  border: 0;
}
.embed-responsive-16by9 {
  padding-bottom: 56.25%;
}
.embed-responsive-4by3 {
  padding-bottom: 75%;
}
.well {
  min-height: 20px;
  padding: 19px;
  margin-bottom: 20px;
  background-color: #f5f5f5;
  border: 1px solid #e3e3e3;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.05);
}
.well blockquote {
  border-color: #ddd;
  border-color: rgba(0, 0, 0, 0.15);
}
.well-lg {
  padding: 24px;
  border-radius: 3px;
}
.well-sm {
  padding: 9px;
  border-radius: 1px;
}
.close {
  float: right;
  font-size: 19.5px;
  font-weight: bold;
  line-height: 1;
  color: #000;
  text-shadow: 0 1px 0 #fff;
  opacity: 0.2;
  filter: alpha(opacity=20);
}
.close:hover,
.close:focus {
  color: #000;
  text-decoration: none;
  cursor: pointer;
  opacity: 0.5;
  filter: alpha(opacity=50);
}
button.close {
  padding: 0;
  cursor: pointer;
  background: transparent;
  border: 0;
  -webkit-appearance: none;
}
.modal-open {
  overflow: hidden;
}
.modal {
  display: none;
  overflow: hidden;
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1050;
  -webkit-overflow-scrolling: touch;
  outline: 0;
}
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, -25%);
  -ms-transform: translate(0, -25%);
  -o-transform: translate(0, -25%);
  transform: translate(0, -25%);
  -webkit-transition: -webkit-transform 0.3s ease-out;
  -moz-transition: -moz-transform 0.3s ease-out;
  -o-transition: -o-transform 0.3s ease-out;
  transition: transform 0.3s ease-out;
}
.modal.in .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
.modal-open .modal {
  overflow-x: hidden;
  overflow-y: auto;
}
.modal-dialog {
  position: relative;
  width: auto;
  margin: 10px;
}
.modal-content {
  position: relative;
  background-color: #fff;
  border: 1px solid #999;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  box-shadow: 0 3px 9px rgba(0, 0, 0, 0.5);
  background-clip: padding-box;
  outline: 0;
}
.modal-backdrop {
  position: fixed;
  top: 0;
  right: 0;
  bottom: 0;
  left: 0;
  z-index: 1040;
  background-color: #000;
}
.modal-backdrop.fade {
  opacity: 0;
  filter: alpha(opacity=0);
}
.modal-backdrop.in {
  opacity: 0.5;
  filter: alpha(opacity=50);
}
.modal-header {
  padding: 15px;
  border-bottom: 1px solid #e5e5e5;
}
.modal-header .close {
  margin-top: -2px;
}
.modal-title {
  margin: 0;
  line-height: 1.42857143;
}
.modal-body {
  position: relative;
  padding: 15px;
}
.modal-footer {
  padding: 15px;
  text-align: right;
  border-top: 1px solid #e5e5e5;
}
.modal-footer .btn + .btn {
  margin-left: 5px;
  margin-bottom: 0;
}
.modal-footer .btn-group .btn + .btn {
  margin-left: -1px;
}
.modal-footer .btn-block + .btn-block {
  margin-left: 0;
}
.modal-scrollbar-measure {
  position: absolute;
  top: -9999px;
  width: 50px;
  height: 50px;
  overflow: scroll;
}
@media (min-width: 768px) {
  .modal-dialog {
    width: 600px;
    margin: 30px auto;
  }
  .modal-content {
    -webkit-box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.5);
  }
  .modal-sm {
    width: 300px;
  }
}
@media (min-width: 992px) {
  .modal-lg {
    width: 900px;
  }
}
.tooltip {
  position: absolute;
  z-index: 1070;
  display: block;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 12px;
  opacity: 0;
  filter: alpha(opacity=0);
}
.tooltip.in {
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.tooltip.top {
  margin-top: -3px;
  padding: 5px 0;
}
.tooltip.right {
  margin-left: 3px;
  padding: 0 5px;
}
.tooltip.bottom {
  margin-top: 3px;
  padding: 5px 0;
}
.tooltip.left {
  margin-left: -3px;
  padding: 0 5px;
}
.tooltip-inner {
  max-width: 200px;
  padding: 3px 8px;
  color: #fff;
  text-align: center;
  background-color: #000;
  border-radius: 2px;
}
.tooltip-arrow {
  position: absolute;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.tooltip.top .tooltip-arrow {
  bottom: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-left .tooltip-arrow {
  bottom: 0;
  right: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.top-right .tooltip-arrow {
  bottom: 0;
  left: 5px;
  margin-bottom: -5px;
  border-width: 5px 5px 0;
  border-top-color: #000;
}
.tooltip.right .tooltip-arrow {
  top: 50%;
  left: 0;
  margin-top: -5px;
  border-width: 5px 5px 5px 0;
  border-right-color: #000;
}
.tooltip.left .tooltip-arrow {
  top: 50%;
  right: 0;
  margin-top: -5px;
  border-width: 5px 0 5px 5px;
  border-left-color: #000;
}
.tooltip.bottom .tooltip-arrow {
  top: 0;
  left: 50%;
  margin-left: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-left .tooltip-arrow {
  top: 0;
  right: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.tooltip.bottom-right .tooltip-arrow {
  top: 0;
  left: 5px;
  margin-top: -5px;
  border-width: 0 5px 5px;
  border-bottom-color: #000;
}
.popover {
  position: absolute;
  top: 0;
  left: 0;
  z-index: 1060;
  display: none;
  max-width: 276px;
  padding: 1px;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-style: normal;
  font-weight: normal;
  letter-spacing: normal;
  line-break: auto;
  line-height: 1.42857143;
  text-align: left;
  text-align: start;
  text-decoration: none;
  text-shadow: none;
  text-transform: none;
  white-space: normal;
  word-break: normal;
  word-spacing: normal;
  word-wrap: normal;
  font-size: 13px;
  background-color: #fff;
  background-clip: padding-box;
  border: 1px solid #ccc;
  border: 1px solid rgba(0, 0, 0, 0.2);
  border-radius: 3px;
  -webkit-box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
  box-shadow: 0 5px 10px rgba(0, 0, 0, 0.2);
}
.popover.top {
  margin-top: -10px;
}
.popover.right {
  margin-left: 10px;
}
.popover.bottom {
  margin-top: 10px;
}
.popover.left {
  margin-left: -10px;
}
.popover-title {
  margin: 0;
  padding: 8px 14px;
  font-size: 13px;
  background-color: #f7f7f7;
  border-bottom: 1px solid #ebebeb;
  border-radius: 2px 2px 0 0;
}
.popover-content {
  padding: 9px 14px;
}
.popover > .arrow,
.popover > .arrow:after {
  position: absolute;
  display: block;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
}
.popover > .arrow {
  border-width: 11px;
}
.popover > .arrow:after {
  border-width: 10px;
  content: "";
}
.popover.top > .arrow {
  left: 50%;
  margin-left: -11px;
  border-bottom-width: 0;
  border-top-color: #999999;
  border-top-color: rgba(0, 0, 0, 0.25);
  bottom: -11px;
}
.popover.top > .arrow:after {
  content: " ";
  bottom: 1px;
  margin-left: -10px;
  border-bottom-width: 0;
  border-top-color: #fff;
}
.popover.right > .arrow {
  top: 50%;
  left: -11px;
  margin-top: -11px;
  border-left-width: 0;
  border-right-color: #999999;
  border-right-color: rgba(0, 0, 0, 0.25);
}
.popover.right > .arrow:after {
  content: " ";
  left: 1px;
  bottom: -10px;
  border-left-width: 0;
  border-right-color: #fff;
}
.popover.bottom > .arrow {
  left: 50%;
  margin-left: -11px;
  border-top-width: 0;
  border-bottom-color: #999999;
  border-bottom-color: rgba(0, 0, 0, 0.25);
  top: -11px;
}
.popover.bottom > .arrow:after {
  content: " ";
  top: 1px;
  margin-left: -10px;
  border-top-width: 0;
  border-bottom-color: #fff;
}
.popover.left > .arrow {
  top: 50%;
  right: -11px;
  margin-top: -11px;
  border-right-width: 0;
  border-left-color: #999999;
  border-left-color: rgba(0, 0, 0, 0.25);
}
.popover.left > .arrow:after {
  content: " ";
  right: 1px;
  border-right-width: 0;
  border-left-color: #fff;
  bottom: -10px;
}
.carousel {
  position: relative;
}
.carousel-inner {
  position: relative;
  overflow: hidden;
  width: 100%;
}
.carousel-inner > .item {
  display: none;
  position: relative;
  -webkit-transition: 0.6s ease-in-out left;
  -o-transition: 0.6s ease-in-out left;
  transition: 0.6s ease-in-out left;
}
.carousel-inner > .item > img,
.carousel-inner > .item > a > img {
  line-height: 1;
}
@media all and (transform-3d), (-webkit-transform-3d) {
  .carousel-inner > .item {
    -webkit-transition: -webkit-transform 0.6s ease-in-out;
    -moz-transition: -moz-transform 0.6s ease-in-out;
    -o-transition: -o-transform 0.6s ease-in-out;
    transition: transform 0.6s ease-in-out;
    -webkit-backface-visibility: hidden;
    -moz-backface-visibility: hidden;
    backface-visibility: hidden;
    -webkit-perspective: 1000px;
    -moz-perspective: 1000px;
    perspective: 1000px;
  }
  .carousel-inner > .item.next,
  .carousel-inner > .item.active.right {
    -webkit-transform: translate3d(100%, 0, 0);
    transform: translate3d(100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.prev,
  .carousel-inner > .item.active.left {
    -webkit-transform: translate3d(-100%, 0, 0);
    transform: translate3d(-100%, 0, 0);
    left: 0;
  }
  .carousel-inner > .item.next.left,
  .carousel-inner > .item.prev.right,
  .carousel-inner > .item.active {
    -webkit-transform: translate3d(0, 0, 0);
    transform: translate3d(0, 0, 0);
    left: 0;
  }
}
.carousel-inner > .active,
.carousel-inner > .next,
.carousel-inner > .prev {
  display: block;
}
.carousel-inner > .active {
  left: 0;
}
.carousel-inner > .next,
.carousel-inner > .prev {
  position: absolute;
  top: 0;
  width: 100%;
}
.carousel-inner > .next {
  left: 100%;
}
.carousel-inner > .prev {
  left: -100%;
}
.carousel-inner > .next.left,
.carousel-inner > .prev.right {
  left: 0;
}
.carousel-inner > .active.left {
  left: -100%;
}
.carousel-inner > .active.right {
  left: 100%;
}
.carousel-control {
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0;
  width: 15%;
  opacity: 0.5;
  filter: alpha(opacity=50);
  font-size: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
  background-color: rgba(0, 0, 0, 0);
}
.carousel-control.left {
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.5) 0%, rgba(0, 0, 0, 0.0001) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#80000000', endColorstr='#00000000', GradientType=1);
}
.carousel-control.right {
  left: auto;
  right: 0;
  background-image: -webkit-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: -o-linear-gradient(left, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-image: linear-gradient(to right, rgba(0, 0, 0, 0.0001) 0%, rgba(0, 0, 0, 0.5) 100%);
  background-repeat: repeat-x;
  filter: progid:DXImageTransform.Microsoft.gradient(startColorstr='#00000000', endColorstr='#80000000', GradientType=1);
}
.carousel-control:hover,
.carousel-control:focus {
  outline: 0;
  color: #fff;
  text-decoration: none;
  opacity: 0.9;
  filter: alpha(opacity=90);
}
.carousel-control .icon-prev,
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-left,
.carousel-control .glyphicon-chevron-right {
  position: absolute;
  top: 50%;
  margin-top: -10px;
  z-index: 5;
  display: inline-block;
}
.carousel-control .icon-prev,
.carousel-control .glyphicon-chevron-left {
  left: 50%;
  margin-left: -10px;
}
.carousel-control .icon-next,
.carousel-control .glyphicon-chevron-right {
  right: 50%;
  margin-right: -10px;
}
.carousel-control .icon-prev,
.carousel-control .icon-next {
  width: 20px;
  height: 20px;
  line-height: 1;
  font-family: serif;
}
.carousel-control .icon-prev:before {
  content: '\2039';
}
.carousel-control .icon-next:before {
  content: '\203a';
}
.carousel-indicators {
  position: absolute;
  bottom: 10px;
  left: 50%;
  z-index: 15;
  width: 60%;
  margin-left: -30%;
  padding-left: 0;
  list-style: none;
  text-align: center;
}
.carousel-indicators li {
  display: inline-block;
  width: 10px;
  height: 10px;
  margin: 1px;
  text-indent: -999px;
  border: 1px solid #fff;
  border-radius: 10px;
  cursor: pointer;
  background-color: #000 \9;
  background-color: rgba(0, 0, 0, 0);
}
.carousel-indicators .active {
  margin: 0;
  width: 12px;
  height: 12px;
  background-color: #fff;
}
.carousel-caption {
  position: absolute;
  left: 15%;
  right: 15%;
  bottom: 20px;
  z-index: 10;
  padding-top: 20px;
  padding-bottom: 20px;
  color: #fff;
  text-align: center;
  text-shadow: 0 1px 2px rgba(0, 0, 0, 0.6);
}
.carousel-caption .btn {
  text-shadow: none;
}
@media screen and (min-width: 768px) {
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-prev,
  .carousel-control .icon-next {
    width: 30px;
    height: 30px;
    margin-top: -10px;
    font-size: 30px;
  }
  .carousel-control .glyphicon-chevron-left,
  .carousel-control .icon-prev {
    margin-left: -10px;
  }
  .carousel-control .glyphicon-chevron-right,
  .carousel-control .icon-next {
    margin-right: -10px;
  }
  .carousel-caption {
    left: 20%;
    right: 20%;
    padding-bottom: 30px;
  }
  .carousel-indicators {
    bottom: 20px;
  }
}
.clearfix:before,
.clearfix:after,
.dl-horizontal dd:before,
.dl-horizontal dd:after,
.container:before,
.container:after,
.container-fluid:before,
.container-fluid:after,
.row:before,
.row:after,
.form-horizontal .form-group:before,
.form-horizontal .form-group:after,
.btn-toolbar:before,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:before,
.btn-group-vertical > .btn-group:after,
.nav:before,
.nav:after,
.navbar:before,
.navbar:after,
.navbar-header:before,
.navbar-header:after,
.navbar-collapse:before,
.navbar-collapse:after,
.pager:before,
.pager:after,
.panel-body:before,
.panel-body:after,
.modal-header:before,
.modal-header:after,
.modal-footer:before,
.modal-footer:after,
.item_buttons:before,
.item_buttons:after {
  content: " ";
  display: table;
}
.clearfix:after,
.dl-horizontal dd:after,
.container:after,
.container-fluid:after,
.row:after,
.form-horizontal .form-group:after,
.btn-toolbar:after,
.btn-group-vertical > .btn-group:after,
.nav:after,
.navbar:after,
.navbar-header:after,
.navbar-collapse:after,
.pager:after,
.panel-body:after,
.modal-header:after,
.modal-footer:after,
.item_buttons:after {
  clear: both;
}
.center-block {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.pull-right {
  float: right !important;
}
.pull-left {
  float: left !important;
}
.hide {
  display: none !important;
}
.show {
  display: block !important;
}
.invisible {
  visibility: hidden;
}
.text-hide {
  font: 0/0 a;
  color: transparent;
  text-shadow: none;
  background-color: transparent;
  border: 0;
}
.hidden {
  display: none !important;
}
.affix {
  position: fixed;
}
@-ms-viewport {
  width: device-width;
}
.visible-xs,
.visible-sm,
.visible-md,
.visible-lg {
  display: none !important;
}
.visible-xs-block,
.visible-xs-inline,
.visible-xs-inline-block,
.visible-sm-block,
.visible-sm-inline,
.visible-sm-inline-block,
.visible-md-block,
.visible-md-inline,
.visible-md-inline-block,
.visible-lg-block,
.visible-lg-inline,
.visible-lg-inline-block {
  display: none !important;
}
@media (max-width: 767px) {
  .visible-xs {
    display: block !important;
  }
  table.visible-xs {
    display: table !important;
  }
  tr.visible-xs {
    display: table-row !important;
  }
  th.visible-xs,
  td.visible-xs {
    display: table-cell !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-block {
    display: block !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline {
    display: inline !important;
  }
}
@media (max-width: 767px) {
  .visible-xs-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm {
    display: block !important;
  }
  table.visible-sm {
    display: table !important;
  }
  tr.visible-sm {
    display: table-row !important;
  }
  th.visible-sm,
  td.visible-sm {
    display: table-cell !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-block {
    display: block !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline {
    display: inline !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .visible-sm-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md {
    display: block !important;
  }
  table.visible-md {
    display: table !important;
  }
  tr.visible-md {
    display: table-row !important;
  }
  th.visible-md,
  td.visible-md {
    display: table-cell !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-block {
    display: block !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline {
    display: inline !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .visible-md-inline-block {
    display: inline-block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg {
    display: block !important;
  }
  table.visible-lg {
    display: table !important;
  }
  tr.visible-lg {
    display: table-row !important;
  }
  th.visible-lg,
  td.visible-lg {
    display: table-cell !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-block {
    display: block !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline {
    display: inline !important;
  }
}
@media (min-width: 1200px) {
  .visible-lg-inline-block {
    display: inline-block !important;
  }
}
@media (max-width: 767px) {
  .hidden-xs {
    display: none !important;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  .hidden-sm {
    display: none !important;
  }
}
@media (min-width: 992px) and (max-width: 1199px) {
  .hidden-md {
    display: none !important;
  }
}
@media (min-width: 1200px) {
  .hidden-lg {
    display: none !important;
  }
}
.visible-print {
  display: none !important;
}
@media print {
  .visible-print {
    display: block !important;
  }
  table.visible-print {
    display: table !important;
  }
  tr.visible-print {
    display: table-row !important;
  }
  th.visible-print,
  td.visible-print {
    display: table-cell !important;
  }
}
.visible-print-block {
  display: none !important;
}
@media print {
  .visible-print-block {
    display: block !important;
  }
}
.visible-print-inline {
  display: none !important;
}
@media print {
  .visible-print-inline {
    display: inline !important;
  }
}
.visible-print-inline-block {
  display: none !important;
}
@media print {
  .visible-print-inline-block {
    display: inline-block !important;
  }
}
@media print {
  .hidden-print {
    display: none !important;
  }
}
/*!
*
* Font Awesome
*
*/
/*!
 *  Font Awesome 4.7.0 by @davegandy - http://fontawesome.io - @fontawesome
 *  License - http://fontawesome.io/license (Font: SIL OFL 1.1, CSS: MIT License)
 */
/* FONT PATH
 * -------------------------- */
@font-face {
  font-family: 'FontAwesome';
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?v=4.7.0');
  src: url('../components/font-awesome/fonts/fontawesome-webfont.eot?#iefix&v=4.7.0') format('embedded-opentype'), url('../components/font-awesome/fonts/fontawesome-webfont.woff2?v=4.7.0') format('woff2'), url('../components/font-awesome/fonts/fontawesome-webfont.woff?v=4.7.0') format('woff'), url('../components/font-awesome/fonts/fontawesome-webfont.ttf?v=4.7.0') format('truetype'), url('../components/font-awesome/fonts/fontawesome-webfont.svg?v=4.7.0#fontawesomeregular') format('svg');
  font-weight: normal;
  font-style: normal;
}
.fa {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}
/* makes the font 33% larger relative to the icon container */
.fa-lg {
  font-size: 1.33333333em;
  line-height: 0.75em;
  vertical-align: -15%;
}
.fa-2x {
  font-size: 2em;
}
.fa-3x {
  font-size: 3em;
}
.fa-4x {
  font-size: 4em;
}
.fa-5x {
  font-size: 5em;
}
.fa-fw {
  width: 1.28571429em;
  text-align: center;
}
.fa-ul {
  padding-left: 0;
  margin-left: 2.14285714em;
  list-style-type: none;
}
.fa-ul > li {
  position: relative;
}
.fa-li {
  position: absolute;
  left: -2.14285714em;
  width: 2.14285714em;
  top: 0.14285714em;
  text-align: center;
}
.fa-li.fa-lg {
  left: -1.85714286em;
}
.fa-border {
  padding: .2em .25em .15em;
  border: solid 0.08em #eee;
  border-radius: .1em;
}
.fa-pull-left {
  float: left;
}
.fa-pull-right {
  float: right;
}
.fa.fa-pull-left {
  margin-right: .3em;
}
.fa.fa-pull-right {
  margin-left: .3em;
}
/* Deprecated as of 4.4.0 */
.pull-right {
  float: right;
}
.pull-left {
  float: left;
}
.fa.pull-left {
  margin-right: .3em;
}
.fa.pull-right {
  margin-left: .3em;
}
.fa-spin {
  -webkit-animation: fa-spin 2s infinite linear;
  animation: fa-spin 2s infinite linear;
}
.fa-pulse {
  -webkit-animation: fa-spin 1s infinite steps(8);
  animation: fa-spin 1s infinite steps(8);
}
@-webkit-keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
@keyframes fa-spin {
  0% {
    -webkit-transform: rotate(0deg);
    transform: rotate(0deg);
  }
  100% {
    -webkit-transform: rotate(359deg);
    transform: rotate(359deg);
  }
}
.fa-rotate-90 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=1)";
  -webkit-transform: rotate(90deg);
  -ms-transform: rotate(90deg);
  transform: rotate(90deg);
}
.fa-rotate-180 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2)";
  -webkit-transform: rotate(180deg);
  -ms-transform: rotate(180deg);
  transform: rotate(180deg);
}
.fa-rotate-270 {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=3)";
  -webkit-transform: rotate(270deg);
  -ms-transform: rotate(270deg);
  transform: rotate(270deg);
}
.fa-flip-horizontal {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=0, mirror=1)";
  -webkit-transform: scale(-1, 1);
  -ms-transform: scale(-1, 1);
  transform: scale(-1, 1);
}
.fa-flip-vertical {
  -ms-filter: "progid:DXImageTransform.Microsoft.BasicImage(rotation=2, mirror=1)";
  -webkit-transform: scale(1, -1);
  -ms-transform: scale(1, -1);
  transform: scale(1, -1);
}
:root .fa-rotate-90,
:root .fa-rotate-180,
:root .fa-rotate-270,
:root .fa-flip-horizontal,
:root .fa-flip-vertical {
  filter: none;
}
.fa-stack {
  position: relative;
  display: inline-block;
  width: 2em;
  height: 2em;
  line-height: 2em;
  vertical-align: middle;
}
.fa-stack-1x,
.fa-stack-2x {
  position: absolute;
  left: 0;
  width: 100%;
  text-align: center;
}
.fa-stack-1x {
  line-height: inherit;
}
.fa-stack-2x {
  font-size: 2em;
}
.fa-inverse {
  color: #fff;
}
/* Font Awesome uses the Unicode Private Use Area (PUA) to ensure screen
   readers do not read off random characters that represent icons */
.fa-glass:before {
  content: "\f000";
}
.fa-music:before {
  content: "\f001";
}
.fa-search:before {
  content: "\f002";
}
.fa-envelope-o:before {
  content: "\f003";
}
.fa-heart:before {
  content: "\f004";
}
.fa-star:before {
  content: "\f005";
}
.fa-star-o:before {
  content: "\f006";
}
.fa-user:before {
  content: "\f007";
}
.fa-film:before {
  content: "\f008";
}
.fa-th-large:before {
  content: "\f009";
}
.fa-th:before {
  content: "\f00a";
}
.fa-th-list:before {
  content: "\f00b";
}
.fa-check:before {
  content: "\f00c";
}
.fa-remove:before,
.fa-close:before,
.fa-times:before {
  content: "\f00d";
}
.fa-search-plus:before {
  content: "\f00e";
}
.fa-search-minus:before {
  content: "\f010";
}
.fa-power-off:before {
  content: "\f011";
}
.fa-signal:before {
  content: "\f012";
}
.fa-gear:before,
.fa-cog:before {
  content: "\f013";
}
.fa-trash-o:before {
  content: "\f014";
}
.fa-home:before {
  content: "\f015";
}
.fa-file-o:before {
  content: "\f016";
}
.fa-clock-o:before {
  content: "\f017";
}
.fa-road:before {
  content: "\f018";
}
.fa-download:before {
  content: "\f019";
}
.fa-arrow-circle-o-down:before {
  content: "\f01a";
}
.fa-arrow-circle-o-up:before {
  content: "\f01b";
}
.fa-inbox:before {
  content: "\f01c";
}
.fa-play-circle-o:before {
  content: "\f01d";
}
.fa-rotate-right:before,
.fa-repeat:before {
  content: "\f01e";
}
.fa-refresh:before {
  content: "\f021";
}
.fa-list-alt:before {
  content: "\f022";
}
.fa-lock:before {
  content: "\f023";
}
.fa-flag:before {
  content: "\f024";
}
.fa-headphones:before {
  content: "\f025";
}
.fa-volume-off:before {
  content: "\f026";
}
.fa-volume-down:before {
  content: "\f027";
}
.fa-volume-up:before {
  content: "\f028";
}
.fa-qrcode:before {
  content: "\f029";
}
.fa-barcode:before {
  content: "\f02a";
}
.fa-tag:before {
  content: "\f02b";
}
.fa-tags:before {
  content: "\f02c";
}
.fa-book:before {
  content: "\f02d";
}
.fa-bookmark:before {
  content: "\f02e";
}
.fa-print:before {
  content: "\f02f";
}
.fa-camera:before {
  content: "\f030";
}
.fa-font:before {
  content: "\f031";
}
.fa-bold:before {
  content: "\f032";
}
.fa-italic:before {
  content: "\f033";
}
.fa-text-height:before {
  content: "\f034";
}
.fa-text-width:before {
  content: "\f035";
}
.fa-align-left:before {
  content: "\f036";
}
.fa-align-center:before {
  content: "\f037";
}
.fa-align-right:before {
  content: "\f038";
}
.fa-align-justify:before {
  content: "\f039";
}
.fa-list:before {
  content: "\f03a";
}
.fa-dedent:before,
.fa-outdent:before {
  content: "\f03b";
}
.fa-indent:before {
  content: "\f03c";
}
.fa-video-camera:before {
  content: "\f03d";
}
.fa-photo:before,
.fa-image:before,
.fa-picture-o:before {
  content: "\f03e";
}
.fa-pencil:before {
  content: "\f040";
}
.fa-map-marker:before {
  content: "\f041";
}
.fa-adjust:before {
  content: "\f042";
}
.fa-tint:before {
  content: "\f043";
}
.fa-edit:before,
.fa-pencil-square-o:before {
  content: "\f044";
}
.fa-share-square-o:before {
  content: "\f045";
}
.fa-check-square-o:before {
  content: "\f046";
}
.fa-arrows:before {
  content: "\f047";
}
.fa-step-backward:before {
  content: "\f048";
}
.fa-fast-backward:before {
  content: "\f049";
}
.fa-backward:before {
  content: "\f04a";
}
.fa-play:before {
  content: "\f04b";
}
.fa-pause:before {
  content: "\f04c";
}
.fa-stop:before {
  content: "\f04d";
}
.fa-forward:before {
  content: "\f04e";
}
.fa-fast-forward:before {
  content: "\f050";
}
.fa-step-forward:before {
  content: "\f051";
}
.fa-eject:before {
  content: "\f052";
}
.fa-chevron-left:before {
  content: "\f053";
}
.fa-chevron-right:before {
  content: "\f054";
}
.fa-plus-circle:before {
  content: "\f055";
}
.fa-minus-circle:before {
  content: "\f056";
}
.fa-times-circle:before {
  content: "\f057";
}
.fa-check-circle:before {
  content: "\f058";
}
.fa-question-circle:before {
  content: "\f059";
}
.fa-info-circle:before {
  content: "\f05a";
}
.fa-crosshairs:before {
  content: "\f05b";
}
.fa-times-circle-o:before {
  content: "\f05c";
}
.fa-check-circle-o:before {
  content: "\f05d";
}
.fa-ban:before {
  content: "\f05e";
}
.fa-arrow-left:before {
  content: "\f060";
}
.fa-arrow-right:before {
  content: "\f061";
}
.fa-arrow-up:before {
  content: "\f062";
}
.fa-arrow-down:before {
  content: "\f063";
}
.fa-mail-forward:before,
.fa-share:before {
  content: "\f064";
}
.fa-expand:before {
  content: "\f065";
}
.fa-compress:before {
  content: "\f066";
}
.fa-plus:before {
  content: "\f067";
}
.fa-minus:before {
  content: "\f068";
}
.fa-asterisk:before {
  content: "\f069";
}
.fa-exclamation-circle:before {
  content: "\f06a";
}
.fa-gift:before {
  content: "\f06b";
}
.fa-leaf:before {
  content: "\f06c";
}
.fa-fire:before {
  content: "\f06d";
}
.fa-eye:before {
  content: "\f06e";
}
.fa-eye-slash:before {
  content: "\f070";
}
.fa-warning:before,
.fa-exclamation-triangle:before {
  content: "\f071";
}
.fa-plane:before {
  content: "\f072";
}
.fa-calendar:before {
  content: "\f073";
}
.fa-random:before {
  content: "\f074";
}
.fa-comment:before {
  content: "\f075";
}
.fa-magnet:before {
  content: "\f076";
}
.fa-chevron-up:before {
  content: "\f077";
}
.fa-chevron-down:before {
  content: "\f078";
}
.fa-retweet:before {
  content: "\f079";
}
.fa-shopping-cart:before {
  content: "\f07a";
}
.fa-folder:before {
  content: "\f07b";
}
.fa-folder-open:before {
  content: "\f07c";
}
.fa-arrows-v:before {
  content: "\f07d";
}
.fa-arrows-h:before {
  content: "\f07e";
}
.fa-bar-chart-o:before,
.fa-bar-chart:before {
  content: "\f080";
}
.fa-twitter-square:before {
  content: "\f081";
}
.fa-facebook-square:before {
  content: "\f082";
}
.fa-camera-retro:before {
  content: "\f083";
}
.fa-key:before {
  content: "\f084";
}
.fa-gears:before,
.fa-cogs:before {
  content: "\f085";
}
.fa-comments:before {
  content: "\f086";
}
.fa-thumbs-o-up:before {
  content: "\f087";
}
.fa-thumbs-o-down:before {
  content: "\f088";
}
.fa-star-half:before {
  content: "\f089";
}
.fa-heart-o:before {
  content: "\f08a";
}
.fa-sign-out:before {
  content: "\f08b";
}
.fa-linkedin-square:before {
  content: "\f08c";
}
.fa-thumb-tack:before {
  content: "\f08d";
}
.fa-external-link:before {
  content: "\f08e";
}
.fa-sign-in:before {
  content: "\f090";
}
.fa-trophy:before {
  content: "\f091";
}
.fa-github-square:before {
  content: "\f092";
}
.fa-upload:before {
  content: "\f093";
}
.fa-lemon-o:before {
  content: "\f094";
}
.fa-phone:before {
  content: "\f095";
}
.fa-square-o:before {
  content: "\f096";
}
.fa-bookmark-o:before {
  content: "\f097";
}
.fa-phone-square:before {
  content: "\f098";
}
.fa-twitter:before {
  content: "\f099";
}
.fa-facebook-f:before,
.fa-facebook:before {
  content: "\f09a";
}
.fa-github:before {
  content: "\f09b";
}
.fa-unlock:before {
  content: "\f09c";
}
.fa-credit-card:before {
  content: "\f09d";
}
.fa-feed:before,
.fa-rss:before {
  content: "\f09e";
}
.fa-hdd-o:before {
  content: "\f0a0";
}
.fa-bullhorn:before {
  content: "\f0a1";
}
.fa-bell:before {
  content: "\f0f3";
}
.fa-certificate:before {
  content: "\f0a3";
}
.fa-hand-o-right:before {
  content: "\f0a4";
}
.fa-hand-o-left:before {
  content: "\f0a5";
}
.fa-hand-o-up:before {
  content: "\f0a6";
}
.fa-hand-o-down:before {
  content: "\f0a7";
}
.fa-arrow-circle-left:before {
  content: "\f0a8";
}
.fa-arrow-circle-right:before {
  content: "\f0a9";
}
.fa-arrow-circle-up:before {
  content: "\f0aa";
}
.fa-arrow-circle-down:before {
  content: "\f0ab";
}
.fa-globe:before {
  content: "\f0ac";
}
.fa-wrench:before {
  content: "\f0ad";
}
.fa-tasks:before {
  content: "\f0ae";
}
.fa-filter:before {
  content: "\f0b0";
}
.fa-briefcase:before {
  content: "\f0b1";
}
.fa-arrows-alt:before {
  content: "\f0b2";
}
.fa-group:before,
.fa-users:before {
  content: "\f0c0";
}
.fa-chain:before,
.fa-link:before {
  content: "\f0c1";
}
.fa-cloud:before {
  content: "\f0c2";
}
.fa-flask:before {
  content: "\f0c3";
}
.fa-cut:before,
.fa-scissors:before {
  content: "\f0c4";
}
.fa-copy:before,
.fa-files-o:before {
  content: "\f0c5";
}
.fa-paperclip:before {
  content: "\f0c6";
}
.fa-save:before,
.fa-floppy-o:before {
  content: "\f0c7";
}
.fa-square:before {
  content: "\f0c8";
}
.fa-navicon:before,
.fa-reorder:before,
.fa-bars:before {
  content: "\f0c9";
}
.fa-list-ul:before {
  content: "\f0ca";
}
.fa-list-ol:before {
  content: "\f0cb";
}
.fa-strikethrough:before {
  content: "\f0cc";
}
.fa-underline:before {
  content: "\f0cd";
}
.fa-table:before {
  content: "\f0ce";
}
.fa-magic:before {
  content: "\f0d0";
}
.fa-truck:before {
  content: "\f0d1";
}
.fa-pinterest:before {
  content: "\f0d2";
}
.fa-pinterest-square:before {
  content: "\f0d3";
}
.fa-google-plus-square:before {
  content: "\f0d4";
}
.fa-google-plus:before {
  content: "\f0d5";
}
.fa-money:before {
  content: "\f0d6";
}
.fa-caret-down:before {
  content: "\f0d7";
}
.fa-caret-up:before {
  content: "\f0d8";
}
.fa-caret-left:before {
  content: "\f0d9";
}
.fa-caret-right:before {
  content: "\f0da";
}
.fa-columns:before {
  content: "\f0db";
}
.fa-unsorted:before,
.fa-sort:before {
  content: "\f0dc";
}
.fa-sort-down:before,
.fa-sort-desc:before {
  content: "\f0dd";
}
.fa-sort-up:before,
.fa-sort-asc:before {
  content: "\f0de";
}
.fa-envelope:before {
  content: "\f0e0";
}
.fa-linkedin:before {
  content: "\f0e1";
}
.fa-rotate-left:before,
.fa-undo:before {
  content: "\f0e2";
}
.fa-legal:before,
.fa-gavel:before {
  content: "\f0e3";
}
.fa-dashboard:before,
.fa-tachometer:before {
  content: "\f0e4";
}
.fa-comment-o:before {
  content: "\f0e5";
}
.fa-comments-o:before {
  content: "\f0e6";
}
.fa-flash:before,
.fa-bolt:before {
  content: "\f0e7";
}
.fa-sitemap:before {
  content: "\f0e8";
}
.fa-umbrella:before {
  content: "\f0e9";
}
.fa-paste:before,
.fa-clipboard:before {
  content: "\f0ea";
}
.fa-lightbulb-o:before {
  content: "\f0eb";
}
.fa-exchange:before {
  content: "\f0ec";
}
.fa-cloud-download:before {
  content: "\f0ed";
}
.fa-cloud-upload:before {
  content: "\f0ee";
}
.fa-user-md:before {
  content: "\f0f0";
}
.fa-stethoscope:before {
  content: "\f0f1";
}
.fa-suitcase:before {
  content: "\f0f2";
}
.fa-bell-o:before {
  content: "\f0a2";
}
.fa-coffee:before {
  content: "\f0f4";
}
.fa-cutlery:before {
  content: "\f0f5";
}
.fa-file-text-o:before {
  content: "\f0f6";
}
.fa-building-o:before {
  content: "\f0f7";
}
.fa-hospital-o:before {
  content: "\f0f8";
}
.fa-ambulance:before {
  content: "\f0f9";
}
.fa-medkit:before {
  content: "\f0fa";
}
.fa-fighter-jet:before {
  content: "\f0fb";
}
.fa-beer:before {
  content: "\f0fc";
}
.fa-h-square:before {
  content: "\f0fd";
}
.fa-plus-square:before {
  content: "\f0fe";
}
.fa-angle-double-left:before {
  content: "\f100";
}
.fa-angle-double-right:before {
  content: "\f101";
}
.fa-angle-double-up:before {
  content: "\f102";
}
.fa-angle-double-down:before {
  content: "\f103";
}
.fa-angle-left:before {
  content: "\f104";
}
.fa-angle-right:before {
  content: "\f105";
}
.fa-angle-up:before {
  content: "\f106";
}
.fa-angle-down:before {
  content: "\f107";
}
.fa-desktop:before {
  content: "\f108";
}
.fa-laptop:before {
  content: "\f109";
}
.fa-tablet:before {
  content: "\f10a";
}
.fa-mobile-phone:before,
.fa-mobile:before {
  content: "\f10b";
}
.fa-circle-o:before {
  content: "\f10c";
}
.fa-quote-left:before {
  content: "\f10d";
}
.fa-quote-right:before {
  content: "\f10e";
}
.fa-spinner:before {
  content: "\f110";
}
.fa-circle:before {
  content: "\f111";
}
.fa-mail-reply:before,
.fa-reply:before {
  content: "\f112";
}
.fa-github-alt:before {
  content: "\f113";
}
.fa-folder-o:before {
  content: "\f114";
}
.fa-folder-open-o:before {
  content: "\f115";
}
.fa-smile-o:before {
  content: "\f118";
}
.fa-frown-o:before {
  content: "\f119";
}
.fa-meh-o:before {
  content: "\f11a";
}
.fa-gamepad:before {
  content: "\f11b";
}
.fa-keyboard-o:before {
  content: "\f11c";
}
.fa-flag-o:before {
  content: "\f11d";
}
.fa-flag-checkered:before {
  content: "\f11e";
}
.fa-terminal:before {
  content: "\f120";
}
.fa-code:before {
  content: "\f121";
}
.fa-mail-reply-all:before,
.fa-reply-all:before {
  content: "\f122";
}
.fa-star-half-empty:before,
.fa-star-half-full:before,
.fa-star-half-o:before {
  content: "\f123";
}
.fa-location-arrow:before {
  content: "\f124";
}
.fa-crop:before {
  content: "\f125";
}
.fa-code-fork:before {
  content: "\f126";
}
.fa-unlink:before,
.fa-chain-broken:before {
  content: "\f127";
}
.fa-question:before {
  content: "\f128";
}
.fa-info:before {
  content: "\f129";
}
.fa-exclamation:before {
  content: "\f12a";
}
.fa-superscript:before {
  content: "\f12b";
}
.fa-subscript:before {
  content: "\f12c";
}
.fa-eraser:before {
  content: "\f12d";
}
.fa-puzzle-piece:before {
  content: "\f12e";
}
.fa-microphone:before {
  content: "\f130";
}
.fa-microphone-slash:before {
  content: "\f131";
}
.fa-shield:before {
  content: "\f132";
}
.fa-calendar-o:before {
  content: "\f133";
}
.fa-fire-extinguisher:before {
  content: "\f134";
}
.fa-rocket:before {
  content: "\f135";
}
.fa-maxcdn:before {
  content: "\f136";
}
.fa-chevron-circle-left:before {
  content: "\f137";
}
.fa-chevron-circle-right:before {
  content: "\f138";
}
.fa-chevron-circle-up:before {
  content: "\f139";
}
.fa-chevron-circle-down:before {
  content: "\f13a";
}
.fa-html5:before {
  content: "\f13b";
}
.fa-css3:before {
  content: "\f13c";
}
.fa-anchor:before {
  content: "\f13d";
}
.fa-unlock-alt:before {
  content: "\f13e";
}
.fa-bullseye:before {
  content: "\f140";
}
.fa-ellipsis-h:before {
  content: "\f141";
}
.fa-ellipsis-v:before {
  content: "\f142";
}
.fa-rss-square:before {
  content: "\f143";
}
.fa-play-circle:before {
  content: "\f144";
}
.fa-ticket:before {
  content: "\f145";
}
.fa-minus-square:before {
  content: "\f146";
}
.fa-minus-square-o:before {
  content: "\f147";
}
.fa-level-up:before {
  content: "\f148";
}
.fa-level-down:before {
  content: "\f149";
}
.fa-check-square:before {
  content: "\f14a";
}
.fa-pencil-square:before {
  content: "\f14b";
}
.fa-external-link-square:before {
  content: "\f14c";
}
.fa-share-square:before {
  content: "\f14d";
}
.fa-compass:before {
  content: "\f14e";
}
.fa-toggle-down:before,
.fa-caret-square-o-down:before {
  content: "\f150";
}
.fa-toggle-up:before,
.fa-caret-square-o-up:before {
  content: "\f151";
}
.fa-toggle-right:before,
.fa-caret-square-o-right:before {
  content: "\f152";
}
.fa-euro:before,
.fa-eur:before {
  content: "\f153";
}
.fa-gbp:before {
  content: "\f154";
}
.fa-dollar:before,
.fa-usd:before {
  content: "\f155";
}
.fa-rupee:before,
.fa-inr:before {
  content: "\f156";
}
.fa-cny:before,
.fa-rmb:before,
.fa-yen:before,
.fa-jpy:before {
  content: "\f157";
}
.fa-ruble:before,
.fa-rouble:before,
.fa-rub:before {
  content: "\f158";
}
.fa-won:before,
.fa-krw:before {
  content: "\f159";
}
.fa-bitcoin:before,
.fa-btc:before {
  content: "\f15a";
}
.fa-file:before {
  content: "\f15b";
}
.fa-file-text:before {
  content: "\f15c";
}
.fa-sort-alpha-asc:before {
  content: "\f15d";
}
.fa-sort-alpha-desc:before {
  content: "\f15e";
}
.fa-sort-amount-asc:before {
  content: "\f160";
}
.fa-sort-amount-desc:before {
  content: "\f161";
}
.fa-sort-numeric-asc:before {
  content: "\f162";
}
.fa-sort-numeric-desc:before {
  content: "\f163";
}
.fa-thumbs-up:before {
  content: "\f164";
}
.fa-thumbs-down:before {
  content: "\f165";
}
.fa-youtube-square:before {
  content: "\f166";
}
.fa-youtube:before {
  content: "\f167";
}
.fa-xing:before {
  content: "\f168";
}
.fa-xing-square:before {
  content: "\f169";
}
.fa-youtube-play:before {
  content: "\f16a";
}
.fa-dropbox:before {
  content: "\f16b";
}
.fa-stack-overflow:before {
  content: "\f16c";
}
.fa-instagram:before {
  content: "\f16d";
}
.fa-flickr:before {
  content: "\f16e";
}
.fa-adn:before {
  content: "\f170";
}
.fa-bitbucket:before {
  content: "\f171";
}
.fa-bitbucket-square:before {
  content: "\f172";
}
.fa-tumblr:before {
  content: "\f173";
}
.fa-tumblr-square:before {
  content: "\f174";
}
.fa-long-arrow-down:before {
  content: "\f175";
}
.fa-long-arrow-up:before {
  content: "\f176";
}
.fa-long-arrow-left:before {
  content: "\f177";
}
.fa-long-arrow-right:before {
  content: "\f178";
}
.fa-apple:before {
  content: "\f179";
}
.fa-windows:before {
  content: "\f17a";
}
.fa-android:before {
  content: "\f17b";
}
.fa-linux:before {
  content: "\f17c";
}
.fa-dribbble:before {
  content: "\f17d";
}
.fa-skype:before {
  content: "\f17e";
}
.fa-foursquare:before {
  content: "\f180";
}
.fa-trello:before {
  content: "\f181";
}
.fa-female:before {
  content: "\f182";
}
.fa-male:before {
  content: "\f183";
}
.fa-gittip:before,
.fa-gratipay:before {
  content: "\f184";
}
.fa-sun-o:before {
  content: "\f185";
}
.fa-moon-o:before {
  content: "\f186";
}
.fa-archive:before {
  content: "\f187";
}
.fa-bug:before {
  content: "\f188";
}
.fa-vk:before {
  content: "\f189";
}
.fa-weibo:before {
  content: "\f18a";
}
.fa-renren:before {
  content: "\f18b";
}
.fa-pagelines:before {
  content: "\f18c";
}
.fa-stack-exchange:before {
  content: "\f18d";
}
.fa-arrow-circle-o-right:before {
  content: "\f18e";
}
.fa-arrow-circle-o-left:before {
  content: "\f190";
}
.fa-toggle-left:before,
.fa-caret-square-o-left:before {
  content: "\f191";
}
.fa-dot-circle-o:before {
  content: "\f192";
}
.fa-wheelchair:before {
  content: "\f193";
}
.fa-vimeo-square:before {
  content: "\f194";
}
.fa-turkish-lira:before,
.fa-try:before {
  content: "\f195";
}
.fa-plus-square-o:before {
  content: "\f196";
}
.fa-space-shuttle:before {
  content: "\f197";
}
.fa-slack:before {
  content: "\f198";
}
.fa-envelope-square:before {
  content: "\f199";
}
.fa-wordpress:before {
  content: "\f19a";
}
.fa-openid:before {
  content: "\f19b";
}
.fa-institution:before,
.fa-bank:before,
.fa-university:before {
  content: "\f19c";
}
.fa-mortar-board:before,
.fa-graduation-cap:before {
  content: "\f19d";
}
.fa-yahoo:before {
  content: "\f19e";
}
.fa-google:before {
  content: "\f1a0";
}
.fa-reddit:before {
  content: "\f1a1";
}
.fa-reddit-square:before {
  content: "\f1a2";
}
.fa-stumbleupon-circle:before {
  content: "\f1a3";
}
.fa-stumbleupon:before {
  content: "\f1a4";
}
.fa-delicious:before {
  content: "\f1a5";
}
.fa-digg:before {
  content: "\f1a6";
}
.fa-pied-piper-pp:before {
  content: "\f1a7";
}
.fa-pied-piper-alt:before {
  content: "\f1a8";
}
.fa-drupal:before {
  content: "\f1a9";
}
.fa-joomla:before {
  content: "\f1aa";
}
.fa-language:before {
  content: "\f1ab";
}
.fa-fax:before {
  content: "\f1ac";
}
.fa-building:before {
  content: "\f1ad";
}
.fa-child:before {
  content: "\f1ae";
}
.fa-paw:before {
  content: "\f1b0";
}
.fa-spoon:before {
  content: "\f1b1";
}
.fa-cube:before {
  content: "\f1b2";
}
.fa-cubes:before {
  content: "\f1b3";
}
.fa-behance:before {
  content: "\f1b4";
}
.fa-behance-square:before {
  content: "\f1b5";
}
.fa-steam:before {
  content: "\f1b6";
}
.fa-steam-square:before {
  content: "\f1b7";
}
.fa-recycle:before {
  content: "\f1b8";
}
.fa-automobile:before,
.fa-car:before {
  content: "\f1b9";
}
.fa-cab:before,
.fa-taxi:before {
  content: "\f1ba";
}
.fa-tree:before {
  content: "\f1bb";
}
.fa-spotify:before {
  content: "\f1bc";
}
.fa-deviantart:before {
  content: "\f1bd";
}
.fa-soundcloud:before {
  content: "\f1be";
}
.fa-database:before {
  content: "\f1c0";
}
.fa-file-pdf-o:before {
  content: "\f1c1";
}
.fa-file-word-o:before {
  content: "\f1c2";
}
.fa-file-excel-o:before {
  content: "\f1c3";
}
.fa-file-powerpoint-o:before {
  content: "\f1c4";
}
.fa-file-photo-o:before,
.fa-file-picture-o:before,
.fa-file-image-o:before {
  content: "\f1c5";
}
.fa-file-zip-o:before,
.fa-file-archive-o:before {
  content: "\f1c6";
}
.fa-file-sound-o:before,
.fa-file-audio-o:before {
  content: "\f1c7";
}
.fa-file-movie-o:before,
.fa-file-video-o:before {
  content: "\f1c8";
}
.fa-file-code-o:before {
  content: "\f1c9";
}
.fa-vine:before {
  content: "\f1ca";
}
.fa-codepen:before {
  content: "\f1cb";
}
.fa-jsfiddle:before {
  content: "\f1cc";
}
.fa-life-bouy:before,
.fa-life-buoy:before,
.fa-life-saver:before,
.fa-support:before,
.fa-life-ring:before {
  content: "\f1cd";
}
.fa-circle-o-notch:before {
  content: "\f1ce";
}
.fa-ra:before,
.fa-resistance:before,
.fa-rebel:before {
  content: "\f1d0";
}
.fa-ge:before,
.fa-empire:before {
  content: "\f1d1";
}
.fa-git-square:before {
  content: "\f1d2";
}
.fa-git:before {
  content: "\f1d3";
}
.fa-y-combinator-square:before,
.fa-yc-square:before,
.fa-hacker-news:before {
  content: "\f1d4";
}
.fa-tencent-weibo:before {
  content: "\f1d5";
}
.fa-qq:before {
  content: "\f1d6";
}
.fa-wechat:before,
.fa-weixin:before {
  content: "\f1d7";
}
.fa-send:before,
.fa-paper-plane:before {
  content: "\f1d8";
}
.fa-send-o:before,
.fa-paper-plane-o:before {
  content: "\f1d9";
}
.fa-history:before {
  content: "\f1da";
}
.fa-circle-thin:before {
  content: "\f1db";
}
.fa-header:before {
  content: "\f1dc";
}
.fa-paragraph:before {
  content: "\f1dd";
}
.fa-sliders:before {
  content: "\f1de";
}
.fa-share-alt:before {
  content: "\f1e0";
}
.fa-share-alt-square:before {
  content: "\f1e1";
}
.fa-bomb:before {
  content: "\f1e2";
}
.fa-soccer-ball-o:before,
.fa-futbol-o:before {
  content: "\f1e3";
}
.fa-tty:before {
  content: "\f1e4";
}
.fa-binoculars:before {
  content: "\f1e5";
}
.fa-plug:before {
  content: "\f1e6";
}
.fa-slideshare:before {
  content: "\f1e7";
}
.fa-twitch:before {
  content: "\f1e8";
}
.fa-yelp:before {
  content: "\f1e9";
}
.fa-newspaper-o:before {
  content: "\f1ea";
}
.fa-wifi:before {
  content: "\f1eb";
}
.fa-calculator:before {
  content: "\f1ec";
}
.fa-paypal:before {
  content: "\f1ed";
}
.fa-google-wallet:before {
  content: "\f1ee";
}
.fa-cc-visa:before {
  content: "\f1f0";
}
.fa-cc-mastercard:before {
  content: "\f1f1";
}
.fa-cc-discover:before {
  content: "\f1f2";
}
.fa-cc-amex:before {
  content: "\f1f3";
}
.fa-cc-paypal:before {
  content: "\f1f4";
}
.fa-cc-stripe:before {
  content: "\f1f5";
}
.fa-bell-slash:before {
  content: "\f1f6";
}
.fa-bell-slash-o:before {
  content: "\f1f7";
}
.fa-trash:before {
  content: "\f1f8";
}
.fa-copyright:before {
  content: "\f1f9";
}
.fa-at:before {
  content: "\f1fa";
}
.fa-eyedropper:before {
  content: "\f1fb";
}
.fa-paint-brush:before {
  content: "\f1fc";
}
.fa-birthday-cake:before {
  content: "\f1fd";
}
.fa-area-chart:before {
  content: "\f1fe";
}
.fa-pie-chart:before {
  content: "\f200";
}
.fa-line-chart:before {
  content: "\f201";
}
.fa-lastfm:before {
  content: "\f202";
}
.fa-lastfm-square:before {
  content: "\f203";
}
.fa-toggle-off:before {
  content: "\f204";
}
.fa-toggle-on:before {
  content: "\f205";
}
.fa-bicycle:before {
  content: "\f206";
}
.fa-bus:before {
  content: "\f207";
}
.fa-ioxhost:before {
  content: "\f208";
}
.fa-angellist:before {
  content: "\f209";
}
.fa-cc:before {
  content: "\f20a";
}
.fa-shekel:before,
.fa-sheqel:before,
.fa-ils:before {
  content: "\f20b";
}
.fa-meanpath:before {
  content: "\f20c";
}
.fa-buysellads:before {
  content: "\f20d";
}
.fa-connectdevelop:before {
  content: "\f20e";
}
.fa-dashcube:before {
  content: "\f210";
}
.fa-forumbee:before {
  content: "\f211";
}
.fa-leanpub:before {
  content: "\f212";
}
.fa-sellsy:before {
  content: "\f213";
}
.fa-shirtsinbulk:before {
  content: "\f214";
}
.fa-simplybuilt:before {
  content: "\f215";
}
.fa-skyatlas:before {
  content: "\f216";
}
.fa-cart-plus:before {
  content: "\f217";
}
.fa-cart-arrow-down:before {
  content: "\f218";
}
.fa-diamond:before {
  content: "\f219";
}
.fa-ship:before {
  content: "\f21a";
}
.fa-user-secret:before {
  content: "\f21b";
}
.fa-motorcycle:before {
  content: "\f21c";
}
.fa-street-view:before {
  content: "\f21d";
}
.fa-heartbeat:before {
  content: "\f21e";
}
.fa-venus:before {
  content: "\f221";
}
.fa-mars:before {
  content: "\f222";
}
.fa-mercury:before {
  content: "\f223";
}
.fa-intersex:before,
.fa-transgender:before {
  content: "\f224";
}
.fa-transgender-alt:before {
  content: "\f225";
}
.fa-venus-double:before {
  content: "\f226";
}
.fa-mars-double:before {
  content: "\f227";
}
.fa-venus-mars:before {
  content: "\f228";
}
.fa-mars-stroke:before {
  content: "\f229";
}
.fa-mars-stroke-v:before {
  content: "\f22a";
}
.fa-mars-stroke-h:before {
  content: "\f22b";
}
.fa-neuter:before {
  content: "\f22c";
}
.fa-genderless:before {
  content: "\f22d";
}
.fa-facebook-official:before {
  content: "\f230";
}
.fa-pinterest-p:before {
  content: "\f231";
}
.fa-whatsapp:before {
  content: "\f232";
}
.fa-server:before {
  content: "\f233";
}
.fa-user-plus:before {
  content: "\f234";
}
.fa-user-times:before {
  content: "\f235";
}
.fa-hotel:before,
.fa-bed:before {
  content: "\f236";
}
.fa-viacoin:before {
  content: "\f237";
}
.fa-train:before {
  content: "\f238";
}
.fa-subway:before {
  content: "\f239";
}
.fa-medium:before {
  content: "\f23a";
}
.fa-yc:before,
.fa-y-combinator:before {
  content: "\f23b";
}
.fa-optin-monster:before {
  content: "\f23c";
}
.fa-opencart:before {
  content: "\f23d";
}
.fa-expeditedssl:before {
  content: "\f23e";
}
.fa-battery-4:before,
.fa-battery:before,
.fa-battery-full:before {
  content: "\f240";
}
.fa-battery-3:before,
.fa-battery-three-quarters:before {
  content: "\f241";
}
.fa-battery-2:before,
.fa-battery-half:before {
  content: "\f242";
}
.fa-battery-1:before,
.fa-battery-quarter:before {
  content: "\f243";
}
.fa-battery-0:before,
.fa-battery-empty:before {
  content: "\f244";
}
.fa-mouse-pointer:before {
  content: "\f245";
}
.fa-i-cursor:before {
  content: "\f246";
}
.fa-object-group:before {
  content: "\f247";
}
.fa-object-ungroup:before {
  content: "\f248";
}
.fa-sticky-note:before {
  content: "\f249";
}
.fa-sticky-note-o:before {
  content: "\f24a";
}
.fa-cc-jcb:before {
  content: "\f24b";
}
.fa-cc-diners-club:before {
  content: "\f24c";
}
.fa-clone:before {
  content: "\f24d";
}
.fa-balance-scale:before {
  content: "\f24e";
}
.fa-hourglass-o:before {
  content: "\f250";
}
.fa-hourglass-1:before,
.fa-hourglass-start:before {
  content: "\f251";
}
.fa-hourglass-2:before,
.fa-hourglass-half:before {
  content: "\f252";
}
.fa-hourglass-3:before,
.fa-hourglass-end:before {
  content: "\f253";
}
.fa-hourglass:before {
  content: "\f254";
}
.fa-hand-grab-o:before,
.fa-hand-rock-o:before {
  content: "\f255";
}
.fa-hand-stop-o:before,
.fa-hand-paper-o:before {
  content: "\f256";
}
.fa-hand-scissors-o:before {
  content: "\f257";
}
.fa-hand-lizard-o:before {
  content: "\f258";
}
.fa-hand-spock-o:before {
  content: "\f259";
}
.fa-hand-pointer-o:before {
  content: "\f25a";
}
.fa-hand-peace-o:before {
  content: "\f25b";
}
.fa-trademark:before {
  content: "\f25c";
}
.fa-registered:before {
  content: "\f25d";
}
.fa-creative-commons:before {
  content: "\f25e";
}
.fa-gg:before {
  content: "\f260";
}
.fa-gg-circle:before {
  content: "\f261";
}
.fa-tripadvisor:before {
  content: "\f262";
}
.fa-odnoklassniki:before {
  content: "\f263";
}
.fa-odnoklassniki-square:before {
  content: "\f264";
}
.fa-get-pocket:before {
  content: "\f265";
}
.fa-wikipedia-w:before {
  content: "\f266";
}
.fa-safari:before {
  content: "\f267";
}
.fa-chrome:before {
  content: "\f268";
}
.fa-firefox:before {
  content: "\f269";
}
.fa-opera:before {
  content: "\f26a";
}
.fa-internet-explorer:before {
  content: "\f26b";
}
.fa-tv:before,
.fa-television:before {
  content: "\f26c";
}
.fa-contao:before {
  content: "\f26d";
}
.fa-500px:before {
  content: "\f26e";
}
.fa-amazon:before {
  content: "\f270";
}
.fa-calendar-plus-o:before {
  content: "\f271";
}
.fa-calendar-minus-o:before {
  content: "\f272";
}
.fa-calendar-times-o:before {
  content: "\f273";
}
.fa-calendar-check-o:before {
  content: "\f274";
}
.fa-industry:before {
  content: "\f275";
}
.fa-map-pin:before {
  content: "\f276";
}
.fa-map-signs:before {
  content: "\f277";
}
.fa-map-o:before {
  content: "\f278";
}
.fa-map:before {
  content: "\f279";
}
.fa-commenting:before {
  content: "\f27a";
}
.fa-commenting-o:before {
  content: "\f27b";
}
.fa-houzz:before {
  content: "\f27c";
}
.fa-vimeo:before {
  content: "\f27d";
}
.fa-black-tie:before {
  content: "\f27e";
}
.fa-fonticons:before {
  content: "\f280";
}
.fa-reddit-alien:before {
  content: "\f281";
}
.fa-edge:before {
  content: "\f282";
}
.fa-credit-card-alt:before {
  content: "\f283";
}
.fa-codiepie:before {
  content: "\f284";
}
.fa-modx:before {
  content: "\f285";
}
.fa-fort-awesome:before {
  content: "\f286";
}
.fa-usb:before {
  content: "\f287";
}
.fa-product-hunt:before {
  content: "\f288";
}
.fa-mixcloud:before {
  content: "\f289";
}
.fa-scribd:before {
  content: "\f28a";
}
.fa-pause-circle:before {
  content: "\f28b";
}
.fa-pause-circle-o:before {
  content: "\f28c";
}
.fa-stop-circle:before {
  content: "\f28d";
}
.fa-stop-circle-o:before {
  content: "\f28e";
}
.fa-shopping-bag:before {
  content: "\f290";
}
.fa-shopping-basket:before {
  content: "\f291";
}
.fa-hashtag:before {
  content: "\f292";
}
.fa-bluetooth:before {
  content: "\f293";
}
.fa-bluetooth-b:before {
  content: "\f294";
}
.fa-percent:before {
  content: "\f295";
}
.fa-gitlab:before {
  content: "\f296";
}
.fa-wpbeginner:before {
  content: "\f297";
}
.fa-wpforms:before {
  content: "\f298";
}
.fa-envira:before {
  content: "\f299";
}
.fa-universal-access:before {
  content: "\f29a";
}
.fa-wheelchair-alt:before {
  content: "\f29b";
}
.fa-question-circle-o:before {
  content: "\f29c";
}
.fa-blind:before {
  content: "\f29d";
}
.fa-audio-description:before {
  content: "\f29e";
}
.fa-volume-control-phone:before {
  content: "\f2a0";
}
.fa-braille:before {
  content: "\f2a1";
}
.fa-assistive-listening-systems:before {
  content: "\f2a2";
}
.fa-asl-interpreting:before,
.fa-american-sign-language-interpreting:before {
  content: "\f2a3";
}
.fa-deafness:before,
.fa-hard-of-hearing:before,
.fa-deaf:before {
  content: "\f2a4";
}
.fa-glide:before {
  content: "\f2a5";
}
.fa-glide-g:before {
  content: "\f2a6";
}
.fa-signing:before,
.fa-sign-language:before {
  content: "\f2a7";
}
.fa-low-vision:before {
  content: "\f2a8";
}
.fa-viadeo:before {
  content: "\f2a9";
}
.fa-viadeo-square:before {
  content: "\f2aa";
}
.fa-snapchat:before {
  content: "\f2ab";
}
.fa-snapchat-ghost:before {
  content: "\f2ac";
}
.fa-snapchat-square:before {
  content: "\f2ad";
}
.fa-pied-piper:before {
  content: "\f2ae";
}
.fa-first-order:before {
  content: "\f2b0";
}
.fa-yoast:before {
  content: "\f2b1";
}
.fa-themeisle:before {
  content: "\f2b2";
}
.fa-google-plus-circle:before,
.fa-google-plus-official:before {
  content: "\f2b3";
}
.fa-fa:before,
.fa-font-awesome:before {
  content: "\f2b4";
}
.fa-handshake-o:before {
  content: "\f2b5";
}
.fa-envelope-open:before {
  content: "\f2b6";
}
.fa-envelope-open-o:before {
  content: "\f2b7";
}
.fa-linode:before {
  content: "\f2b8";
}
.fa-address-book:before {
  content: "\f2b9";
}
.fa-address-book-o:before {
  content: "\f2ba";
}
.fa-vcard:before,
.fa-address-card:before {
  content: "\f2bb";
}
.fa-vcard-o:before,
.fa-address-card-o:before {
  content: "\f2bc";
}
.fa-user-circle:before {
  content: "\f2bd";
}
.fa-user-circle-o:before {
  content: "\f2be";
}
.fa-user-o:before {
  content: "\f2c0";
}
.fa-id-badge:before {
  content: "\f2c1";
}
.fa-drivers-license:before,
.fa-id-card:before {
  content: "\f2c2";
}
.fa-drivers-license-o:before,
.fa-id-card-o:before {
  content: "\f2c3";
}
.fa-quora:before {
  content: "\f2c4";
}
.fa-free-code-camp:before {
  content: "\f2c5";
}
.fa-telegram:before {
  content: "\f2c6";
}
.fa-thermometer-4:before,
.fa-thermometer:before,
.fa-thermometer-full:before {
  content: "\f2c7";
}
.fa-thermometer-3:before,
.fa-thermometer-three-quarters:before {
  content: "\f2c8";
}
.fa-thermometer-2:before,
.fa-thermometer-half:before {
  content: "\f2c9";
}
.fa-thermometer-1:before,
.fa-thermometer-quarter:before {
  content: "\f2ca";
}
.fa-thermometer-0:before,
.fa-thermometer-empty:before {
  content: "\f2cb";
}
.fa-shower:before {
  content: "\f2cc";
}
.fa-bathtub:before,
.fa-s15:before,
.fa-bath:before {
  content: "\f2cd";
}
.fa-podcast:before {
  content: "\f2ce";
}
.fa-window-maximize:before {
  content: "\f2d0";
}
.fa-window-minimize:before {
  content: "\f2d1";
}
.fa-window-restore:before {
  content: "\f2d2";
}
.fa-times-rectangle:before,
.fa-window-close:before {
  content: "\f2d3";
}
.fa-times-rectangle-o:before,
.fa-window-close-o:before {
  content: "\f2d4";
}
.fa-bandcamp:before {
  content: "\f2d5";
}
.fa-grav:before {
  content: "\f2d6";
}
.fa-etsy:before {
  content: "\f2d7";
}
.fa-imdb:before {
  content: "\f2d8";
}
.fa-ravelry:before {
  content: "\f2d9";
}
.fa-eercast:before {
  content: "\f2da";
}
.fa-microchip:before {
  content: "\f2db";
}
.fa-snowflake-o:before {
  content: "\f2dc";
}
.fa-superpowers:before {
  content: "\f2dd";
}
.fa-wpexplorer:before {
  content: "\f2de";
}
.fa-meetup:before {
  content: "\f2e0";
}
.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  border: 0;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
.sr-only-focusable:active,
.sr-only-focusable:focus {
  position: static;
  width: auto;
  height: auto;
  margin: 0;
  overflow: visible;
  clip: auto;
}
/*!
*
* IPython base
*
*/
.modal.fade .modal-dialog {
  -webkit-transform: translate(0, 0);
  -ms-transform: translate(0, 0);
  -o-transform: translate(0, 0);
  transform: translate(0, 0);
}
code {
  color: #000;
}
pre {
  font-size: inherit;
  line-height: inherit;
}
label {
  font-weight: normal;
}
/* Make the page background atleast 100% the height of the view port */
/* Make the page itself atleast 70% the height of the view port */
.border-box-sizing {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.corner-all {
  border-radius: 2px;
}
.no-padding {
  padding: 0px;
}
/* Flexible box model classes */
/* Taken from Alex Russell http://infrequently.org/2009/08/css-3-progress/ */
/* This file is a compatability layer.  It allows the usage of flexible box 
model layouts accross multiple browsers, including older browsers.  The newest,
universal implementation of the flexible box model is used when available (see
`Modern browsers` comments below).  Browsers that are known to implement this 
new spec completely include:

    Firefox 28.0+
    Chrome 29.0+
    Internet Explorer 11+ 
    Opera 17.0+

Browsers not listed, including Safari, are supported via the styling under the
`Old browsers` comments below.
*/
.hbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
.hbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.vbox {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
.vbox > * {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
}
.hbox.reverse,
.vbox.reverse,
.reverse {
  /* Old browsers */
  -webkit-box-direction: reverse;
  -moz-box-direction: reverse;
  box-direction: reverse;
  /* Modern browsers */
  flex-direction: row-reverse;
}
.hbox.box-flex0,
.vbox.box-flex0,
.box-flex0 {
  /* Old browsers */
  -webkit-box-flex: 0;
  -moz-box-flex: 0;
  box-flex: 0;
  /* Modern browsers */
  flex: none;
  width: auto;
}
.hbox.box-flex1,
.vbox.box-flex1,
.box-flex1 {
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex,
.vbox.box-flex,
.box-flex {
  /* Old browsers */
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
.hbox.box-flex2,
.vbox.box-flex2,
.box-flex2 {
  /* Old browsers */
  -webkit-box-flex: 2;
  -moz-box-flex: 2;
  box-flex: 2;
  /* Modern browsers */
  flex: 2;
}
.box-group1 {
  /*  Deprecated */
  -webkit-box-flex-group: 1;
  -moz-box-flex-group: 1;
  box-flex-group: 1;
}
.box-group2 {
  /* Deprecated */
  -webkit-box-flex-group: 2;
  -moz-box-flex-group: 2;
  box-flex-group: 2;
}
.hbox.start,
.vbox.start,
.start {
  /* Old browsers */
  -webkit-box-pack: start;
  -moz-box-pack: start;
  box-pack: start;
  /* Modern browsers */
  justify-content: flex-start;
}
.hbox.end,
.vbox.end,
.end {
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
}
.hbox.center,
.vbox.center,
.center {
  /* Old browsers */
  -webkit-box-pack: center;
  -moz-box-pack: center;
  box-pack: center;
  /* Modern browsers */
  justify-content: center;
}
.hbox.baseline,
.vbox.baseline,
.baseline {
  /* Old browsers */
  -webkit-box-pack: baseline;
  -moz-box-pack: baseline;
  box-pack: baseline;
  /* Modern browsers */
  justify-content: baseline;
}
.hbox.stretch,
.vbox.stretch,
.stretch {
  /* Old browsers */
  -webkit-box-pack: stretch;
  -moz-box-pack: stretch;
  box-pack: stretch;
  /* Modern browsers */
  justify-content: stretch;
}
.hbox.align-start,
.vbox.align-start,
.align-start {
  /* Old browsers */
  -webkit-box-align: start;
  -moz-box-align: start;
  box-align: start;
  /* Modern browsers */
  align-items: flex-start;
}
.hbox.align-end,
.vbox.align-end,
.align-end {
  /* Old browsers */
  -webkit-box-align: end;
  -moz-box-align: end;
  box-align: end;
  /* Modern browsers */
  align-items: flex-end;
}
.hbox.align-center,
.vbox.align-center,
.align-center {
  /* Old browsers */
  -webkit-box-align: center;
  -moz-box-align: center;
  box-align: center;
  /* Modern browsers */
  align-items: center;
}
.hbox.align-baseline,
.vbox.align-baseline,
.align-baseline {
  /* Old browsers */
  -webkit-box-align: baseline;
  -moz-box-align: baseline;
  box-align: baseline;
  /* Modern browsers */
  align-items: baseline;
}
.hbox.align-stretch,
.vbox.align-stretch,
.align-stretch {
  /* Old browsers */
  -webkit-box-align: stretch;
  -moz-box-align: stretch;
  box-align: stretch;
  /* Modern browsers */
  align-items: stretch;
}
div.error {
  margin: 2em;
  text-align: center;
}
div.error > h1 {
  font-size: 500%;
  line-height: normal;
}
div.error > p {
  font-size: 200%;
  line-height: normal;
}
div.traceback-wrapper {
  text-align: left;
  max-width: 800px;
  margin: auto;
}
div.traceback-wrapper pre.traceback {
  max-height: 600px;
  overflow: auto;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
body {
  background-color: #fff;
  /* This makes sure that the body covers the entire window and needs to
       be in a different element than the display: box in wrapper below */
  position: absolute;
  left: 0px;
  right: 0px;
  top: 0px;
  bottom: 0px;
  overflow: visible;
}
body > #header {
  /* Initially hidden to prevent FLOUC */
  display: none;
  background-color: #fff;
  /* Display over codemirror */
  position: relative;
  z-index: 100;
}
body > #header #header-container {
  display: flex;
  flex-direction: row;
  justify-content: space-between;
  padding: 5px;
  padding-bottom: 5px;
  padding-top: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
body > #header .header-bar {
  width: 100%;
  height: 1px;
  background: #e7e7e7;
  margin-bottom: -1px;
}
@media print {
  body > #header {
    display: none !important;
  }
}
#header-spacer {
  width: 100%;
  visibility: hidden;
}
@media print {
  #header-spacer {
    display: none;
  }
}
#ipython_notebook {
  padding-left: 0px;
  padding-top: 1px;
  padding-bottom: 1px;
}
[dir="rtl"] #ipython_notebook {
  margin-right: 10px;
  margin-left: 0;
}
[dir="rtl"] #ipython_notebook.pull-left {
  float: right !important;
  float: right;
}
.flex-spacer {
  flex: 1;
}
#noscript {
  width: auto;
  padding-top: 16px;
  padding-bottom: 16px;
  text-align: center;
  font-size: 22px;
  color: red;
  font-weight: bold;
}
#ipython_notebook img {
  height: 28px;
}
#site {
  width: 100%;
  display: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  overflow: auto;
}
@media print {
  #site {
    height: auto !important;
  }
}
/* Smaller buttons */
.ui-button .ui-button-text {
  padding: 0.2em 0.8em;
  font-size: 77%;
}
input.ui-button {
  padding: 0.3em 0.9em;
}
span#kernel_logo_widget {
  margin: 0 10px;
}
span#login_widget {
  float: right;
}
[dir="rtl"] span#login_widget {
  float: left;
}
span#login_widget > .button,
#logout {
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button:focus,
#logout:focus,
span#login_widget > .button.focus,
#logout.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
span#login_widget > .button:hover,
#logout:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
span#login_widget > .button:active:hover,
#logout:active:hover,
span#login_widget > .button.active:hover,
#logout.active:hover,
.open > .dropdown-togglespan#login_widget > .button:hover,
.open > .dropdown-toggle#logout:hover,
span#login_widget > .button:active:focus,
#logout:active:focus,
span#login_widget > .button.active:focus,
#logout.active:focus,
.open > .dropdown-togglespan#login_widget > .button:focus,
.open > .dropdown-toggle#logout:focus,
span#login_widget > .button:active.focus,
#logout:active.focus,
span#login_widget > .button.active.focus,
#logout.active.focus,
.open > .dropdown-togglespan#login_widget > .button.focus,
.open > .dropdown-toggle#logout.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
span#login_widget > .button:active,
#logout:active,
span#login_widget > .button.active,
#logout.active,
.open > .dropdown-togglespan#login_widget > .button,
.open > .dropdown-toggle#logout {
  background-image: none;
}
span#login_widget > .button.disabled:hover,
#logout.disabled:hover,
span#login_widget > .button[disabled]:hover,
#logout[disabled]:hover,
fieldset[disabled] span#login_widget > .button:hover,
fieldset[disabled] #logout:hover,
span#login_widget > .button.disabled:focus,
#logout.disabled:focus,
span#login_widget > .button[disabled]:focus,
#logout[disabled]:focus,
fieldset[disabled] span#login_widget > .button:focus,
fieldset[disabled] #logout:focus,
span#login_widget > .button.disabled.focus,
#logout.disabled.focus,
span#login_widget > .button[disabled].focus,
#logout[disabled].focus,
fieldset[disabled] span#login_widget > .button.focus,
fieldset[disabled] #logout.focus {
  background-color: #fff;
  border-color: #ccc;
}
span#login_widget > .button .badge,
#logout .badge {
  color: #fff;
  background-color: #333;
}
.nav-header {
  text-transform: none;
}
#header > span {
  margin-top: 10px;
}
.modal_stretch .modal-dialog {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  min-height: 80vh;
}
.modal_stretch .modal-dialog .modal-body {
  max-height: calc(100vh - 200px);
  overflow: auto;
  flex: 1;
}
.modal-header {
  cursor: move;
}
@media (min-width: 768px) {
  .modal .modal-dialog {
    width: 700px;
  }
}
@media (min-width: 768px) {
  select.form-control {
    margin-left: 12px;
    margin-right: 12px;
  }
}
/*!
*
* IPython auth
*
*/
.center-nav {
  display: inline-block;
  margin-bottom: -4px;
}
[dir="rtl"] .center-nav form.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] .center-nav .navbar-text {
  float: right;
}
[dir="rtl"] .navbar-inner {
  text-align: right;
}
[dir="rtl"] div.text-left {
  text-align: right;
}
/*!
*
* IPython tree view
*
*/
/* We need an invisible input field on top of the sentense*/
/* "Drag file onto the list ..." */
.alternate_upload {
  background-color: none;
  display: inline;
}
.alternate_upload.form {
  padding: 0;
  margin: 0;
}
.alternate_upload input.fileinput {
  position: absolute;
  display: block;
  width: 100%;
  height: 100%;
  overflow: hidden;
  cursor: pointer;
  opacity: 0;
  z-index: 2;
}
.alternate_upload .btn-xs > input.fileinput {
  margin: -1px -5px;
}
.alternate_upload .btn-upload {
  position: relative;
  height: 22px;
}
::-webkit-file-upload-button {
  cursor: pointer;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
ul#tabs {
  margin-bottom: 4px;
}
ul#tabs a {
  padding-top: 6px;
  padding-bottom: 4px;
}
[dir="rtl"] ul#tabs.nav-tabs > li {
  float: right;
}
[dir="rtl"] ul#tabs.nav.nav-tabs {
  padding-right: 0;
}
ul.breadcrumb a:focus,
ul.breadcrumb a:hover {
  text-decoration: none;
}
ul.breadcrumb i.icon-home {
  font-size: 16px;
  margin-right: 4px;
}
ul.breadcrumb span {
  color: #5e5e5e;
}
.list_toolbar {
  padding: 4px 0 4px 0;
  vertical-align: middle;
}
.list_toolbar .tree-buttons {
  padding-top: 1px;
}
[dir="rtl"] .list_toolbar .tree-buttons .pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .list_toolbar .col-sm-4,
[dir="rtl"] .list_toolbar .col-sm-8 {
  float: right;
}
.dynamic-buttons {
  padding-top: 3px;
  display: inline-block;
}
.list_toolbar [class*="span"] {
  min-height: 24px;
}
.list_header {
  font-weight: bold;
  background-color: #EEE;
}
.list_placeholder {
  font-weight: bold;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
}
.list_container {
  margin-top: 4px;
  margin-bottom: 20px;
  border: 1px solid #ddd;
  border-radius: 2px;
}
.list_container > div {
  border-bottom: 1px solid #ddd;
}
.list_container > div:hover .list-item {
  background-color: red;
}
.list_container > div:last-child {
  border: none;
}
.list_item:hover .list_item {
  background-color: #ddd;
}
.list_item a {
  text-decoration: none;
}
.list_item:hover {
  background-color: #fafafa;
}
.list_header > div,
.list_item > div {
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
.list_header > div input,
.list_item > div input {
  margin-right: 7px;
  margin-left: 14px;
  vertical-align: text-bottom;
  line-height: 22px;
  position: relative;
  top: -1px;
}
.list_header > div .item_link,
.list_item > div .item_link {
  margin-left: -1px;
  vertical-align: baseline;
  line-height: 22px;
}
[dir="rtl"] .list_item > div input {
  margin-right: 0;
}
.new-file input[type=checkbox] {
  visibility: hidden;
}
.item_name {
  line-height: 22px;
  height: 24px;
}
.item_icon {
  font-size: 14px;
  color: #5e5e5e;
  margin-right: 7px;
  margin-left: 7px;
  line-height: 22px;
  vertical-align: baseline;
}
.item_modified {
  margin-right: 7px;
  margin-left: 7px;
}
[dir="rtl"] .item_modified.pull-right {
  float: left !important;
  float: left;
}
.item_buttons {
  line-height: 1em;
  margin-left: -5px;
}
.item_buttons .btn,
.item_buttons .btn-group,
.item_buttons .input-group {
  float: left;
}
.item_buttons > .btn,
.item_buttons > .btn-group,
.item_buttons > .input-group {
  margin-left: 5px;
}
.item_buttons .btn {
  min-width: 13ex;
}
.item_buttons .running-indicator {
  padding-top: 4px;
  color: #5cb85c;
}
.item_buttons .kernel-name {
  padding-top: 4px;
  color: #5bc0de;
  margin-right: 7px;
  float: left;
}
[dir="rtl"] .item_buttons.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .item_buttons .kernel-name {
  margin-left: 7px;
  float: right;
}
.toolbar_info {
  height: 24px;
  line-height: 24px;
}
.list_item input:not([type=checkbox]) {
  padding-top: 3px;
  padding-bottom: 3px;
  height: 22px;
  line-height: 14px;
  margin: 0px;
}
.highlight_text {
  color: blue;
}
#project_name {
  display: inline-block;
  padding-left: 7px;
  margin-left: -2px;
}
#project_name > .breadcrumb {
  padding: 0px;
  margin-bottom: 0px;
  background-color: transparent;
  font-weight: bold;
}
.sort_button {
  display: inline-block;
  padding-left: 7px;
}
[dir="rtl"] .sort_button.pull-right {
  float: left !important;
  float: left;
}
#tree-selector {
  padding-right: 0px;
}
#button-select-all {
  min-width: 50px;
}
[dir="rtl"] #button-select-all.btn {
  float: right ;
}
#select-all {
  margin-left: 7px;
  margin-right: 2px;
  margin-top: 2px;
  height: 16px;
}
[dir="rtl"] #select-all.pull-left {
  float: right !important;
  float: right;
}
.menu_icon {
  margin-right: 2px;
}
.tab-content .row {
  margin-left: 0px;
  margin-right: 0px;
}
.folder_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f114";
}
.folder_icon:before.fa-pull-left {
  margin-right: .3em;
}
.folder_icon:before.fa-pull-right {
  margin-left: .3em;
}
.folder_icon:before.pull-left {
  margin-right: .3em;
}
.folder_icon:before.pull-right {
  margin-left: .3em;
}
.notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
}
.notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.notebook_icon:before.pull-left {
  margin-right: .3em;
}
.notebook_icon:before.pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f02d";
  position: relative;
  top: -1px;
  color: #5cb85c;
}
.running_notebook_icon:before.fa-pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.fa-pull-right {
  margin-left: .3em;
}
.running_notebook_icon:before.pull-left {
  margin-right: .3em;
}
.running_notebook_icon:before.pull-right {
  margin-left: .3em;
}
.file_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f016";
  position: relative;
  top: -2px;
}
.file_icon:before.fa-pull-left {
  margin-right: .3em;
}
.file_icon:before.fa-pull-right {
  margin-left: .3em;
}
.file_icon:before.pull-left {
  margin-right: .3em;
}
.file_icon:before.pull-right {
  margin-left: .3em;
}
#notebook_toolbar .pull-right {
  padding-top: 0px;
  margin-right: -1px;
}
ul#new-menu {
  left: auto;
  right: 0;
}
#new-menu .dropdown-header {
  font-size: 10px;
  border-bottom: 1px solid #e5e5e5;
  padding: 0 0 3px;
  margin: -3px 20px 0;
}
.kernel-menu-icon {
  padding-right: 12px;
  width: 24px;
  content: "\f096";
}
.kernel-menu-icon:before {
  content: "\f096";
}
.kernel-menu-icon-current:before {
  content: "\f00c";
}
#tab_content {
  padding-top: 20px;
}
#running .panel-group .panel {
  margin-top: 3px;
  margin-bottom: 1em;
}
#running .panel-group .panel .panel-heading {
  background-color: #EEE;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 7px;
  padding-right: 7px;
  line-height: 22px;
}
#running .panel-group .panel .panel-heading a:focus,
#running .panel-group .panel .panel-heading a:hover {
  text-decoration: none;
}
#running .panel-group .panel .panel-body {
  padding: 0px;
}
#running .panel-group .panel .panel-body .list_container {
  margin-top: 0px;
  margin-bottom: 0px;
  border: 0px;
  border-radius: 0px;
}
#running .panel-group .panel .panel-body .list_container .list_item {
  border-bottom: 1px solid #ddd;
}
#running .panel-group .panel .panel-body .list_container .list_item:last-child {
  border-bottom: 0px;
}
.delete-button {
  display: none;
}
.duplicate-button {
  display: none;
}
.rename-button {
  display: none;
}
.move-button {
  display: none;
}
.download-button {
  display: none;
}
.shutdown-button {
  display: none;
}
.dynamic-instructions {
  display: inline-block;
  padding-top: 4px;
}
/*!
*
* IPython text editor webapp
*
*/
.selected-keymap i.fa {
  padding: 0px 5px;
}
.selected-keymap i.fa:before {
  content: "\f00c";
}
#mode-menu {
  overflow: auto;
  max-height: 20em;
}
.edit_app #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.edit_app #menubar .navbar {
  /* Use a negative 1 bottom margin, so the border overlaps the border of the
    header */
  margin-bottom: -1px;
}
.dirty-indicator {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator.pull-left {
  margin-right: .3em;
}
.dirty-indicator.pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-dirty.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-dirty.pull-left {
  margin-right: .3em;
}
.dirty-indicator-dirty.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  width: 20px;
}
.dirty-indicator-clean.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean.pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f00c";
}
.dirty-indicator-clean:before.fa-pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.fa-pull-right {
  margin-left: .3em;
}
.dirty-indicator-clean:before.pull-left {
  margin-right: .3em;
}
.dirty-indicator-clean:before.pull-right {
  margin-left: .3em;
}
#filename {
  font-size: 16pt;
  display: table;
  padding: 0px 5px;
}
#current-mode {
  padding-left: 5px;
  padding-right: 5px;
}
#texteditor-backdrop {
  padding-top: 20px;
  padding-bottom: 20px;
}
@media not print {
  #texteditor-backdrop {
    background-color: #EEE;
  }
}
@media print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container .CodeMirror-gutter,
  #texteditor-backdrop #texteditor-container .CodeMirror-gutters {
    background-color: #fff;
  }
}
@media not print {
  #texteditor-backdrop #texteditor-container {
    padding: 0px;
    background-color: #fff;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
.CodeMirror-dialog {
  background-color: #fff;
}
/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area .rendered_html table {
  margin-left: 0;
  margin-right: 0;
}
div.output_area .rendered_html img {
  margin-left: 0;
  margin-right: 0;
}
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}
.rendered_html em {
  font-style: italic;
}
.rendered_html strong {
  font-weight: bold;
}
.rendered_html u {
  text-decoration: underline;
}
.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}
.rendered_html h1 {
  font-size: 185.7%;
  margin: 1.08em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h2 {
  font-size: 157.1%;
  margin: 1.27em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h3 {
  font-size: 128.6%;
  margin: 1.55em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h4 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
}
.rendered_html h5 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h6 {
  font-size: 100%;
  margin: 2em 0 0 0;
  font-weight: bold;
  line-height: 1.0;
  font-style: italic;
}
.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}
.rendered_html ul {
  list-style: disc;
}
.rendered_html ul ul {
  list-style: square;
  margin-top: 0;
}
.rendered_html ul ul ul {
  list-style: circle;
}
.rendered_html ol {
  list-style: decimal;
}
.rendered_html ol ol {
  list-style: upper-alpha;
  margin-top: 0;
}
.rendered_html ol ol ol {
  list-style: lower-alpha;
}
.rendered_html ol ol ol ol {
  list-style: lower-roman;
}
.rendered_html ol ol ol ol ol {
  list-style: decimal;
}
.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}
.rendered_html hr {
  color: black;
  background-color: black;
}
.rendered_html pre {
  margin: 1em 2em;
  padding: 0px;
  background-color: #fff;
}
.rendered_html code {
  background-color: #eff0f1;
}
.rendered_html p code {
  padding: 1px 5px;
}
.rendered_html pre code {
  background-color: #fff;
}
.rendered_html pre,
.rendered_html code {
  border: 0;
  color: #000;
  font-size: 100%;
}
.rendered_html blockquote {
  margin: 1em 2em;
}
.rendered_html table {
  margin-left: auto;
  margin-right: auto;
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.rendered_html tr,
.rendered_html th,
.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.rendered_html th {
  font-weight: bold;
}
.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}
.rendered_html p {
  text-align: left;
}
.rendered_html * + p {
  margin-top: 1em;
}
.rendered_html img {
  display: block;
  margin-left: auto;
  margin-right: auto;
}
.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,
.rendered_html svg {
  max-width: 100%;
  height: auto;
}
.rendered_html img.unconfined,
.rendered_html svg.unconfined {
  max-width: none;
}
.rendered_html .alert {
  margin-bottom: initial;
}
.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] .rendered_html p {
  text-align: right;
}
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered .rendered_html {
  overflow-x: auto;
  overflow-y: hidden;
}
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered .rendered_html td {
  max-width: none;
}
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
/*!
*
* IPython notebook webapp
*
*/
@media (max-width: 767px) {
  .notebook_app {
    padding-left: 0px;
    padding-right: 0px;
  }
}
#ipython-main-app {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook_panel {
  margin: 0px;
  padding: 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  height: 100%;
}
div#notebook {
  font-size: 14px;
  line-height: 20px;
  overflow-y: hidden;
  overflow-x: auto;
  width: 100%;
  /* This spaces the page away from the edge of the notebook area */
  padding-top: 20px;
  margin: 0px;
  outline: none;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  min-height: 100%;
}
@media not print {
  #notebook-container {
    padding: 15px;
    background-color: #fff;
    min-height: 0;
    -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
    box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  }
}
@media print {
  #notebook-container {
    width: 100%;
  }
}
div.ui-widget-content {
  border: 1px solid #ababab;
  outline: none;
}
pre.dialog {
  background-color: #f7f7f7;
  border: 1px solid #ddd;
  border-radius: 2px;
  padding: 0.4em;
  padding-left: 2em;
}
p.dialog {
  padding: 0.2em;
}
/* Word-wrap output correctly.  This is the CSS3 spelling, though Firefox seems
   to not honor it correctly.  Webkit browsers (Chrome, rekonq, Safari) do.
 */
pre,
code,
kbd,
samp {
  white-space: pre-wrap;
}
#fonttest {
  font-family: monospace;
}
p {
  margin-bottom: 0;
}
.end_space {
  min-height: 100px;
  transition: height .2s ease;
}
.notebook_app > #header {
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
@media not print {
  .notebook_app {
    background-color: #EEE;
  }
}
kbd {
  border-style: solid;
  border-width: 1px;
  box-shadow: none;
  margin: 2px;
  padding-left: 2px;
  padding-right: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
.jupyter-keybindings {
  padding: 1px;
  line-height: 24px;
  border-bottom: 1px solid gray;
}
.jupyter-keybindings input {
  margin: 0;
  padding: 0;
  border: none;
}
.jupyter-keybindings i {
  padding: 6px;
}
.well code {
  background-color: #ffffff;
  border-color: #ababab;
  border-width: 1px;
  border-style: solid;
  padding: 2px;
  padding-top: 1px;
  padding-bottom: 1px;
}
/* CSS for the cell toolbar */
.celltoolbar {
  border: thin solid #CFCFCF;
  border-bottom: none;
  background: #EEE;
  border-radius: 2px 2px 0px 0px;
  width: 100%;
  height: 29px;
  padding-right: 4px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-pack: end;
  -moz-box-pack: end;
  box-pack: end;
  /* Modern browsers */
  justify-content: flex-end;
  display: -webkit-flex;
}
@media print {
  .celltoolbar {
    display: none;
  }
}
.ctb_hideshow {
  display: none;
  vertical-align: bottom;
}
/* ctb_show is added to the ctb_hideshow div to show the cell toolbar.
   Cell toolbars are only shown when the ctb_global_show class is also set.
*/
.ctb_global_show .ctb_show.ctb_hideshow {
  display: block;
}
.ctb_global_show .ctb_show + .input_area,
.ctb_global_show .ctb_show + div.text_cell_input,
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border-top-right-radius: 0px;
  border-top-left-radius: 0px;
}
.ctb_global_show .ctb_show ~ div.text_cell_render {
  border: 1px solid #cfcfcf;
}
.celltoolbar {
  font-size: 87%;
  padding-top: 3px;
}
.celltoolbar select {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  width: inherit;
  font-size: inherit;
  height: 22px;
  padding: 0px;
  display: inline-block;
}
.celltoolbar select:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.celltoolbar select::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.celltoolbar select:-ms-input-placeholder {
  color: #999;
}
.celltoolbar select::-webkit-input-placeholder {
  color: #999;
}
.celltoolbar select::-ms-expand {
  border: 0;
  background-color: transparent;
}
.celltoolbar select[disabled],
.celltoolbar select[readonly],
fieldset[disabled] .celltoolbar select {
  background-color: #eeeeee;
  opacity: 1;
}
.celltoolbar select[disabled],
fieldset[disabled] .celltoolbar select {
  cursor: not-allowed;
}
textarea.celltoolbar select {
  height: auto;
}
select.celltoolbar select {
  height: 30px;
  line-height: 30px;
}
textarea.celltoolbar select,
select[multiple].celltoolbar select {
  height: auto;
}
.celltoolbar label {
  margin-left: 5px;
  margin-right: 5px;
}
.tags_button_container {
  width: 100%;
  display: flex;
}
.tag-container {
  display: flex;
  flex-direction: row;
  flex-grow: 1;
  overflow: hidden;
  position: relative;
}
.tag-container > * {
  margin: 0 4px;
}
.remove-tag-btn {
  margin-left: 4px;
}
.tags-input {
  display: flex;
}
.cell-tag:last-child:after {
  content: "";
  position: absolute;
  right: 0;
  width: 40px;
  height: 100%;
  /* Fade to background color of cell toolbar */
  background: linear-gradient(to right, rgba(0, 0, 0, 0), #EEE);
}
.tags-input > * {
  margin-left: 4px;
}
.cell-tag,
.tags-input input,
.tags-input button {
  display: block;
  width: 100%;
  height: 32px;
  padding: 6px 12px;
  font-size: 13px;
  line-height: 1.42857143;
  color: #555555;
  background-color: #fff;
  background-image: none;
  border: 1px solid #ccc;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  box-shadow: inset 0 1px 1px rgba(0, 0, 0, 0.075);
  -webkit-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  -o-transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  transition: border-color ease-in-out .15s, box-shadow ease-in-out .15s;
  height: 30px;
  padding: 5px 10px;
  font-size: 12px;
  line-height: 1.5;
  border-radius: 1px;
  box-shadow: none;
  width: inherit;
  font-size: inherit;
  height: 22px;
  line-height: 22px;
  padding: 0px 4px;
  display: inline-block;
}
.cell-tag:focus,
.tags-input input:focus,
.tags-input button:focus {
  border-color: #66afe9;
  outline: 0;
  -webkit-box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
  box-shadow: inset 0 1px 1px rgba(0,0,0,.075), 0 0 8px rgba(102, 175, 233, 0.6);
}
.cell-tag::-moz-placeholder,
.tags-input input::-moz-placeholder,
.tags-input button::-moz-placeholder {
  color: #999;
  opacity: 1;
}
.cell-tag:-ms-input-placeholder,
.tags-input input:-ms-input-placeholder,
.tags-input button:-ms-input-placeholder {
  color: #999;
}
.cell-tag::-webkit-input-placeholder,
.tags-input input::-webkit-input-placeholder,
.tags-input button::-webkit-input-placeholder {
  color: #999;
}
.cell-tag::-ms-expand,
.tags-input input::-ms-expand,
.tags-input button::-ms-expand {
  border: 0;
  background-color: transparent;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
.cell-tag[readonly],
.tags-input input[readonly],
.tags-input button[readonly],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  background-color: #eeeeee;
  opacity: 1;
}
.cell-tag[disabled],
.tags-input input[disabled],
.tags-input button[disabled],
fieldset[disabled] .cell-tag,
fieldset[disabled] .tags-input input,
fieldset[disabled] .tags-input button {
  cursor: not-allowed;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button {
  height: auto;
}
select.cell-tag,
select.tags-input input,
select.tags-input button {
  height: 30px;
  line-height: 30px;
}
textarea.cell-tag,
textarea.tags-input input,
textarea.tags-input button,
select[multiple].cell-tag,
select[multiple].tags-input input,
select[multiple].tags-input button {
  height: auto;
}
.cell-tag,
.tags-input button {
  padding: 0px 4px;
}
.cell-tag {
  background-color: #fff;
  white-space: nowrap;
}
.tags-input input[type=text]:focus {
  outline: none;
  box-shadow: none;
  border-color: #ccc;
}
.completions {
  position: absolute;
  z-index: 110;
  overflow: hidden;
  border: 1px solid #ababab;
  border-radius: 2px;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  line-height: 1;
}
.completions select {
  background: white;
  outline: none;
  border: none;
  padding: 0px;
  margin: 0px;
  overflow: auto;
  font-family: monospace;
  font-size: 110%;
  color: #000;
  width: auto;
}
.completions select option.context {
  color: #286090;
}
#kernel_logo_widget .current_kernel_logo {
  display: none;
  margin-top: -1px;
  margin-bottom: -1px;
  width: 32px;
  height: 32px;
}
[dir="rtl"] #kernel_logo_widget {
  float: left !important;
  float: left;
}
.modal .modal-body .move-path {
  display: flex;
  flex-direction: row;
  justify-content: space;
  align-items: center;
}
.modal .modal-body .move-path .server-root {
  padding-right: 20px;
}
.modal .modal-body .move-path .path-input {
  flex: 1;
}
#menubar {
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  margin-top: 1px;
}
#menubar .navbar {
  border-top: 1px;
  border-radius: 0px 0px 2px 2px;
  margin-bottom: 0px;
}
#menubar .navbar-toggle {
  float: left;
  padding-top: 7px;
  padding-bottom: 7px;
  border: none;
}
#menubar .navbar-collapse {
  clear: left;
}
[dir="rtl"] #menubar .navbar-toggle {
  float: right;
}
[dir="rtl"] #menubar .navbar-collapse {
  clear: right;
}
[dir="rtl"] #menubar .navbar-nav {
  float: right;
}
[dir="rtl"] #menubar .nav {
  padding-right: 0px;
}
[dir="rtl"] #menubar .navbar-nav > li {
  float: right;
}
[dir="rtl"] #menubar .navbar-right {
  float: left !important;
}
[dir="rtl"] ul.dropdown-menu {
  text-align: right;
  left: auto;
}
[dir="rtl"] ul#new-menu.dropdown-menu {
  right: auto;
  left: 0;
}
.nav-wrapper {
  border-bottom: 1px solid #e7e7e7;
}
i.menu-icon {
  padding-top: 4px;
}
[dir="rtl"] i.menu-icon.pull-right {
  float: left !important;
  float: left;
}
ul#help_menu li a {
  overflow: hidden;
  padding-right: 2.2em;
}
ul#help_menu li a i {
  margin-right: -1.2em;
}
[dir="rtl"] ul#help_menu li a {
  padding-left: 2.2em;
}
[dir="rtl"] ul#help_menu li a i {
  margin-right: 0;
  margin-left: -1.2em;
}
[dir="rtl"] ul#help_menu li a i.pull-right {
  float: left !important;
  float: left;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu > .dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
}
[dir="rtl"] .dropdown-submenu > .dropdown-menu {
  right: 100%;
  margin-right: -1px;
}
.dropdown-submenu:hover > .dropdown-menu {
  display: block;
}
.dropdown-submenu > a:after {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  display: block;
  content: "\f0da";
  float: right;
  color: #333333;
  margin-top: 2px;
  margin-right: -10px;
}
.dropdown-submenu > a:after.fa-pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.fa-pull-right {
  margin-left: .3em;
}
.dropdown-submenu > a:after.pull-left {
  margin-right: .3em;
}
.dropdown-submenu > a:after.pull-right {
  margin-left: .3em;
}
[dir="rtl"] .dropdown-submenu > a:after {
  float: left;
  content: "\f0d9";
  margin-right: 0;
  margin-left: -10px;
}
.dropdown-submenu:hover > a:after {
  color: #262626;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left > .dropdown-menu {
  left: -100%;
  margin-left: 10px;
}
#notification_area {
  float: right !important;
  float: right;
  z-index: 10;
}
[dir="rtl"] #notification_area {
  float: left !important;
  float: left;
}
.indicator_area {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] .indicator_area {
  float: left !important;
  float: left;
}
#kernel_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  border-left: 1px solid;
}
#kernel_indicator .kernel_indicator_name {
  padding-left: 5px;
  padding-right: 5px;
}
[dir="rtl"] #kernel_indicator {
  float: left !important;
  float: left;
  border-left: 0;
  border-right: 1px solid;
}
#modal_indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
}
[dir="rtl"] #modal_indicator {
  float: left !important;
  float: left;
}
#readonly-indicator {
  float: right !important;
  float: right;
  color: #777;
  margin-left: 5px;
  margin-right: 5px;
  width: 11px;
  z-index: 10;
  text-align: center;
  width: auto;
  margin-top: 2px;
  margin-bottom: 0px;
  margin-left: 0px;
  margin-right: 0px;
  display: none;
}
.modal_indicator:before {
  width: 1.28571429em;
  text-align: center;
}
.edit_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f040";
}
.edit_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.edit_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.edit_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: ' ';
}
.command_mode .modal_indicator:before.fa-pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.fa-pull-right {
  margin-left: .3em;
}
.command_mode .modal_indicator:before.pull-left {
  margin-right: .3em;
}
.command_mode .modal_indicator:before.pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f10c";
}
.kernel_idle_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_idle_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_idle_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f111";
}
.kernel_busy_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_busy_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_busy_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f1e2";
}
.kernel_dead_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_dead_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_dead_icon:before.pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before {
  display: inline-block;
  font: normal normal normal 14px/1 FontAwesome;
  font-size: inherit;
  text-rendering: auto;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  content: "\f127";
}
.kernel_disconnected_icon:before.fa-pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.fa-pull-right {
  margin-left: .3em;
}
.kernel_disconnected_icon:before.pull-left {
  margin-right: .3em;
}
.kernel_disconnected_icon:before.pull-right {
  margin-left: .3em;
}
.notification_widget {
  color: #777;
  z-index: 10;
  background: rgba(240, 240, 240, 0.5);
  margin-right: 4px;
  color: #333;
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget:focus,
.notification_widget.focus {
  color: #333;
  background-color: #e6e6e6;
  border-color: #8c8c8c;
}
.notification_widget:hover {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  color: #333;
  background-color: #e6e6e6;
  border-color: #adadad;
}
.notification_widget:active:hover,
.notification_widget.active:hover,
.open > .dropdown-toggle.notification_widget:hover,
.notification_widget:active:focus,
.notification_widget.active:focus,
.open > .dropdown-toggle.notification_widget:focus,
.notification_widget:active.focus,
.notification_widget.active.focus,
.open > .dropdown-toggle.notification_widget.focus {
  color: #333;
  background-color: #d4d4d4;
  border-color: #8c8c8c;
}
.notification_widget:active,
.notification_widget.active,
.open > .dropdown-toggle.notification_widget {
  background-image: none;
}
.notification_widget.disabled:hover,
.notification_widget[disabled]:hover,
fieldset[disabled] .notification_widget:hover,
.notification_widget.disabled:focus,
.notification_widget[disabled]:focus,
fieldset[disabled] .notification_widget:focus,
.notification_widget.disabled.focus,
.notification_widget[disabled].focus,
fieldset[disabled] .notification_widget.focus {
  background-color: #fff;
  border-color: #ccc;
}
.notification_widget .badge {
  color: #fff;
  background-color: #333;
}
.notification_widget.warning {
  color: #fff;
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning:focus,
.notification_widget.warning.focus {
  color: #fff;
  background-color: #ec971f;
  border-color: #985f0d;
}
.notification_widget.warning:hover {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  color: #fff;
  background-color: #ec971f;
  border-color: #d58512;
}
.notification_widget.warning:active:hover,
.notification_widget.warning.active:hover,
.open > .dropdown-toggle.notification_widget.warning:hover,
.notification_widget.warning:active:focus,
.notification_widget.warning.active:focus,
.open > .dropdown-toggle.notification_widget.warning:focus,
.notification_widget.warning:active.focus,
.notification_widget.warning.active.focus,
.open > .dropdown-toggle.notification_widget.warning.focus {
  color: #fff;
  background-color: #d58512;
  border-color: #985f0d;
}
.notification_widget.warning:active,
.notification_widget.warning.active,
.open > .dropdown-toggle.notification_widget.warning {
  background-image: none;
}
.notification_widget.warning.disabled:hover,
.notification_widget.warning[disabled]:hover,
fieldset[disabled] .notification_widget.warning:hover,
.notification_widget.warning.disabled:focus,
.notification_widget.warning[disabled]:focus,
fieldset[disabled] .notification_widget.warning:focus,
.notification_widget.warning.disabled.focus,
.notification_widget.warning[disabled].focus,
fieldset[disabled] .notification_widget.warning.focus {
  background-color: #f0ad4e;
  border-color: #eea236;
}
.notification_widget.warning .badge {
  color: #f0ad4e;
  background-color: #fff;
}
.notification_widget.success {
  color: #fff;
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success:focus,
.notification_widget.success.focus {
  color: #fff;
  background-color: #449d44;
  border-color: #255625;
}
.notification_widget.success:hover {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  color: #fff;
  background-color: #449d44;
  border-color: #398439;
}
.notification_widget.success:active:hover,
.notification_widget.success.active:hover,
.open > .dropdown-toggle.notification_widget.success:hover,
.notification_widget.success:active:focus,
.notification_widget.success.active:focus,
.open > .dropdown-toggle.notification_widget.success:focus,
.notification_widget.success:active.focus,
.notification_widget.success.active.focus,
.open > .dropdown-toggle.notification_widget.success.focus {
  color: #fff;
  background-color: #398439;
  border-color: #255625;
}
.notification_widget.success:active,
.notification_widget.success.active,
.open > .dropdown-toggle.notification_widget.success {
  background-image: none;
}
.notification_widget.success.disabled:hover,
.notification_widget.success[disabled]:hover,
fieldset[disabled] .notification_widget.success:hover,
.notification_widget.success.disabled:focus,
.notification_widget.success[disabled]:focus,
fieldset[disabled] .notification_widget.success:focus,
.notification_widget.success.disabled.focus,
.notification_widget.success[disabled].focus,
fieldset[disabled] .notification_widget.success.focus {
  background-color: #5cb85c;
  border-color: #4cae4c;
}
.notification_widget.success .badge {
  color: #5cb85c;
  background-color: #fff;
}
.notification_widget.info {
  color: #fff;
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info:focus,
.notification_widget.info.focus {
  color: #fff;
  background-color: #31b0d5;
  border-color: #1b6d85;
}
.notification_widget.info:hover {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  color: #fff;
  background-color: #31b0d5;
  border-color: #269abc;
}
.notification_widget.info:active:hover,
.notification_widget.info.active:hover,
.open > .dropdown-toggle.notification_widget.info:hover,
.notification_widget.info:active:focus,
.notification_widget.info.active:focus,
.open > .dropdown-toggle.notification_widget.info:focus,
.notification_widget.info:active.focus,
.notification_widget.info.active.focus,
.open > .dropdown-toggle.notification_widget.info.focus {
  color: #fff;
  background-color: #269abc;
  border-color: #1b6d85;
}
.notification_widget.info:active,
.notification_widget.info.active,
.open > .dropdown-toggle.notification_widget.info {
  background-image: none;
}
.notification_widget.info.disabled:hover,
.notification_widget.info[disabled]:hover,
fieldset[disabled] .notification_widget.info:hover,
.notification_widget.info.disabled:focus,
.notification_widget.info[disabled]:focus,
fieldset[disabled] .notification_widget.info:focus,
.notification_widget.info.disabled.focus,
.notification_widget.info[disabled].focus,
fieldset[disabled] .notification_widget.info.focus {
  background-color: #5bc0de;
  border-color: #46b8da;
}
.notification_widget.info .badge {
  color: #5bc0de;
  background-color: #fff;
}
.notification_widget.danger {
  color: #fff;
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger:focus,
.notification_widget.danger.focus {
  color: #fff;
  background-color: #c9302c;
  border-color: #761c19;
}
.notification_widget.danger:hover {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  color: #fff;
  background-color: #c9302c;
  border-color: #ac2925;
}
.notification_widget.danger:active:hover,
.notification_widget.danger.active:hover,
.open > .dropdown-toggle.notification_widget.danger:hover,
.notification_widget.danger:active:focus,
.notification_widget.danger.active:focus,
.open > .dropdown-toggle.notification_widget.danger:focus,
.notification_widget.danger:active.focus,
.notification_widget.danger.active.focus,
.open > .dropdown-toggle.notification_widget.danger.focus {
  color: #fff;
  background-color: #ac2925;
  border-color: #761c19;
}
.notification_widget.danger:active,
.notification_widget.danger.active,
.open > .dropdown-toggle.notification_widget.danger {
  background-image: none;
}
.notification_widget.danger.disabled:hover,
.notification_widget.danger[disabled]:hover,
fieldset[disabled] .notification_widget.danger:hover,
.notification_widget.danger.disabled:focus,
.notification_widget.danger[disabled]:focus,
fieldset[disabled] .notification_widget.danger:focus,
.notification_widget.danger.disabled.focus,
.notification_widget.danger[disabled].focus,
fieldset[disabled] .notification_widget.danger.focus {
  background-color: #d9534f;
  border-color: #d43f3a;
}
.notification_widget.danger .badge {
  color: #d9534f;
  background-color: #fff;
}
div#pager {
  background-color: #fff;
  font-size: 14px;
  line-height: 20px;
  overflow: hidden;
  display: none;
  position: fixed;
  bottom: 0px;
  width: 100%;
  max-height: 50%;
  padding-top: 8px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  /* Display over codemirror */
  z-index: 100;
  /* Hack which prevents jquery ui resizable from changing top. */
  top: auto !important;
}
div#pager pre {
  line-height: 1.21429em;
  color: #000;
  background-color: #f7f7f7;
  padding: 0.4em;
}
div#pager #pager-button-area {
  position: absolute;
  top: 8px;
  right: 20px;
}
div#pager #pager-contents {
  position: relative;
  overflow: auto;
  width: 100%;
  height: 100%;
}
div#pager #pager-contents #pager-container {
  position: relative;
  padding: 15px 0px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
div#pager .ui-resizable-handle {
  top: 0px;
  height: 8px;
  background: #f7f7f7;
  border-top: 1px solid #cfcfcf;
  border-bottom: 1px solid #cfcfcf;
  /* This injects handle bars (a short, wide = symbol) for 
        the resize handle. */
}
div#pager .ui-resizable-handle::after {
  content: '';
  top: 2px;
  left: 50%;
  height: 3px;
  width: 30px;
  margin-left: -15px;
  position: absolute;
  border-top: 1px solid #cfcfcf;
}
.quickhelp {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
  line-height: 1.8em;
}
.shortcut_key {
  display: inline-block;
  width: 21ex;
  text-align: right;
  font-family: monospace;
}
.shortcut_descr {
  display: inline-block;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
span.save_widget {
  height: 30px;
  margin-top: 4px;
  display: flex;
  justify-content: flex-start;
  align-items: baseline;
  width: 50%;
  flex: 1;
}
span.save_widget span.filename {
  height: 100%;
  line-height: 1em;
  margin-left: 16px;
  border: none;
  font-size: 146.5%;
  text-overflow: ellipsis;
  overflow: hidden;
  white-space: nowrap;
  border-radius: 2px;
}
span.save_widget span.filename:hover {
  background-color: #e6e6e6;
}
[dir="rtl"] span.save_widget.pull-left {
  float: right !important;
  float: right;
}
[dir="rtl"] span.save_widget span.filename {
  margin-left: 0;
  margin-right: 16px;
}
span.checkpoint_status,
span.autosave_status {
  font-size: small;
  white-space: nowrap;
  padding: 0 5px;
}
@media (max-width: 767px) {
  span.save_widget {
    font-size: small;
    padding: 0 0 0 5px;
  }
  span.checkpoint_status,
  span.autosave_status {
    display: none;
  }
}
@media (min-width: 768px) and (max-width: 991px) {
  span.checkpoint_status {
    display: none;
  }
  span.autosave_status {
    font-size: x-small;
  }
}
.toolbar {
  padding: 0px;
  margin-left: -5px;
  margin-top: 2px;
  margin-bottom: 5px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
.toolbar select,
.toolbar label {
  width: auto;
  vertical-align: middle;
  margin-right: 2px;
  margin-bottom: 0px;
  display: inline;
  font-size: 92%;
  margin-left: 0.3em;
  margin-right: 0.3em;
  padding: 0px;
  padding-top: 3px;
}
.toolbar .btn {
  padding: 2px 8px;
}
.toolbar .btn-group {
  margin-top: 0px;
  margin-left: 5px;
}
.toolbar-btn-label {
  margin-left: 6px;
}
#maintoolbar {
  margin-bottom: -3px;
  margin-top: -8px;
  border: 0px;
  min-height: 27px;
  margin-left: 0px;
  padding-top: 11px;
  padding-bottom: 3px;
}
#maintoolbar .navbar-text {
  float: none;
  vertical-align: middle;
  text-align: right;
  margin-left: 5px;
  margin-right: 0px;
  margin-top: 0px;
}
.select-xs {
  height: 24px;
}
[dir="rtl"] .btn-group > .btn,
.btn-group-vertical > .btn {
  float: right;
}
.pulse,
.dropdown-menu > li > a.pulse,
li.pulse > a.dropdown-toggle,
li.pulse.open > a.dropdown-toggle {
  background-color: #F37626;
  color: white;
}
/**
 * Primary styles
 *
 * Author: Jupyter Development Team
 */
/** WARNING IF YOU ARE EDITTING THIS FILE, if this is a .css file, It has a lot
 * of chance of beeing generated from the ../less/[samename].less file, you can
 * try to get back the less file by reverting somme commit in history
 **/
/*
 * We'll try to get something pretty, so we
 * have some strange css to have the scroll bar on
 * the left with fix button on the top right of the tooltip
 */
@-moz-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-webkit-keyframes fadeOut {
  from {
    opacity: 1;
  }
  to {
    opacity: 0;
  }
}
@-moz-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
@-webkit-keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}
/*properties of tooltip after "expand"*/
.bigtooltip {
  overflow: auto;
  height: 200px;
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
}
/*properties of tooltip before "expand"*/
.smalltooltip {
  -webkit-transition-property: height;
  -webkit-transition-duration: 500ms;
  -moz-transition-property: height;
  -moz-transition-duration: 500ms;
  transition-property: height;
  transition-duration: 500ms;
  text-overflow: ellipsis;
  overflow: hidden;
  height: 80px;
}
.tooltipbuttons {
  position: absolute;
  padding-right: 15px;
  top: 0px;
  right: 0px;
}
.tooltiptext {
  /*avoid the button to overlap on some docstring*/
  padding-right: 30px;
}
.ipython_tooltip {
  max-width: 700px;
  /*fade-in animation when inserted*/
  -webkit-animation: fadeOut 400ms;
  -moz-animation: fadeOut 400ms;
  animation: fadeOut 400ms;
  -webkit-animation: fadeIn 400ms;
  -moz-animation: fadeIn 400ms;
  animation: fadeIn 400ms;
  vertical-align: middle;
  background-color: #f7f7f7;
  overflow: visible;
  border: #ababab 1px solid;
  outline: none;
  padding: 3px;
  margin: 0px;
  padding-left: 7px;
  font-family: monospace;
  min-height: 50px;
  -moz-box-shadow: 0px 6px 10px -1px #adadad;
  -webkit-box-shadow: 0px 6px 10px -1px #adadad;
  box-shadow: 0px 6px 10px -1px #adadad;
  border-radius: 2px;
  position: absolute;
  z-index: 1000;
}
.ipython_tooltip a {
  float: right;
}
.ipython_tooltip .tooltiptext pre {
  border: 0;
  border-radius: 0;
  font-size: 100%;
  background-color: #f7f7f7;
}
.pretooltiparrow {
  left: 0px;
  margin: 0px;
  top: -16px;
  width: 40px;
  height: 16px;
  overflow: hidden;
  position: absolute;
}
.pretooltiparrow:before {
  background-color: #f7f7f7;
  border: 1px #ababab solid;
  z-index: 11;
  content: "";
  position: absolute;
  left: 15px;
  top: 10px;
  width: 25px;
  height: 25px;
  -webkit-transform: rotate(45deg);
  -moz-transform: rotate(45deg);
  -ms-transform: rotate(45deg);
  -o-transform: rotate(45deg);
}
ul.typeahead-list i {
  margin-left: -10px;
  width: 18px;
}
[dir="rtl"] ul.typeahead-list i {
  margin-left: 0;
  margin-right: -10px;
}
ul.typeahead-list {
  max-height: 80vh;
  overflow: auto;
}
ul.typeahead-list > li > a {
  /** Firefox bug **/
  /* see https://github.com/jupyter/notebook/issues/559 */
  white-space: normal;
}
ul.typeahead-list  > li > a.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .typeahead-list {
  text-align: right;
}
.cmd-palette .modal-body {
  padding: 7px;
}
.cmd-palette form {
  background: white;
}
.cmd-palette input {
  outline: none;
}
.no-shortcut {
  min-width: 20px;
  color: transparent;
}
[dir="rtl"] .no-shortcut.pull-right {
  float: left !important;
  float: left;
}
[dir="rtl"] .command-shortcut.pull-right {
  float: left !important;
  float: left;
}
.command-shortcut:before {
  content: "(command mode)";
  padding-right: 3px;
  color: #777777;
}
.edit-shortcut:before {
  content: "(edit)";
  padding-right: 3px;
  color: #777777;
}
[dir="rtl"] .edit-shortcut.pull-right {
  float: left !important;
  float: left;
}
#find-and-replace #replace-preview .match,
#find-and-replace #replace-preview .insert {
  background-color: #BBDEFB;
  border-color: #90CAF9;
  border-style: solid;
  border-width: 1px;
  border-radius: 0px;
}
[dir="ltr"] #find-and-replace .input-group-btn + .form-control {
  border-left: none;
}
[dir="rtl"] #find-and-replace .input-group-btn + .form-control {
  border-right: none;
}
#find-and-replace #replace-preview .replace .match {
  background-color: #FFCDD2;
  border-color: #EF9A9A;
  border-radius: 0px;
}
#find-and-replace #replace-preview .replace .insert {
  background-color: #C8E6C9;
  border-color: #A5D6A7;
  border-radius: 0px;
}
#find-and-replace #replace-preview {
  max-height: 60vh;
  overflow: auto;
}
#find-and-replace #replace-preview pre {
  padding: 5px 10px;
}
.terminal-app {
  background: #EEE;
}
.terminal-app #header {
  background: #fff;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.2);
}
.terminal-app .terminal {
  width: 100%;
  float: left;
  font-family: monospace;
  color: white;
  background: black;
  padding: 0.4em;
  border-radius: 2px;
  -webkit-box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
  box-shadow: 0px 0px 12px 1px rgba(87, 87, 87, 0.4);
}
.terminal-app .terminal,
.terminal-app .terminal dummy-screen {
  line-height: 1em;
  font-size: 14px;
}
.terminal-app .terminal .xterm-rows {
  padding: 10px;
}
.terminal-app .terminal-cursor {
  color: black;
  background: white;
}
.terminal-app #terminado-container {
  margin-top: 20px;
}
/*# sourceMappingURL=style.min.css.map */
    </style>
<style type="text/css">
    .highlight .hll { background-color: #ffffcc }
.highlight  { background: #f8f8f8; }
.highlight .c { color: #408080; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #BC7A00 } /* Comment.Preproc */
.highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */
.highlight .cs { color: #408080; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #FF0000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #00A000 } /* Generic.Inserted */
.highlight .go { color: #888888 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #7D9029 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #A0A000 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #BB6688 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */
    </style>
<style type="text/css">
    
/* Temporary definitions which will become obsolete with Notebook release 5.0 */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

    </style>


<style type="text/css">
/* Overrides of notebook CSS for static HTML export */
body {
  overflow: visible;
  padding: 8px;
}

div#notebook {
  overflow: visible;
  border-top: none;
}@media print {
  div.cell {
    display: block;
    page-break-inside: avoid;
  } 
  div.output_wrapper { 
    display: block;
    page-break-inside: avoid; 
  }
  div.output { 
    display: block;
    page-break-inside: avoid; 
  }
}
</style>

<!-- Custom stylesheet, it must be in the same directory as the html file -->
<link rel="stylesheet" href="custom.css">

<!-- Loading mathjax macro -->
<!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true
        },
        // Center justify equations in code and markdown cells. Elsewhere
        // we use CSS to left justify single line equations in code cells.
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        }
    });
    </script>
    <!-- End of mathjax configuration --></head>
<body>
  <div tabindex="-1" id="notebook" class="border-box-sizing">
    <div class="container" id="notebook-container">

<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#50752;&#51064;-&#46321;&#44553;-&#44396;&#48324;(190812)">&#50752;&#51064; &#46321;&#44553; &#44396;&#48324;(190812)<a class="anchor-link" href="#&#50752;&#51064;-&#46321;&#44553;-&#44396;&#48324;(190812)">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># need library</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="c1"># 딥러닝 구동에 필요한 케라스 함수</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span> 

<span class="c1"># warning remove</span>
<span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">type</span><span class="p">(</span><span class="n">tf</span><span class="p">):</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">_warning</span> <span class="o">=</span> <span class="kc">None</span>   
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stderr output_text">
<pre>Using TensorFlow backend.
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="&#45936;&#51060;&#53552;-&#54869;&#51064;-&#48143;-&#48152;&#51025;&#48320;&#49688;,-&#49444;&#47749;&#48320;&#49688;-&#44396;&#48516;">&#45936;&#51060;&#53552; &#54869;&#51064; &#48143; &#48152;&#51025;&#48320;&#49688;, &#49444;&#47749;&#48320;&#49688; &#44396;&#48516;<a class="anchor-link" href="#&#45936;&#51060;&#53552;-&#54869;&#51064;-&#48143;-&#48152;&#51025;&#48320;&#49688;,-&#49444;&#47749;&#48320;&#49688;-&#44396;&#48516;">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[2]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df_pre</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;wine_data.csv&#39;</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df_pre</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># 원본 데이터의 100% 추출</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[2]:</div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4870</th>
      <td>6.5</td>
      <td>0.32</td>
      <td>0.34</td>
      <td>5.7</td>
      <td>0.044</td>
      <td>27.0</td>
      <td>91.0</td>
      <td>0.99184</td>
      <td>3.28</td>
      <td>0.60</td>
      <td>12.000000</td>
      <td>0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>1398</th>
      <td>7.0</td>
      <td>0.60</td>
      <td>0.12</td>
      <td>2.2</td>
      <td>0.083</td>
      <td>13.0</td>
      <td>28.0</td>
      <td>0.99660</td>
      <td>3.52</td>
      <td>0.62</td>
      <td>10.200000</td>
      <td>1</td>
      <td>7</td>
    </tr>
    <tr>
      <th>1448</th>
      <td>6.9</td>
      <td>0.58</td>
      <td>0.01</td>
      <td>1.9</td>
      <td>0.080</td>
      <td>40.0</td>
      <td>54.0</td>
      <td>0.99683</td>
      <td>3.40</td>
      <td>0.73</td>
      <td>9.700000</td>
      <td>1</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1029</th>
      <td>7.7</td>
      <td>0.58</td>
      <td>0.01</td>
      <td>1.8</td>
      <td>0.088</td>
      <td>12.0</td>
      <td>18.0</td>
      <td>0.99568</td>
      <td>3.32</td>
      <td>0.56</td>
      <td>10.500000</td>
      <td>1</td>
      <td>7</td>
    </tr>
    <tr>
      <th>1892</th>
      <td>6.2</td>
      <td>0.28</td>
      <td>0.22</td>
      <td>7.3</td>
      <td>0.041</td>
      <td>26.0</td>
      <td>157.0</td>
      <td>0.99570</td>
      <td>3.44</td>
      <td>0.64</td>
      <td>9.800000</td>
      <td>0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>1067</th>
      <td>11.1</td>
      <td>0.31</td>
      <td>0.53</td>
      <td>2.2</td>
      <td>0.060</td>
      <td>3.0</td>
      <td>10.0</td>
      <td>0.99572</td>
      <td>3.02</td>
      <td>0.83</td>
      <td>10.900000</td>
      <td>1</td>
      <td>7</td>
    </tr>
    <tr>
      <th>54</th>
      <td>7.6</td>
      <td>0.51</td>
      <td>0.15</td>
      <td>2.8</td>
      <td>0.110</td>
      <td>33.0</td>
      <td>73.0</td>
      <td>0.99550</td>
      <td>3.17</td>
      <td>0.63</td>
      <td>10.200000</td>
      <td>1</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2117</th>
      <td>5.9</td>
      <td>0.13</td>
      <td>0.28</td>
      <td>1.9</td>
      <td>0.050</td>
      <td>20.0</td>
      <td>78.0</td>
      <td>0.99180</td>
      <td>3.43</td>
      <td>0.64</td>
      <td>10.800000</td>
      <td>0</td>
      <td>6</td>
    </tr>
    <tr>
      <th>2443</th>
      <td>7.3</td>
      <td>0.21</td>
      <td>0.29</td>
      <td>1.6</td>
      <td>0.034</td>
      <td>29.0</td>
      <td>118.0</td>
      <td>0.99170</td>
      <td>3.30</td>
      <td>0.50</td>
      <td>11.000000</td>
      <td>0</td>
      <td>8</td>
    </tr>
    <tr>
      <th>1475</th>
      <td>5.3</td>
      <td>0.47</td>
      <td>0.11</td>
      <td>2.2</td>
      <td>0.048</td>
      <td>16.0</td>
      <td>89.0</td>
      <td>0.99182</td>
      <td>3.54</td>
      <td>0.88</td>
      <td>13.566667</td>
      <td>1</td>
      <td>7</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[3]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># X : explanatory variables, Y : response variable (와인의 10단계 등급)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">values</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">12</span><span class="p">]</span>
<span class="n">Y_obj</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span><span class="mi">12</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># one-hot encoding</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="k">import</span> <span class="n">np_utils</span>

<span class="n">Y</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">Y_obj</span><span class="p">,</span><span class="mi">11</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">Y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt output_prompt">Out[5]:</div>




<div class="output_text output_subarea output_execute_result">
<pre>array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="modeling-(Deep-learning),-update">modeling (Deep-learning), update<a class="anchor-link" href="#modeling-(Deep-learning),-update">&#182;</a></h3><ul>
<li>은닉노드의 개수와 활성화 함수를 다르게 적용하여 4가지의 딥러닝 모델 구축 후 성능 비교</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="model-1">model 1<a class="anchor-link" href="#model-1">&#182;</a></h4><ul>
<li>input 12</li>
<li>4 hidden layer , 30 <em> 15 </em> 10 * 11 node</li>
<li>activation function : relu -&gt; relu -&gt; softplus -&gt; softmax</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[7]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">keras.models</span> <span class="k">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">load_model</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="k">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.callbacks</span> <span class="k">import</span> <span class="n">ModelCheckpoint</span><span class="p">,</span> <span class="n">EarlyStopping</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># modeling</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model update</span>
<span class="n">MODEL_DIR</span> <span class="o">=</span> <span class="s1">&#39;model1/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">)</span>

<span class="n">modelpath</span> <span class="o">=</span> <span class="s2">&quot;model1/</span><span class="si">{epoch:02d}</span><span class="s2">-</span><span class="si">{val_loss:.4f}</span><span class="s2">.hdf5&quot;</span>
<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">modelpath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">early_stopping_callback</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">history1</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping_callback</span><span class="p">,</span> <span class="n">checkpointer</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 4547 samples, validate on 1950 samples
Epoch 1/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.0264 - acc: 0.5564 - val_loss: 1.1088 - val_acc: 0.5323

Epoch 00001: val_loss improved from inf to 1.10884, saving model to model1/01-1.1088.hdf5
Epoch 2/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0283 - acc: 0.5520 - val_loss: 1.1021 - val_acc: 0.5190

Epoch 00002: val_loss improved from 1.10884 to 1.10206, saving model to model1/02-1.1021.hdf5
Epoch 3/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0223 - acc: 0.5584 - val_loss: 1.0658 - val_acc: 0.5456

Epoch 00003: val_loss improved from 1.10206 to 1.06585, saving model to model1/03-1.0658.hdf5
Epoch 4/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0142 - acc: 0.5619 - val_loss: 1.0684 - val_acc: 0.5462

Epoch 00004: val_loss did not improve from 1.06585
Epoch 5/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0142 - acc: 0.5621 - val_loss: 1.0684 - val_acc: 0.5446

Epoch 00005: val_loss did not improve from 1.06585
Epoch 6/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0150 - acc: 0.5628 - val_loss: 1.0657 - val_acc: 0.5456

Epoch 00006: val_loss improved from 1.06585 to 1.06574, saving model to model1/06-1.0657.hdf5
Epoch 7/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0200 - acc: 0.5533 - val_loss: 1.0696 - val_acc: 0.5451

Epoch 00007: val_loss did not improve from 1.06574
Epoch 8/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0197 - acc: 0.5575 - val_loss: 1.0687 - val_acc: 0.5492

Epoch 00008: val_loss did not improve from 1.06574
Epoch 9/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0179 - acc: 0.5593 - val_loss: 1.0732 - val_acc: 0.5451

Epoch 00009: val_loss did not improve from 1.06574
Epoch 10/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0191 - acc: 0.5588 - val_loss: 1.0660 - val_acc: 0.5441

Epoch 00010: val_loss did not improve from 1.06574
Epoch 11/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0291 - acc: 0.5553 - val_loss: 1.0672 - val_acc: 0.5436

Epoch 00011: val_loss did not improve from 1.06574
Epoch 12/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0186 - acc: 0.5593 - val_loss: 1.0703 - val_acc: 0.5462

Epoch 00012: val_loss did not improve from 1.06574
Epoch 13/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0162 - acc: 0.5612 - val_loss: 1.0699 - val_acc: 0.5436

Epoch 00013: val_loss did not improve from 1.06574
Epoch 14/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0157 - acc: 0.5630 - val_loss: 1.0735 - val_acc: 0.5441

Epoch 00014: val_loss did not improve from 1.06574
Epoch 15/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0137 - acc: 0.5667 - val_loss: 1.0655 - val_acc: 0.5415

Epoch 00015: val_loss improved from 1.06574 to 1.06550, saving model to model1/15-1.0655.hdf5
Epoch 16/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0155 - acc: 0.5621 - val_loss: 1.0758 - val_acc: 0.5410

Epoch 00016: val_loss did not improve from 1.06550
Epoch 17/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0155 - acc: 0.5656 - val_loss: 1.0827 - val_acc: 0.5390

Epoch 00017: val_loss did not improve from 1.06550
Epoch 18/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0217 - acc: 0.5558 - val_loss: 1.0707 - val_acc: 0.5518

Epoch 00018: val_loss did not improve from 1.06550
Epoch 19/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0210 - acc: 0.5619 - val_loss: 1.0969 - val_acc: 0.5215

Epoch 00019: val_loss did not improve from 1.06550
Epoch 20/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0392 - acc: 0.5452 - val_loss: 1.0786 - val_acc: 0.5313

Epoch 00020: val_loss did not improve from 1.06550
Epoch 21/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0305 - acc: 0.5553 - val_loss: 1.0888 - val_acc: 0.5297

Epoch 00021: val_loss did not improve from 1.06550
Epoch 22/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0276 - acc: 0.5483 - val_loss: 1.1010 - val_acc: 0.5467

Epoch 00022: val_loss did not improve from 1.06550
Epoch 23/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0235 - acc: 0.5634 - val_loss: 1.0974 - val_acc: 0.5359

Epoch 00023: val_loss did not improve from 1.06550
Epoch 24/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0283 - acc: 0.5516 - val_loss: 1.0975 - val_acc: 0.5215

Epoch 00024: val_loss did not improve from 1.06550
Epoch 25/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0240 - acc: 0.5498 - val_loss: 1.1023 - val_acc: 0.5195

Epoch 00025: val_loss did not improve from 1.06550
Epoch 26/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0279 - acc: 0.5590 - val_loss: 1.0737 - val_acc: 0.5528

Epoch 00026: val_loss did not improve from 1.06550
Epoch 27/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0246 - acc: 0.5553 - val_loss: 1.0845 - val_acc: 0.5236

Epoch 00027: val_loss did not improve from 1.06550
Epoch 28/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0294 - acc: 0.5448 - val_loss: 1.0828 - val_acc: 0.5277

Epoch 00028: val_loss did not improve from 1.06550
Epoch 29/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0227 - acc: 0.5604 - val_loss: 1.0640 - val_acc: 0.5472

Epoch 00029: val_loss improved from 1.06550 to 1.06399, saving model to model1/29-1.0640.hdf5
Epoch 30/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0160 - acc: 0.5632 - val_loss: 1.0665 - val_acc: 0.5405

Epoch 00030: val_loss did not improve from 1.06399
Epoch 31/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0156 - acc: 0.5652 - val_loss: 1.0717 - val_acc: 0.5415

Epoch 00031: val_loss did not improve from 1.06399
Epoch 32/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0151 - acc: 0.5584 - val_loss: 1.0687 - val_acc: 0.5508

Epoch 00032: val_loss did not improve from 1.06399
Epoch 33/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5648 - val_loss: 1.0726 - val_acc: 0.5415

Epoch 00033: val_loss did not improve from 1.06399
Epoch 34/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0205 - acc: 0.5601 - val_loss: 1.0796 - val_acc: 0.5456

Epoch 00034: val_loss did not improve from 1.06399
Epoch 35/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0217 - acc: 0.5562 - val_loss: 1.0728 - val_acc: 0.5472

Epoch 00035: val_loss did not improve from 1.06399
Epoch 36/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0190 - acc: 0.5634 - val_loss: 1.0737 - val_acc: 0.5487

Epoch 00036: val_loss did not improve from 1.06399
Epoch 37/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0186 - acc: 0.5623 - val_loss: 1.0819 - val_acc: 0.5267

Epoch 00037: val_loss did not improve from 1.06399
Epoch 38/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0236 - acc: 0.5634 - val_loss: 1.0714 - val_acc: 0.5421

Epoch 00038: val_loss did not improve from 1.06399
Epoch 39/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0164 - acc: 0.5656 - val_loss: 1.0751 - val_acc: 0.5518

Epoch 00039: val_loss did not improve from 1.06399
Epoch 40/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0152 - acc: 0.5575 - val_loss: 1.0883 - val_acc: 0.5205

Epoch 00040: val_loss did not improve from 1.06399
Epoch 41/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0346 - acc: 0.5412 - val_loss: 1.0773 - val_acc: 0.5400

Epoch 00041: val_loss did not improve from 1.06399
Epoch 42/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0216 - acc: 0.5588 - val_loss: 1.0658 - val_acc: 0.5467

Epoch 00042: val_loss did not improve from 1.06399
Epoch 43/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0208 - acc: 0.5555 - val_loss: 1.0702 - val_acc: 0.5508

Epoch 00043: val_loss did not improve from 1.06399
Epoch 44/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0184 - acc: 0.5606 - val_loss: 1.0867 - val_acc: 0.5185

Epoch 00044: val_loss did not improve from 1.06399
Epoch 45/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0364 - acc: 0.5494 - val_loss: 1.0690 - val_acc: 0.5374

Epoch 00045: val_loss did not improve from 1.06399
Epoch 46/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0204 - acc: 0.5639 - val_loss: 1.0700 - val_acc: 0.5441

Epoch 00046: val_loss did not improve from 1.06399
Epoch 47/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0139 - acc: 0.5639 - val_loss: 1.0787 - val_acc: 0.5421

Epoch 00047: val_loss did not improve from 1.06399
Epoch 48/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0231 - acc: 0.5586 - val_loss: 1.0735 - val_acc: 0.5487

Epoch 00048: val_loss did not improve from 1.06399
Epoch 49/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0187 - acc: 0.5612 - val_loss: 1.0823 - val_acc: 0.5482

Epoch 00049: val_loss did not improve from 1.06399
Epoch 50/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0172 - acc: 0.5667 - val_loss: 1.0784 - val_acc: 0.5354

Epoch 00050: val_loss did not improve from 1.06399
Epoch 51/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0196 - acc: 0.5604 - val_loss: 1.0951 - val_acc: 0.5292

Epoch 00051: val_loss did not improve from 1.06399
Epoch 52/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0214 - acc: 0.5604 - val_loss: 1.0676 - val_acc: 0.5333

Epoch 00052: val_loss did not improve from 1.06399
Epoch 53/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0281 - acc: 0.5443 - val_loss: 1.0769 - val_acc: 0.5344

Epoch 00053: val_loss did not improve from 1.06399
Epoch 54/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5573 - val_loss: 1.0756 - val_acc: 0.5354

Epoch 00054: val_loss did not improve from 1.06399
Epoch 55/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5566 - val_loss: 1.0790 - val_acc: 0.5395

Epoch 00055: val_loss did not improve from 1.06399
Epoch 56/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0268 - acc: 0.5489 - val_loss: 1.1023 - val_acc: 0.5174

Epoch 00056: val_loss did not improve from 1.06399
Epoch 57/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0232 - acc: 0.5588 - val_loss: 1.0727 - val_acc: 0.5462

Epoch 00057: val_loss did not improve from 1.06399
Epoch 58/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5595 - val_loss: 1.0710 - val_acc: 0.5472

Epoch 00058: val_loss did not improve from 1.06399
Epoch 59/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0184 - acc: 0.5555 - val_loss: 1.0783 - val_acc: 0.5354

Epoch 00059: val_loss did not improve from 1.06399
Epoch 60/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0198 - acc: 0.5621 - val_loss: 1.0643 - val_acc: 0.5436

Epoch 00060: val_loss did not improve from 1.06399
Epoch 61/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0186 - acc: 0.5577 - val_loss: 1.0681 - val_acc: 0.5338

Epoch 00061: val_loss did not improve from 1.06399
Epoch 62/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0260 - acc: 0.5520 - val_loss: 1.0729 - val_acc: 0.5328

Epoch 00062: val_loss did not improve from 1.06399
Epoch 63/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0257 - acc: 0.5555 - val_loss: 1.0651 - val_acc: 0.5451

Epoch 00063: val_loss did not improve from 1.06399
Epoch 64/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0244 - acc: 0.5536 - val_loss: 1.0681 - val_acc: 0.5456

Epoch 00064: val_loss did not improve from 1.06399
Epoch 65/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0207 - acc: 0.5606 - val_loss: 1.0889 - val_acc: 0.5313

Epoch 00065: val_loss did not improve from 1.06399
Epoch 66/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0219 - acc: 0.5562 - val_loss: 1.0695 - val_acc: 0.5467

Epoch 00066: val_loss did not improve from 1.06399
Epoch 67/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0261 - acc: 0.5514 - val_loss: 1.0888 - val_acc: 0.5272

Epoch 00067: val_loss did not improve from 1.06399
Epoch 68/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0363 - acc: 0.5377 - val_loss: 1.0637 - val_acc: 0.5533

Epoch 00068: val_loss improved from 1.06399 to 1.06370, saving model to model1/68-1.0637.hdf5
Epoch 69/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0228 - acc: 0.5612 - val_loss: 1.0772 - val_acc: 0.5287

Epoch 00069: val_loss did not improve from 1.06370
Epoch 70/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0173 - acc: 0.5509 - val_loss: 1.0697 - val_acc: 0.5456

Epoch 00070: val_loss did not improve from 1.06370
Epoch 71/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0140 - acc: 0.5667 - val_loss: 1.0669 - val_acc: 0.5497

Epoch 00071: val_loss did not improve from 1.06370
Epoch 72/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0157 - acc: 0.5630 - val_loss: 1.0688 - val_acc: 0.5533

Epoch 00072: val_loss did not improve from 1.06370
Epoch 73/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0170 - acc: 0.5632 - val_loss: 1.0692 - val_acc: 0.5467

Epoch 00073: val_loss did not improve from 1.06370
Epoch 74/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5628 - val_loss: 1.0700 - val_acc: 0.5477

Epoch 00074: val_loss did not improve from 1.06370
Epoch 75/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0130 - acc: 0.5672 - val_loss: 1.0670 - val_acc: 0.5513

Epoch 00075: val_loss did not improve from 1.06370
Epoch 76/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0189 - acc: 0.5564 - val_loss: 1.0886 - val_acc: 0.5390

Epoch 00076: val_loss did not improve from 1.06370
Epoch 77/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0270 - acc: 0.5518 - val_loss: 1.1169 - val_acc: 0.5390

Epoch 00077: val_loss did not improve from 1.06370
Epoch 78/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0326 - acc: 0.5540 - val_loss: 1.0875 - val_acc: 0.5282

Epoch 00078: val_loss did not improve from 1.06370
Epoch 79/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0219 - acc: 0.5566 - val_loss: 1.0667 - val_acc: 0.5436

Epoch 00079: val_loss did not improve from 1.06370
Epoch 80/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0269 - acc: 0.5529 - val_loss: 1.0712 - val_acc: 0.5369

Epoch 00080: val_loss did not improve from 1.06370
Epoch 81/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0175 - acc: 0.5604 - val_loss: 1.0705 - val_acc: 0.5421

Epoch 00081: val_loss did not improve from 1.06370
Epoch 82/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0182 - acc: 0.5617 - val_loss: 1.0865 - val_acc: 0.5379

Epoch 00082: val_loss did not improve from 1.06370
Epoch 83/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0218 - acc: 0.5595 - val_loss: 1.0741 - val_acc: 0.5436

Epoch 00083: val_loss did not improve from 1.06370
Epoch 84/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0158 - acc: 0.5612 - val_loss: 1.0748 - val_acc: 0.5436

Epoch 00084: val_loss did not improve from 1.06370
Epoch 85/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0155 - acc: 0.5612 - val_loss: 1.0701 - val_acc: 0.5456

Epoch 00085: val_loss did not improve from 1.06370
Epoch 86/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0141 - acc: 0.5694 - val_loss: 1.0680 - val_acc: 0.5508

Epoch 00086: val_loss did not improve from 1.06370
Epoch 87/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0135 - acc: 0.5672 - val_loss: 1.0809 - val_acc: 0.5349

Epoch 00087: val_loss did not improve from 1.06370
Epoch 88/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0192 - acc: 0.5566 - val_loss: 1.0774 - val_acc: 0.5456

Epoch 00088: val_loss did not improve from 1.06370
Epoch 89/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0187 - acc: 0.5615 - val_loss: 1.0687 - val_acc: 0.5436

Epoch 00089: val_loss did not improve from 1.06370
Epoch 90/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0181 - acc: 0.5564 - val_loss: 1.0688 - val_acc: 0.5508

Epoch 00090: val_loss did not improve from 1.06370
Epoch 91/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0142 - acc: 0.5608 - val_loss: 1.0687 - val_acc: 0.5544

Epoch 00091: val_loss did not improve from 1.06370
Epoch 92/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5599 - val_loss: 1.0725 - val_acc: 0.5487

Epoch 00092: val_loss did not improve from 1.06370
Epoch 93/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0135 - acc: 0.5634 - val_loss: 1.0642 - val_acc: 0.5421

Epoch 00093: val_loss did not improve from 1.06370
Epoch 94/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5569 - val_loss: 1.0766 - val_acc: 0.5262

Epoch 00094: val_loss did not improve from 1.06370
Epoch 95/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0185 - acc: 0.5604 - val_loss: 1.0665 - val_acc: 0.5462

Epoch 00095: val_loss did not improve from 1.06370
Epoch 96/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0187 - acc: 0.5634 - val_loss: 1.0775 - val_acc: 0.5405

Epoch 00096: val_loss did not improve from 1.06370
Epoch 97/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5621 - val_loss: 1.0686 - val_acc: 0.5467

Epoch 00097: val_loss did not improve from 1.06370
Epoch 98/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0180 - acc: 0.5595 - val_loss: 1.0669 - val_acc: 0.5436

Epoch 00098: val_loss did not improve from 1.06370
Epoch 99/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0218 - acc: 0.5500 - val_loss: 1.0802 - val_acc: 0.5374

Epoch 00099: val_loss did not improve from 1.06370
Epoch 100/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0228 - acc: 0.5527 - val_loss: 1.0740 - val_acc: 0.5374

Epoch 00100: val_loss did not improve from 1.06370
Epoch 101/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5617 - val_loss: 1.0729 - val_acc: 0.5482

Epoch 00101: val_loss did not improve from 1.06370
Epoch 102/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0143 - acc: 0.5571 - val_loss: 1.0695 - val_acc: 0.5364

Epoch 00102: val_loss did not improve from 1.06370
Epoch 103/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0155 - acc: 0.5580 - val_loss: 1.0704 - val_acc: 0.5405

Epoch 00103: val_loss did not improve from 1.06370
Epoch 104/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0189 - acc: 0.5584 - val_loss: 1.0740 - val_acc: 0.5390

Epoch 00104: val_loss did not improve from 1.06370
Epoch 105/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0183 - acc: 0.5597 - val_loss: 1.0827 - val_acc: 0.5385

Epoch 00105: val_loss did not improve from 1.06370
Epoch 106/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0326 - acc: 0.5485 - val_loss: 1.1038 - val_acc: 0.5344

Epoch 00106: val_loss did not improve from 1.06370
Epoch 107/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0326 - acc: 0.5452 - val_loss: 1.0867 - val_acc: 0.5328

Epoch 00107: val_loss did not improve from 1.06370
Epoch 108/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0207 - acc: 0.5551 - val_loss: 1.0775 - val_acc: 0.5441

Epoch 00108: val_loss did not improve from 1.06370
Epoch 109/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0128 - acc: 0.5608 - val_loss: 1.0830 - val_acc: 0.5436

Epoch 00109: val_loss did not improve from 1.06370
Epoch 110/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0205 - acc: 0.5595 - val_loss: 1.0736 - val_acc: 0.5426

Epoch 00110: val_loss did not improve from 1.06370
Epoch 111/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0218 - acc: 0.5538 - val_loss: 1.0722 - val_acc: 0.5497

Epoch 00111: val_loss did not improve from 1.06370
Epoch 112/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5659 - val_loss: 1.0679 - val_acc: 0.5492

Epoch 00112: val_loss did not improve from 1.06370
Epoch 113/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0168 - acc: 0.5628 - val_loss: 1.0798 - val_acc: 0.5400

Epoch 00113: val_loss did not improve from 1.06370
Epoch 114/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0146 - acc: 0.5643 - val_loss: 1.0696 - val_acc: 0.5467

Epoch 00114: val_loss did not improve from 1.06370
Epoch 115/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0142 - acc: 0.5623 - val_loss: 1.0705 - val_acc: 0.5426

Epoch 00115: val_loss did not improve from 1.06370
Epoch 116/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0194 - acc: 0.5522 - val_loss: 1.0781 - val_acc: 0.5256

Epoch 00116: val_loss did not improve from 1.06370
Epoch 117/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0156 - acc: 0.5606 - val_loss: 1.0731 - val_acc: 0.5523

Epoch 00117: val_loss did not improve from 1.06370
Epoch 118/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0136 - acc: 0.5641 - val_loss: 1.0791 - val_acc: 0.5369

Epoch 00118: val_loss did not improve from 1.06370
Epoch 119/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0158 - acc: 0.5588 - val_loss: 1.0700 - val_acc: 0.5446

Epoch 00119: val_loss did not improve from 1.06370
Epoch 120/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0141 - acc: 0.5663 - val_loss: 1.0686 - val_acc: 0.5451

Epoch 00120: val_loss did not improve from 1.06370
Epoch 121/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0187 - acc: 0.5577 - val_loss: 1.0698 - val_acc: 0.5487

Epoch 00121: val_loss did not improve from 1.06370
Epoch 122/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0135 - acc: 0.5648 - val_loss: 1.0951 - val_acc: 0.5128

Epoch 00122: val_loss did not improve from 1.06370
Epoch 123/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0294 - acc: 0.5518 - val_loss: 1.0700 - val_acc: 0.5426

Epoch 00123: val_loss did not improve from 1.06370
Epoch 124/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0181 - acc: 0.5571 - val_loss: 1.0799 - val_acc: 0.5395

Epoch 00124: val_loss did not improve from 1.06370
Epoch 125/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0161 - acc: 0.5617 - val_loss: 1.0692 - val_acc: 0.5533

Epoch 00125: val_loss did not improve from 1.06370
Epoch 126/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0124 - acc: 0.5621 - val_loss: 1.0725 - val_acc: 0.5415

Epoch 00126: val_loss did not improve from 1.06370
Epoch 127/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0170 - acc: 0.5608 - val_loss: 1.0873 - val_acc: 0.5277

Epoch 00127: val_loss did not improve from 1.06370
Epoch 128/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5514 - val_loss: 1.0695 - val_acc: 0.5395

Epoch 00128: val_loss did not improve from 1.06370
Epoch 129/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0167 - acc: 0.5645 - val_loss: 1.0678 - val_acc: 0.5467

Epoch 00129: val_loss did not improve from 1.06370
Epoch 130/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0173 - acc: 0.5601 - val_loss: 1.0718 - val_acc: 0.5364

Epoch 00130: val_loss did not improve from 1.06370
Epoch 131/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0173 - acc: 0.5601 - val_loss: 1.0890 - val_acc: 0.5338

Epoch 00131: val_loss did not improve from 1.06370
Epoch 132/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0165 - acc: 0.5637 - val_loss: 1.0733 - val_acc: 0.5482

Epoch 00132: val_loss did not improve from 1.06370
Epoch 133/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0159 - acc: 0.5615 - val_loss: 1.0795 - val_acc: 0.5405

Epoch 00133: val_loss did not improve from 1.06370
Epoch 134/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0129 - acc: 0.5606 - val_loss: 1.0770 - val_acc: 0.5415

Epoch 00134: val_loss did not improve from 1.06370
Epoch 135/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5676 - val_loss: 1.0799 - val_acc: 0.5405

Epoch 00135: val_loss did not improve from 1.06370
Epoch 136/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0126 - acc: 0.5632 - val_loss: 1.0663 - val_acc: 0.5374

Epoch 00136: val_loss did not improve from 1.06370
Epoch 137/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0152 - acc: 0.5623 - val_loss: 1.0706 - val_acc: 0.5487

Epoch 00137: val_loss did not improve from 1.06370
Epoch 138/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0194 - acc: 0.5551 - val_loss: 1.0845 - val_acc: 0.5323

Epoch 00138: val_loss did not improve from 1.06370
Epoch 139/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0189 - acc: 0.5551 - val_loss: 1.0708 - val_acc: 0.5487

Epoch 00139: val_loss did not improve from 1.06370
Epoch 140/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0150 - acc: 0.5630 - val_loss: 1.0738 - val_acc: 0.5400

Epoch 00140: val_loss did not improve from 1.06370
Epoch 141/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0155 - acc: 0.5584 - val_loss: 1.0921 - val_acc: 0.5415

Epoch 00141: val_loss did not improve from 1.06370
Epoch 142/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0242 - acc: 0.5478 - val_loss: 1.0706 - val_acc: 0.5549

Epoch 00142: val_loss did not improve from 1.06370
Epoch 143/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0151 - acc: 0.5637 - val_loss: 1.0678 - val_acc: 0.5446

Epoch 00143: val_loss did not improve from 1.06370
Epoch 144/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0142 - acc: 0.5621 - val_loss: 1.0673 - val_acc: 0.5508

Epoch 00144: val_loss did not improve from 1.06370
Epoch 145/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0202 - acc: 0.5580 - val_loss: 1.0900 - val_acc: 0.5456

Epoch 00145: val_loss did not improve from 1.06370
Epoch 146/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0279 - acc: 0.5542 - val_loss: 1.1049 - val_acc: 0.5328

Epoch 00146: val_loss did not improve from 1.06370
Epoch 147/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0275 - acc: 0.5456 - val_loss: 1.0718 - val_acc: 0.5446

Epoch 00147: val_loss did not improve from 1.06370
Epoch 148/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0167 - acc: 0.5595 - val_loss: 1.0683 - val_acc: 0.5431

Epoch 00148: val_loss did not improve from 1.06370
Epoch 149/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0165 - acc: 0.5630 - val_loss: 1.0666 - val_acc: 0.5579

Epoch 00149: val_loss did not improve from 1.06370
Epoch 150/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0177 - acc: 0.5674 - val_loss: 1.0723 - val_acc: 0.5472

Epoch 00150: val_loss did not improve from 1.06370
Epoch 151/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0176 - acc: 0.5694 - val_loss: 1.0658 - val_acc: 0.5482

Epoch 00151: val_loss did not improve from 1.06370
Epoch 152/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5637 - val_loss: 1.0806 - val_acc: 0.5456

Epoch 00152: val_loss did not improve from 1.06370
Epoch 153/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0168 - acc: 0.5634 - val_loss: 1.0688 - val_acc: 0.5462

Epoch 00153: val_loss did not improve from 1.06370
Epoch 154/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0179 - acc: 0.5610 - val_loss: 1.0657 - val_acc: 0.5492

Epoch 00154: val_loss did not improve from 1.06370
Epoch 155/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0131 - acc: 0.5661 - val_loss: 1.0711 - val_acc: 0.5533

Epoch 00155: val_loss did not improve from 1.06370
Epoch 156/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0179 - acc: 0.5619 - val_loss: 1.1076 - val_acc: 0.5333

Epoch 00156: val_loss did not improve from 1.06370
Epoch 157/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0383 - acc: 0.5481 - val_loss: 1.0792 - val_acc: 0.5451

Epoch 00157: val_loss did not improve from 1.06370
Epoch 158/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0203 - acc: 0.5520 - val_loss: 1.0903 - val_acc: 0.5231

Epoch 00158: val_loss did not improve from 1.06370
Epoch 159/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0220 - acc: 0.5584 - val_loss: 1.0697 - val_acc: 0.5426

Epoch 00159: val_loss did not improve from 1.06370
Epoch 160/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0197 - acc: 0.5588 - val_loss: 1.0722 - val_acc: 0.5338

Epoch 00160: val_loss did not improve from 1.06370
Epoch 161/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0166 - acc: 0.5604 - val_loss: 1.0685 - val_acc: 0.5395

Epoch 00161: val_loss did not improve from 1.06370
Epoch 162/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0166 - acc: 0.5569 - val_loss: 1.0681 - val_acc: 0.5390

Epoch 00162: val_loss did not improve from 1.06370
Epoch 163/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5637 - val_loss: 1.1037 - val_acc: 0.5328

Epoch 00163: val_loss did not improve from 1.06370
Epoch 164/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0292 - acc: 0.5498 - val_loss: 1.1115 - val_acc: 0.5282

Epoch 00164: val_loss did not improve from 1.06370
Epoch 165/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0309 - acc: 0.5496 - val_loss: 1.0716 - val_acc: 0.5467

Epoch 00165: val_loss did not improve from 1.06370
Epoch 166/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0177 - acc: 0.5650 - val_loss: 1.0671 - val_acc: 0.5544

Epoch 00166: val_loss did not improve from 1.06370
Epoch 167/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5626 - val_loss: 1.0683 - val_acc: 0.5456

Epoch 00167: val_loss did not improve from 1.06370
Epoch 168/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0126 - acc: 0.5641 - val_loss: 1.0659 - val_acc: 0.5579

Epoch 00168: val_loss did not improve from 1.06370
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># save model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;result/my_model1.h5&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;result/my_model1.h5&#39;</span><span class="p">)</span>

<span class="c1"># Accuracy result</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Accuracy: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>

<span class="k">del</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>6497/6497 [==============================] - 0s 13us/step

 Accuracy: 0.5641
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="model-2">model 2<a class="anchor-link" href="#model-2">&#182;</a></h4><ul>
<li>input 12</li>
<li>4 hidden layer , 30 <em> 15 </em> 10 * 11 node</li>
<li>activation function : relu -&gt; tanh -&gt; softplus -&gt; softmax</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[12]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># modeling</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;tanh&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model update</span>
<span class="n">MODEL_DIR</span> <span class="o">=</span> <span class="s1">&#39;model2/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">)</span>

<span class="n">modelpath</span> <span class="o">=</span> <span class="s2">&quot;model2/</span><span class="si">{epoch:02d}</span><span class="s2">-</span><span class="si">{val_loss:.4f}</span><span class="s2">.hdf5&quot;</span>
<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">modelpath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">early_stopping_callback</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">history2</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping_callback</span><span class="p">,</span> <span class="n">checkpointer</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 4547 samples, validate on 1950 samples
Epoch 1/3000
4547/4547 [==============================] - 0s 55us/step - loss: 2.3879 - acc: 0.2276 - val_loss: 2.0743 - val_acc: 0.4082

Epoch 00001: val_loss improved from inf to 2.07425, saving model to model2/01-2.0743.hdf5
Epoch 2/3000
4547/4547 [==============================] - 0s 4us/step - loss: 2.0179 - acc: 0.4242 - val_loss: 1.9407 - val_acc: 0.4467

Epoch 00002: val_loss improved from 2.07425 to 1.94073, saving model to model2/02-1.9407.hdf5
Epoch 3/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.9011 - acc: 0.4322 - val_loss: 1.8232 - val_acc: 0.4467

Epoch 00003: val_loss improved from 1.94073 to 1.82317, saving model to model2/03-1.8232.hdf5
Epoch 4/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.7688 - acc: 0.4322 - val_loss: 1.6946 - val_acc: 0.4467

Epoch 00004: val_loss improved from 1.82317 to 1.69455, saving model to model2/04-1.6946.hdf5
Epoch 5/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.6485 - acc: 0.4322 - val_loss: 1.6162 - val_acc: 0.4467

Epoch 00005: val_loss improved from 1.69455 to 1.61617, saving model to model2/05-1.6162.hdf5
Epoch 6/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.5817 - acc: 0.4322 - val_loss: 1.5619 - val_acc: 0.4467

Epoch 00006: val_loss improved from 1.61617 to 1.56187, saving model to model2/06-1.5619.hdf5
Epoch 7/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.5310 - acc: 0.4322 - val_loss: 1.5181 - val_acc: 0.4467

Epoch 00007: val_loss improved from 1.56187 to 1.51808, saving model to model2/07-1.5181.hdf5
Epoch 8/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.4890 - acc: 0.4322 - val_loss: 1.4824 - val_acc: 0.4467

Epoch 00008: val_loss improved from 1.51808 to 1.48239, saving model to model2/08-1.4824.hdf5
Epoch 9/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.4540 - acc: 0.4322 - val_loss: 1.4527 - val_acc: 0.4467

Epoch 00009: val_loss improved from 1.48239 to 1.45266, saving model to model2/09-1.4527.hdf5
Epoch 10/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.4240 - acc: 0.4322 - val_loss: 1.4274 - val_acc: 0.4467

Epoch 00010: val_loss improved from 1.45266 to 1.42741, saving model to model2/10-1.4274.hdf5
Epoch 11/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3983 - acc: 0.4322 - val_loss: 1.4063 - val_acc: 0.4467

Epoch 00011: val_loss improved from 1.42741 to 1.40626, saving model to model2/11-1.4063.hdf5
Epoch 12/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3765 - acc: 0.4322 - val_loss: 1.3884 - val_acc: 0.4467

Epoch 00012: val_loss improved from 1.40626 to 1.38836, saving model to model2/12-1.3884.hdf5
Epoch 13/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3585 - acc: 0.4322 - val_loss: 1.3744 - val_acc: 0.4467

Epoch 00013: val_loss improved from 1.38836 to 1.37441, saving model to model2/13-1.3744.hdf5
Epoch 14/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3438 - acc: 0.4322 - val_loss: 1.3621 - val_acc: 0.4467

Epoch 00014: val_loss improved from 1.37441 to 1.36214, saving model to model2/14-1.3621.hdf5
Epoch 15/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3312 - acc: 0.4322 - val_loss: 1.3526 - val_acc: 0.4467

Epoch 00015: val_loss improved from 1.36214 to 1.35256, saving model to model2/15-1.3526.hdf5
Epoch 16/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3214 - acc: 0.4322 - val_loss: 1.3441 - val_acc: 0.4467

Epoch 00016: val_loss improved from 1.35256 to 1.34414, saving model to model2/16-1.3441.hdf5
Epoch 17/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3127 - acc: 0.4322 - val_loss: 1.3376 - val_acc: 0.4467

Epoch 00017: val_loss improved from 1.34414 to 1.33755, saving model to model2/17-1.3376.hdf5
Epoch 18/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3061 - acc: 0.4322 - val_loss: 1.3316 - val_acc: 0.4467

Epoch 00018: val_loss improved from 1.33755 to 1.33158, saving model to model2/18-1.3316.hdf5
Epoch 19/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3000 - acc: 0.4322 - val_loss: 1.3254 - val_acc: 0.4467

Epoch 00019: val_loss improved from 1.33158 to 1.32537, saving model to model2/19-1.3254.hdf5
Epoch 20/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2954 - acc: 0.4322 - val_loss: 1.3219 - val_acc: 0.4467

Epoch 00020: val_loss improved from 1.32537 to 1.32188, saving model to model2/20-1.3219.hdf5
Epoch 21/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2917 - acc: 0.4322 - val_loss: 1.3187 - val_acc: 0.4467

Epoch 00021: val_loss improved from 1.32188 to 1.31875, saving model to model2/21-1.3187.hdf5
Epoch 22/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2885 - acc: 0.4322 - val_loss: 1.3167 - val_acc: 0.4467

Epoch 00022: val_loss improved from 1.31875 to 1.31673, saving model to model2/22-1.3167.hdf5
Epoch 23/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2862 - acc: 0.4322 - val_loss: 1.3151 - val_acc: 0.4467

Epoch 00023: val_loss improved from 1.31673 to 1.31507, saving model to model2/23-1.3151.hdf5
Epoch 24/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2837 - acc: 0.4322 - val_loss: 1.3135 - val_acc: 0.4467

Epoch 00024: val_loss improved from 1.31507 to 1.31350, saving model to model2/24-1.3135.hdf5
Epoch 25/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2814 - acc: 0.4322 - val_loss: 1.3121 - val_acc: 0.4467

Epoch 00025: val_loss improved from 1.31350 to 1.31214, saving model to model2/25-1.3121.hdf5
Epoch 26/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2803 - acc: 0.4322 - val_loss: 1.3113 - val_acc: 0.4467

Epoch 00026: val_loss improved from 1.31214 to 1.31134, saving model to model2/26-1.3113.hdf5
Epoch 27/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2783 - acc: 0.4322 - val_loss: 1.3085 - val_acc: 0.4467

Epoch 00027: val_loss improved from 1.31134 to 1.30850, saving model to model2/27-1.3085.hdf5
Epoch 28/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2773 - acc: 0.4322 - val_loss: 1.3069 - val_acc: 0.4467

Epoch 00028: val_loss improved from 1.30850 to 1.30693, saving model to model2/28-1.3069.hdf5
Epoch 29/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2761 - acc: 0.4322 - val_loss: 1.3076 - val_acc: 0.4467

Epoch 00029: val_loss did not improve from 1.30693
Epoch 30/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2756 - acc: 0.4322 - val_loss: 1.3063 - val_acc: 0.4467

Epoch 00030: val_loss improved from 1.30693 to 1.30630, saving model to model2/30-1.3063.hdf5
Epoch 31/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2748 - acc: 0.4322 - val_loss: 1.3067 - val_acc: 0.4467

Epoch 00031: val_loss did not improve from 1.30630
Epoch 32/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2734 - acc: 0.4322 - val_loss: 1.3043 - val_acc: 0.4467

Epoch 00032: val_loss improved from 1.30630 to 1.30426, saving model to model2/32-1.3043.hdf5
Epoch 33/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2734 - acc: 0.4322 - val_loss: 1.3038 - val_acc: 0.4467

Epoch 00033: val_loss improved from 1.30426 to 1.30382, saving model to model2/33-1.3038.hdf5
Epoch 34/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2727 - acc: 0.4322 - val_loss: 1.3040 - val_acc: 0.4467

Epoch 00034: val_loss did not improve from 1.30382
Epoch 35/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2716 - acc: 0.4322 - val_loss: 1.3035 - val_acc: 0.4467

Epoch 00035: val_loss improved from 1.30382 to 1.30345, saving model to model2/35-1.3035.hdf5
Epoch 36/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2709 - acc: 0.4322 - val_loss: 1.3039 - val_acc: 0.4467

Epoch 00036: val_loss did not improve from 1.30345
Epoch 37/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2707 - acc: 0.4322 - val_loss: 1.3045 - val_acc: 0.4467

Epoch 00037: val_loss did not improve from 1.30345
Epoch 38/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2699 - acc: 0.4322 - val_loss: 1.3014 - val_acc: 0.4467

Epoch 00038: val_loss improved from 1.30345 to 1.30144, saving model to model2/38-1.3014.hdf5
Epoch 39/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2698 - acc: 0.4322 - val_loss: 1.3010 - val_acc: 0.4467

Epoch 00039: val_loss improved from 1.30144 to 1.30102, saving model to model2/39-1.3010.hdf5
Epoch 40/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2692 - acc: 0.4322 - val_loss: 1.3018 - val_acc: 0.4467

Epoch 00040: val_loss did not improve from 1.30102
Epoch 41/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2684 - acc: 0.4322 - val_loss: 1.3014 - val_acc: 0.4467

Epoch 00041: val_loss did not improve from 1.30102
Epoch 42/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2681 - acc: 0.4322 - val_loss: 1.3007 - val_acc: 0.4467

Epoch 00042: val_loss improved from 1.30102 to 1.30066, saving model to model2/42-1.3007.hdf5
Epoch 43/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2684 - acc: 0.4322 - val_loss: 1.3028 - val_acc: 0.4467

Epoch 00043: val_loss did not improve from 1.30066
Epoch 44/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2676 - acc: 0.4322 - val_loss: 1.3007 - val_acc: 0.4467

Epoch 00044: val_loss did not improve from 1.30066
Epoch 45/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2675 - acc: 0.4322 - val_loss: 1.2995 - val_acc: 0.4467

Epoch 00045: val_loss improved from 1.30066 to 1.29953, saving model to model2/45-1.2995.hdf5
Epoch 46/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2669 - acc: 0.4322 - val_loss: 1.2999 - val_acc: 0.4467

Epoch 00046: val_loss did not improve from 1.29953
Epoch 47/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2669 - acc: 0.4322 - val_loss: 1.3020 - val_acc: 0.4467

Epoch 00047: val_loss did not improve from 1.29953
Epoch 48/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2667 - acc: 0.4322 - val_loss: 1.3005 - val_acc: 0.4467

Epoch 00048: val_loss did not improve from 1.29953
Epoch 49/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2662 - acc: 0.4322 - val_loss: 1.3001 - val_acc: 0.4467

Epoch 00049: val_loss did not improve from 1.29953
Epoch 50/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2659 - acc: 0.4322 - val_loss: 1.2994 - val_acc: 0.4467

Epoch 00050: val_loss improved from 1.29953 to 1.29940, saving model to model2/50-1.2994.hdf5
Epoch 51/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2663 - acc: 0.4322 - val_loss: 1.2976 - val_acc: 0.4467

Epoch 00051: val_loss improved from 1.29940 to 1.29756, saving model to model2/51-1.2976.hdf5
Epoch 52/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2654 - acc: 0.4322 - val_loss: 1.2989 - val_acc: 0.4467

Epoch 00052: val_loss did not improve from 1.29756
Epoch 53/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2648 - acc: 0.4322 - val_loss: 1.2980 - val_acc: 0.4467

Epoch 00053: val_loss did not improve from 1.29756
Epoch 54/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2648 - acc: 0.4322 - val_loss: 1.2985 - val_acc: 0.4467

Epoch 00054: val_loss did not improve from 1.29756
Epoch 55/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2657 - acc: 0.4322 - val_loss: 1.2966 - val_acc: 0.4467

Epoch 00055: val_loss improved from 1.29756 to 1.29662, saving model to model2/55-1.2966.hdf5
Epoch 56/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2642 - acc: 0.4322 - val_loss: 1.2939 - val_acc: 0.4467

Epoch 00056: val_loss improved from 1.29662 to 1.29392, saving model to model2/56-1.2939.hdf5
Epoch 57/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2613 - acc: 0.4322 - val_loss: 1.2920 - val_acc: 0.4497

Epoch 00057: val_loss improved from 1.29392 to 1.29199, saving model to model2/57-1.2920.hdf5
Epoch 58/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2603 - acc: 0.4335 - val_loss: 1.2876 - val_acc: 0.4482

Epoch 00058: val_loss improved from 1.29199 to 1.28764, saving model to model2/58-1.2876.hdf5
Epoch 59/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2595 - acc: 0.4324 - val_loss: 1.2854 - val_acc: 0.4549

Epoch 00059: val_loss improved from 1.28764 to 1.28544, saving model to model2/59-1.2854.hdf5
Epoch 60/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2599 - acc: 0.4326 - val_loss: 1.2874 - val_acc: 0.4544

Epoch 00060: val_loss did not improve from 1.28544
Epoch 61/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2578 - acc: 0.4350 - val_loss: 1.2832 - val_acc: 0.4595

Epoch 00061: val_loss improved from 1.28544 to 1.28319, saving model to model2/61-1.2832.hdf5
Epoch 62/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2572 - acc: 0.4337 - val_loss: 1.2841 - val_acc: 0.4549

Epoch 00062: val_loss did not improve from 1.28319
Epoch 63/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2576 - acc: 0.4333 - val_loss: 1.2833 - val_acc: 0.4569

Epoch 00063: val_loss did not improve from 1.28319
Epoch 64/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2558 - acc: 0.4368 - val_loss: 1.2816 - val_acc: 0.4615

Epoch 00064: val_loss improved from 1.28319 to 1.28157, saving model to model2/64-1.2816.hdf5
Epoch 65/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2565 - acc: 0.4344 - val_loss: 1.2825 - val_acc: 0.4559

Epoch 00065: val_loss did not improve from 1.28157
Epoch 66/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2573 - acc: 0.4333 - val_loss: 1.2874 - val_acc: 0.4477

Epoch 00066: val_loss did not improve from 1.28157
Epoch 67/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2554 - acc: 0.4350 - val_loss: 1.2789 - val_acc: 0.4600

Epoch 00067: val_loss improved from 1.28157 to 1.27885, saving model to model2/67-1.2789.hdf5
Epoch 68/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2536 - acc: 0.4352 - val_loss: 1.2771 - val_acc: 0.4585

Epoch 00068: val_loss improved from 1.27885 to 1.27709, saving model to model2/68-1.2771.hdf5
Epoch 69/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2540 - acc: 0.4319 - val_loss: 1.2761 - val_acc: 0.4631

Epoch 00069: val_loss improved from 1.27709 to 1.27614, saving model to model2/69-1.2761.hdf5
Epoch 70/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2530 - acc: 0.4407 - val_loss: 1.2819 - val_acc: 0.4636

Epoch 00070: val_loss did not improve from 1.27614
Epoch 71/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2521 - acc: 0.4374 - val_loss: 1.2753 - val_acc: 0.4662

Epoch 00071: val_loss improved from 1.27614 to 1.27532, saving model to model2/71-1.2753.hdf5
Epoch 72/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2521 - acc: 0.4341 - val_loss: 1.2740 - val_acc: 0.4636

Epoch 00072: val_loss improved from 1.27532 to 1.27403, saving model to model2/72-1.2740.hdf5
Epoch 73/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2516 - acc: 0.4427 - val_loss: 1.2777 - val_acc: 0.4656

Epoch 00073: val_loss did not improve from 1.27403
Epoch 74/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2502 - acc: 0.4396 - val_loss: 1.2746 - val_acc: 0.4656

Epoch 00074: val_loss did not improve from 1.27403
Epoch 75/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2504 - acc: 0.4445 - val_loss: 1.2735 - val_acc: 0.4656

Epoch 00075: val_loss improved from 1.27403 to 1.27352, saving model to model2/75-1.2735.hdf5
Epoch 76/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2510 - acc: 0.4401 - val_loss: 1.2752 - val_acc: 0.4646

Epoch 00076: val_loss did not improve from 1.27352
Epoch 77/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2492 - acc: 0.4385 - val_loss: 1.2727 - val_acc: 0.4662

Epoch 00077: val_loss improved from 1.27352 to 1.27272, saving model to model2/77-1.2727.hdf5
Epoch 78/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2483 - acc: 0.4442 - val_loss: 1.2742 - val_acc: 0.4723

Epoch 00078: val_loss did not improve from 1.27272
Epoch 79/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2487 - acc: 0.4458 - val_loss: 1.2733 - val_acc: 0.4692

Epoch 00079: val_loss did not improve from 1.27272
Epoch 80/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2483 - acc: 0.4414 - val_loss: 1.2728 - val_acc: 0.4723

Epoch 00080: val_loss did not improve from 1.27272
Epoch 81/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2463 - acc: 0.4508 - val_loss: 1.2701 - val_acc: 0.4728

Epoch 00081: val_loss improved from 1.27272 to 1.27005, saving model to model2/81-1.2701.hdf5
Epoch 82/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2488 - acc: 0.4493 - val_loss: 1.2712 - val_acc: 0.4631

Epoch 00082: val_loss did not improve from 1.27005
Epoch 83/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2478 - acc: 0.4374 - val_loss: 1.2745 - val_acc: 0.4677

Epoch 00083: val_loss did not improve from 1.27005
Epoch 84/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2471 - acc: 0.4403 - val_loss: 1.2700 - val_acc: 0.4713

Epoch 00084: val_loss improved from 1.27005 to 1.26999, saving model to model2/84-1.2700.hdf5
Epoch 85/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2455 - acc: 0.4447 - val_loss: 1.2679 - val_acc: 0.4708

Epoch 00085: val_loss improved from 1.26999 to 1.26792, saving model to model2/85-1.2679.hdf5
Epoch 86/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2461 - acc: 0.4436 - val_loss: 1.2656 - val_acc: 0.4754

Epoch 00086: val_loss improved from 1.26792 to 1.26562, saving model to model2/86-1.2656.hdf5
Epoch 87/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2431 - acc: 0.4478 - val_loss: 1.2682 - val_acc: 0.4790

Epoch 00087: val_loss did not improve from 1.26562
Epoch 88/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2424 - acc: 0.4502 - val_loss: 1.2653 - val_acc: 0.4754

Epoch 00088: val_loss improved from 1.26562 to 1.26533, saving model to model2/88-1.2653.hdf5
Epoch 89/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2420 - acc: 0.4453 - val_loss: 1.2639 - val_acc: 0.4759

Epoch 00089: val_loss improved from 1.26533 to 1.26391, saving model to model2/89-1.2639.hdf5
Epoch 90/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2405 - acc: 0.4526 - val_loss: 1.2666 - val_acc: 0.4831

Epoch 00090: val_loss did not improve from 1.26391
Epoch 91/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2425 - acc: 0.4460 - val_loss: 1.2627 - val_acc: 0.4744

Epoch 00091: val_loss improved from 1.26391 to 1.26271, saving model to model2/91-1.2627.hdf5
Epoch 92/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2414 - acc: 0.4495 - val_loss: 1.2586 - val_acc: 0.4785

Epoch 00092: val_loss improved from 1.26271 to 1.25860, saving model to model2/92-1.2586.hdf5
Epoch 93/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2381 - acc: 0.4489 - val_loss: 1.2574 - val_acc: 0.4841

Epoch 00093: val_loss improved from 1.25860 to 1.25740, saving model to model2/93-1.2574.hdf5
Epoch 94/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2367 - acc: 0.4546 - val_loss: 1.2588 - val_acc: 0.4795

Epoch 00094: val_loss did not improve from 1.25740
Epoch 95/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2345 - acc: 0.4590 - val_loss: 1.2560 - val_acc: 0.4897

Epoch 00095: val_loss improved from 1.25740 to 1.25604, saving model to model2/95-1.2560.hdf5
Epoch 96/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2332 - acc: 0.4599 - val_loss: 1.2533 - val_acc: 0.4964

Epoch 00096: val_loss improved from 1.25604 to 1.25330, saving model to model2/96-1.2533.hdf5
Epoch 97/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2314 - acc: 0.4643 - val_loss: 1.2523 - val_acc: 0.4933

Epoch 00097: val_loss improved from 1.25330 to 1.25226, saving model to model2/97-1.2523.hdf5
Epoch 98/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2296 - acc: 0.4665 - val_loss: 1.2465 - val_acc: 0.4913

Epoch 00098: val_loss improved from 1.25226 to 1.24645, saving model to model2/98-1.2465.hdf5
Epoch 99/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2240 - acc: 0.4689 - val_loss: 1.2423 - val_acc: 0.4836

Epoch 00099: val_loss improved from 1.24645 to 1.24227, saving model to model2/99-1.2423.hdf5
Epoch 100/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2128 - acc: 0.4596 - val_loss: 1.2494 - val_acc: 0.4697

Epoch 00100: val_loss did not improve from 1.24227
Epoch 101/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2120 - acc: 0.4651 - val_loss: 1.2314 - val_acc: 0.4805

Epoch 00101: val_loss improved from 1.24227 to 1.23136, saving model to model2/101-1.2314.hdf5
Epoch 102/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1997 - acc: 0.4625 - val_loss: 1.2249 - val_acc: 0.4872

Epoch 00102: val_loss improved from 1.23136 to 1.22490, saving model to model2/102-1.2249.hdf5
Epoch 103/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1933 - acc: 0.4667 - val_loss: 1.2316 - val_acc: 0.4938

Epoch 00103: val_loss did not improve from 1.22490
Epoch 104/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1982 - acc: 0.4777 - val_loss: 1.2182 - val_acc: 0.4779

Epoch 00104: val_loss improved from 1.22490 to 1.21823, saving model to model2/104-1.2182.hdf5
Epoch 105/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1882 - acc: 0.4783 - val_loss: 1.2122 - val_acc: 0.4749

Epoch 00105: val_loss improved from 1.21823 to 1.21219, saving model to model2/105-1.2122.hdf5
Epoch 106/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1766 - acc: 0.4854 - val_loss: 1.2152 - val_acc: 0.4867

Epoch 00106: val_loss did not improve from 1.21219
Epoch 107/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1720 - acc: 0.4772 - val_loss: 1.2057 - val_acc: 0.4995

Epoch 00107: val_loss improved from 1.21219 to 1.20574, saving model to model2/107-1.2057.hdf5
Epoch 108/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1637 - acc: 0.4937 - val_loss: 1.1963 - val_acc: 0.5031

Epoch 00108: val_loss improved from 1.20574 to 1.19625, saving model to model2/108-1.1963.hdf5
Epoch 109/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1586 - acc: 0.5027 - val_loss: 1.1902 - val_acc: 0.5051

Epoch 00109: val_loss improved from 1.19625 to 1.19023, saving model to model2/109-1.1902.hdf5
Epoch 110/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1558 - acc: 0.4986 - val_loss: 1.1902 - val_acc: 0.5067

Epoch 00110: val_loss improved from 1.19023 to 1.19016, saving model to model2/110-1.1902.hdf5
Epoch 111/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1509 - acc: 0.4955 - val_loss: 1.1777 - val_acc: 0.5015

Epoch 00111: val_loss improved from 1.19016 to 1.17773, saving model to model2/111-1.1777.hdf5
Epoch 112/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1450 - acc: 0.5036 - val_loss: 1.1765 - val_acc: 0.5097

Epoch 00112: val_loss improved from 1.17773 to 1.17650, saving model to model2/112-1.1765.hdf5
Epoch 113/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1400 - acc: 0.5115 - val_loss: 1.1816 - val_acc: 0.5133

Epoch 00113: val_loss did not improve from 1.17650
Epoch 114/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1408 - acc: 0.5060 - val_loss: 1.1669 - val_acc: 0.5041

Epoch 00114: val_loss improved from 1.17650 to 1.16694, saving model to model2/114-1.1669.hdf5
Epoch 115/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1372 - acc: 0.5005 - val_loss: 1.1770 - val_acc: 0.5046

Epoch 00115: val_loss did not improve from 1.16694
Epoch 116/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1354 - acc: 0.5074 - val_loss: 1.1636 - val_acc: 0.5133

Epoch 00116: val_loss improved from 1.16694 to 1.16361, saving model to model2/116-1.1636.hdf5
Epoch 117/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1301 - acc: 0.5082 - val_loss: 1.1868 - val_acc: 0.5000

Epoch 00117: val_loss did not improve from 1.16361
Epoch 118/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1484 - acc: 0.4953 - val_loss: 1.1583 - val_acc: 0.5190

Epoch 00118: val_loss improved from 1.16361 to 1.15830, saving model to model2/118-1.1583.hdf5
Epoch 119/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1288 - acc: 0.5052 - val_loss: 1.1557 - val_acc: 0.5108

Epoch 00119: val_loss improved from 1.15830 to 1.15570, saving model to model2/119-1.1557.hdf5
Epoch 120/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1225 - acc: 0.5133 - val_loss: 1.1533 - val_acc: 0.5246

Epoch 00120: val_loss improved from 1.15570 to 1.15327, saving model to model2/120-1.1533.hdf5
Epoch 121/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1198 - acc: 0.5166 - val_loss: 1.1554 - val_acc: 0.5185

Epoch 00121: val_loss did not improve from 1.15327
Epoch 122/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1234 - acc: 0.5155 - val_loss: 1.1495 - val_acc: 0.5221

Epoch 00122: val_loss improved from 1.15327 to 1.14952, saving model to model2/122-1.1495.hdf5
Epoch 123/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1213 - acc: 0.5203 - val_loss: 1.1884 - val_acc: 0.5087

Epoch 00123: val_loss did not improve from 1.14952
Epoch 124/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1383 - acc: 0.4964 - val_loss: 1.1929 - val_acc: 0.4764

Epoch 00124: val_loss did not improve from 1.14952
Epoch 125/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1394 - acc: 0.4975 - val_loss: 1.1599 - val_acc: 0.5067

Epoch 00125: val_loss did not improve from 1.14952
Epoch 126/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1348 - acc: 0.5019 - val_loss: 1.1543 - val_acc: 0.5072

Epoch 00126: val_loss did not improve from 1.14952
Epoch 127/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1189 - acc: 0.5091 - val_loss: 1.1633 - val_acc: 0.5036

Epoch 00127: val_loss did not improve from 1.14952
Epoch 128/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1146 - acc: 0.5129 - val_loss: 1.1493 - val_acc: 0.5174

Epoch 00128: val_loss improved from 1.14952 to 1.14926, saving model to model2/128-1.1493.hdf5
Epoch 129/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1102 - acc: 0.5170 - val_loss: 1.1604 - val_acc: 0.5062

Epoch 00129: val_loss did not improve from 1.14926
Epoch 130/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1133 - acc: 0.5137 - val_loss: 1.1531 - val_acc: 0.5133

Epoch 00130: val_loss did not improve from 1.14926
Epoch 131/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1121 - acc: 0.5144 - val_loss: 1.1459 - val_acc: 0.5133

Epoch 00131: val_loss improved from 1.14926 to 1.14590, saving model to model2/131-1.1459.hdf5
Epoch 132/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1063 - acc: 0.5201 - val_loss: 1.1469 - val_acc: 0.5133

Epoch 00132: val_loss did not improve from 1.14590
Epoch 133/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1045 - acc: 0.5228 - val_loss: 1.1415 - val_acc: 0.5169

Epoch 00133: val_loss improved from 1.14590 to 1.14150, saving model to model2/133-1.1415.hdf5
Epoch 134/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1027 - acc: 0.5217 - val_loss: 1.1521 - val_acc: 0.5077

Epoch 00134: val_loss did not improve from 1.14150
Epoch 135/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1209 - acc: 0.5082 - val_loss: 1.1468 - val_acc: 0.5179

Epoch 00135: val_loss did not improve from 1.14150
Epoch 136/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1152 - acc: 0.5151 - val_loss: 1.1687 - val_acc: 0.5144

Epoch 00136: val_loss did not improve from 1.14150
Epoch 137/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1160 - acc: 0.5170 - val_loss: 1.1464 - val_acc: 0.5159

Epoch 00137: val_loss did not improve from 1.14150
Epoch 138/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1075 - acc: 0.5159 - val_loss: 1.1359 - val_acc: 0.5190

Epoch 00138: val_loss improved from 1.14150 to 1.13590, saving model to model2/138-1.1359.hdf5
Epoch 139/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1010 - acc: 0.5212 - val_loss: 1.1340 - val_acc: 0.5210

Epoch 00139: val_loss improved from 1.13590 to 1.13400, saving model to model2/139-1.1340.hdf5
Epoch 140/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0965 - acc: 0.5265 - val_loss: 1.1355 - val_acc: 0.5190

Epoch 00140: val_loss did not improve from 1.13400
Epoch 141/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0948 - acc: 0.5280 - val_loss: 1.1425 - val_acc: 0.5108

Epoch 00141: val_loss did not improve from 1.13400
Epoch 142/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0929 - acc: 0.5287 - val_loss: 1.1305 - val_acc: 0.5215

Epoch 00142: val_loss improved from 1.13400 to 1.13049, saving model to model2/142-1.1305.hdf5
Epoch 143/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1033 - acc: 0.5230 - val_loss: 1.1367 - val_acc: 0.5226

Epoch 00143: val_loss did not improve from 1.13049
Epoch 144/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1157 - acc: 0.5056 - val_loss: 1.1603 - val_acc: 0.5005

Epoch 00144: val_loss did not improve from 1.13049
Epoch 145/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1124 - acc: 0.5098 - val_loss: 1.1297 - val_acc: 0.5333

Epoch 00145: val_loss improved from 1.13049 to 1.12970, saving model to model2/145-1.1297.hdf5
Epoch 146/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0907 - acc: 0.5362 - val_loss: 1.1268 - val_acc: 0.5246

Epoch 00146: val_loss improved from 1.12970 to 1.12680, saving model to model2/146-1.1268.hdf5
Epoch 147/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0889 - acc: 0.5298 - val_loss: 1.1903 - val_acc: 0.4738

Epoch 00147: val_loss did not improve from 1.12680
Epoch 148/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1144 - acc: 0.5069 - val_loss: 1.1294 - val_acc: 0.5210

Epoch 00148: val_loss did not improve from 1.12680
Epoch 149/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0985 - acc: 0.5252 - val_loss: 1.1270 - val_acc: 0.5297

Epoch 00149: val_loss did not improve from 1.12680
Epoch 150/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0907 - acc: 0.5355 - val_loss: 1.1240 - val_acc: 0.5287

Epoch 00150: val_loss improved from 1.12680 to 1.12399, saving model to model2/150-1.1240.hdf5
Epoch 151/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0861 - acc: 0.5263 - val_loss: 1.1267 - val_acc: 0.5267

Epoch 00151: val_loss did not improve from 1.12399
Epoch 152/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0843 - acc: 0.5318 - val_loss: 1.1221 - val_acc: 0.5344

Epoch 00152: val_loss improved from 1.12399 to 1.12208, saving model to model2/152-1.1221.hdf5
Epoch 153/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0854 - acc: 0.5338 - val_loss: 1.1243 - val_acc: 0.5364

Epoch 00153: val_loss did not improve from 1.12208
Epoch 154/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0891 - acc: 0.5329 - val_loss: 1.1240 - val_acc: 0.5267

Epoch 00154: val_loss did not improve from 1.12208
Epoch 155/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0937 - acc: 0.5197 - val_loss: 1.1280 - val_acc: 0.5297

Epoch 00155: val_loss did not improve from 1.12208
Epoch 156/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0912 - acc: 0.5287 - val_loss: 1.1195 - val_acc: 0.5308

Epoch 00156: val_loss improved from 1.12208 to 1.11948, saving model to model2/156-1.1195.hdf5
Epoch 157/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0842 - acc: 0.5307 - val_loss: 1.1176 - val_acc: 0.5272

Epoch 00157: val_loss improved from 1.11948 to 1.11758, saving model to model2/157-1.1176.hdf5
Epoch 158/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0863 - acc: 0.5338 - val_loss: 1.1203 - val_acc: 0.5241

Epoch 00158: val_loss did not improve from 1.11758
Epoch 159/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0818 - acc: 0.5307 - val_loss: 1.1192 - val_acc: 0.5221

Epoch 00159: val_loss did not improve from 1.11758
Epoch 160/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0809 - acc: 0.5346 - val_loss: 1.1228 - val_acc: 0.5256

Epoch 00160: val_loss did not improve from 1.11758
Epoch 161/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0781 - acc: 0.5362 - val_loss: 1.1266 - val_acc: 0.5292

Epoch 00161: val_loss did not improve from 1.11758
Epoch 162/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0834 - acc: 0.5320 - val_loss: 1.1190 - val_acc: 0.5282

Epoch 00162: val_loss did not improve from 1.11758
Epoch 163/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0781 - acc: 0.5410 - val_loss: 1.1163 - val_acc: 0.5231

Epoch 00163: val_loss improved from 1.11758 to 1.11632, saving model to model2/163-1.1163.hdf5
Epoch 164/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0786 - acc: 0.5386 - val_loss: 1.1193 - val_acc: 0.5205

Epoch 00164: val_loss did not improve from 1.11632
Epoch 165/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0837 - acc: 0.5342 - val_loss: 1.1124 - val_acc: 0.5369

Epoch 00165: val_loss improved from 1.11632 to 1.11241, saving model to model2/165-1.1124.hdf5
Epoch 166/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0780 - acc: 0.5355 - val_loss: 1.1136 - val_acc: 0.5282

Epoch 00166: val_loss did not improve from 1.11241
Epoch 167/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0756 - acc: 0.5452 - val_loss: 1.1161 - val_acc: 0.5282

Epoch 00167: val_loss did not improve from 1.11241
Epoch 168/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0753 - acc: 0.5393 - val_loss: 1.1102 - val_acc: 0.5328

Epoch 00168: val_loss improved from 1.11241 to 1.11016, saving model to model2/168-1.1102.hdf5
Epoch 169/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0747 - acc: 0.5335 - val_loss: 1.1116 - val_acc: 0.5277

Epoch 00169: val_loss did not improve from 1.11016
Epoch 170/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0762 - acc: 0.5349 - val_loss: 1.1517 - val_acc: 0.4944

Epoch 00170: val_loss did not improve from 1.11016
Epoch 171/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0911 - acc: 0.5219 - val_loss: 1.1230 - val_acc: 0.5272

Epoch 00171: val_loss did not improve from 1.11016
Epoch 172/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0843 - acc: 0.5357 - val_loss: 1.1500 - val_acc: 0.4933

Epoch 00172: val_loss did not improve from 1.11016
Epoch 173/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0969 - acc: 0.5166 - val_loss: 1.1288 - val_acc: 0.5174

Epoch 00173: val_loss did not improve from 1.11016
Epoch 174/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0747 - acc: 0.5353 - val_loss: 1.1095 - val_acc: 0.5282

Epoch 00174: val_loss improved from 1.11016 to 1.10948, saving model to model2/174-1.1095.hdf5
Epoch 175/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0720 - acc: 0.5344 - val_loss: 1.1231 - val_acc: 0.5195

Epoch 00175: val_loss did not improve from 1.10948
Epoch 176/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0757 - acc: 0.5322 - val_loss: 1.1102 - val_acc: 0.5282

Epoch 00176: val_loss did not improve from 1.10948
Epoch 177/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0707 - acc: 0.5377 - val_loss: 1.1069 - val_acc: 0.5328

Epoch 00177: val_loss improved from 1.10948 to 1.10686, saving model to model2/177-1.1069.hdf5
Epoch 178/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0725 - acc: 0.5377 - val_loss: 1.1126 - val_acc: 0.5256

Epoch 00178: val_loss did not improve from 1.10686
Epoch 179/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0728 - acc: 0.5423 - val_loss: 1.1043 - val_acc: 0.5303

Epoch 00179: val_loss improved from 1.10686 to 1.10429, saving model to model2/179-1.1043.hdf5
Epoch 180/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0690 - acc: 0.5395 - val_loss: 1.1117 - val_acc: 0.5262

Epoch 00180: val_loss did not improve from 1.10429
Epoch 181/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0708 - acc: 0.5384 - val_loss: 1.1106 - val_acc: 0.5262

Epoch 00181: val_loss did not improve from 1.10429
Epoch 182/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0668 - acc: 0.5443 - val_loss: 1.1045 - val_acc: 0.5308

Epoch 00182: val_loss did not improve from 1.10429
Epoch 183/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0689 - acc: 0.5395 - val_loss: 1.1153 - val_acc: 0.5282

Epoch 00183: val_loss did not improve from 1.10429
Epoch 184/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0760 - acc: 0.5331 - val_loss: 1.1337 - val_acc: 0.5123

Epoch 00184: val_loss did not improve from 1.10429
Epoch 185/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0926 - acc: 0.5236 - val_loss: 1.1253 - val_acc: 0.5215

Epoch 00185: val_loss did not improve from 1.10429
Epoch 186/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0726 - acc: 0.5353 - val_loss: 1.1405 - val_acc: 0.4990

Epoch 00186: val_loss did not improve from 1.10429
Epoch 187/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0815 - acc: 0.5239 - val_loss: 1.1248 - val_acc: 0.5169

Epoch 00187: val_loss did not improve from 1.10429
Epoch 188/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0673 - acc: 0.5395 - val_loss: 1.1109 - val_acc: 0.5292

Epoch 00188: val_loss did not improve from 1.10429
Epoch 189/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0801 - acc: 0.5386 - val_loss: 1.1359 - val_acc: 0.4979

Epoch 00189: val_loss did not improve from 1.10429
Epoch 190/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0988 - acc: 0.5197 - val_loss: 1.1077 - val_acc: 0.5256

Epoch 00190: val_loss did not improve from 1.10429
Epoch 191/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0901 - acc: 0.5247 - val_loss: 1.1339 - val_acc: 0.5128

Epoch 00191: val_loss did not improve from 1.10429
Epoch 192/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0813 - acc: 0.5305 - val_loss: 1.1559 - val_acc: 0.4872

Epoch 00192: val_loss did not improve from 1.10429
Epoch 193/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0962 - acc: 0.5159 - val_loss: 1.1577 - val_acc: 0.4851

Epoch 00193: val_loss did not improve from 1.10429
Epoch 194/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0891 - acc: 0.5219 - val_loss: 1.1078 - val_acc: 0.5282

Epoch 00194: val_loss did not improve from 1.10429
Epoch 195/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0745 - acc: 0.5333 - val_loss: 1.1151 - val_acc: 0.5221

Epoch 00195: val_loss did not improve from 1.10429
Epoch 196/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0780 - acc: 0.5313 - val_loss: 1.1052 - val_acc: 0.5349

Epoch 00196: val_loss did not improve from 1.10429
Epoch 197/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0687 - acc: 0.5379 - val_loss: 1.1376 - val_acc: 0.5000

Epoch 00197: val_loss did not improve from 1.10429
Epoch 198/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0731 - acc: 0.5342 - val_loss: 1.1029 - val_acc: 0.5364

Epoch 00198: val_loss improved from 1.10429 to 1.10291, saving model to model2/198-1.1029.hdf5
Epoch 199/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0641 - acc: 0.5423 - val_loss: 1.1026 - val_acc: 0.5287

Epoch 00199: val_loss improved from 1.10291 to 1.10255, saving model to model2/199-1.1026.hdf5
Epoch 200/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0658 - acc: 0.5410 - val_loss: 1.1009 - val_acc: 0.5359

Epoch 00200: val_loss improved from 1.10255 to 1.10088, saving model to model2/200-1.1009.hdf5
Epoch 201/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0642 - acc: 0.5399 - val_loss: 1.1060 - val_acc: 0.5308

Epoch 00201: val_loss did not improve from 1.10088
Epoch 202/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0749 - acc: 0.5340 - val_loss: 1.1239 - val_acc: 0.5123

Epoch 00202: val_loss did not improve from 1.10088
Epoch 203/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0780 - acc: 0.5296 - val_loss: 1.1107 - val_acc: 0.5308

Epoch 00203: val_loss did not improve from 1.10088
Epoch 204/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0653 - acc: 0.5393 - val_loss: 1.1007 - val_acc: 0.5308

Epoch 00204: val_loss improved from 1.10088 to 1.10065, saving model to model2/204-1.1007.hdf5
Epoch 205/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0684 - acc: 0.5430 - val_loss: 1.0998 - val_acc: 0.5323

Epoch 00205: val_loss improved from 1.10065 to 1.09979, saving model to model2/205-1.0998.hdf5
Epoch 206/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0672 - acc: 0.5393 - val_loss: 1.1017 - val_acc: 0.5349

Epoch 00206: val_loss did not improve from 1.09979
Epoch 207/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0684 - acc: 0.5384 - val_loss: 1.1001 - val_acc: 0.5349

Epoch 00207: val_loss did not improve from 1.09979
Epoch 208/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0711 - acc: 0.5327 - val_loss: 1.1064 - val_acc: 0.5303

Epoch 00208: val_loss did not improve from 1.09979
Epoch 209/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0674 - acc: 0.5362 - val_loss: 1.1053 - val_acc: 0.5282

Epoch 00209: val_loss did not improve from 1.09979
Epoch 210/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0638 - acc: 0.5373 - val_loss: 1.1041 - val_acc: 0.5297

Epoch 00210: val_loss did not improve from 1.09979
Epoch 211/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0622 - acc: 0.5406 - val_loss: 1.1018 - val_acc: 0.5338

Epoch 00211: val_loss did not improve from 1.09979
Epoch 212/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0641 - acc: 0.5423 - val_loss: 1.0995 - val_acc: 0.5338

Epoch 00212: val_loss improved from 1.09979 to 1.09953, saving model to model2/212-1.0995.hdf5
Epoch 213/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0600 - acc: 0.5461 - val_loss: 1.0994 - val_acc: 0.5344

Epoch 00213: val_loss improved from 1.09953 to 1.09945, saving model to model2/213-1.0994.hdf5
Epoch 214/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0623 - acc: 0.5432 - val_loss: 1.1118 - val_acc: 0.5215

Epoch 00214: val_loss did not improve from 1.09945
Epoch 215/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0617 - acc: 0.5445 - val_loss: 1.0968 - val_acc: 0.5364

Epoch 00215: val_loss improved from 1.09945 to 1.09675, saving model to model2/215-1.0968.hdf5
Epoch 216/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0606 - acc: 0.5395 - val_loss: 1.1002 - val_acc: 0.5236

Epoch 00216: val_loss did not improve from 1.09675
Epoch 217/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0650 - acc: 0.5353 - val_loss: 1.1297 - val_acc: 0.5108

Epoch 00217: val_loss did not improve from 1.09675
Epoch 218/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0629 - acc: 0.5432 - val_loss: 1.1096 - val_acc: 0.5241

Epoch 00218: val_loss did not improve from 1.09675
Epoch 219/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0605 - acc: 0.5443 - val_loss: 1.1026 - val_acc: 0.5287

Epoch 00219: val_loss did not improve from 1.09675
Epoch 220/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0618 - acc: 0.5393 - val_loss: 1.1078 - val_acc: 0.5241

Epoch 00220: val_loss did not improve from 1.09675
Epoch 221/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0700 - acc: 0.5313 - val_loss: 1.1110 - val_acc: 0.5190

Epoch 00221: val_loss did not improve from 1.09675
Epoch 222/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0744 - acc: 0.5280 - val_loss: 1.1091 - val_acc: 0.5277

Epoch 00222: val_loss did not improve from 1.09675
Epoch 223/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0605 - acc: 0.5417 - val_loss: 1.0958 - val_acc: 0.5328

Epoch 00223: val_loss improved from 1.09675 to 1.09577, saving model to model2/223-1.0958.hdf5
Epoch 224/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0581 - acc: 0.5489 - val_loss: 1.0999 - val_acc: 0.5369

Epoch 00224: val_loss did not improve from 1.09577
Epoch 225/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0650 - acc: 0.5364 - val_loss: 1.0996 - val_acc: 0.5344

Epoch 00225: val_loss did not improve from 1.09577
Epoch 226/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0621 - acc: 0.5388 - val_loss: 1.1337 - val_acc: 0.5036

Epoch 00226: val_loss did not improve from 1.09577
Epoch 227/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0869 - acc: 0.5265 - val_loss: 1.1016 - val_acc: 0.5374

Epoch 00227: val_loss did not improve from 1.09577
Epoch 228/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0620 - acc: 0.5421 - val_loss: 1.0961 - val_acc: 0.5338

Epoch 00228: val_loss did not improve from 1.09577
Epoch 229/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0588 - acc: 0.5465 - val_loss: 1.1105 - val_acc: 0.5246

Epoch 00229: val_loss did not improve from 1.09577
Epoch 230/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0702 - acc: 0.5355 - val_loss: 1.1079 - val_acc: 0.5282

Epoch 00230: val_loss did not improve from 1.09577
Epoch 231/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0586 - acc: 0.5423 - val_loss: 1.0969 - val_acc: 0.5287

Epoch 00231: val_loss did not improve from 1.09577
Epoch 232/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0605 - acc: 0.5415 - val_loss: 1.1199 - val_acc: 0.5067

Epoch 00232: val_loss did not improve from 1.09577
Epoch 233/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0629 - acc: 0.5406 - val_loss: 1.1062 - val_acc: 0.5282

Epoch 00233: val_loss did not improve from 1.09577
Epoch 234/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0602 - acc: 0.5404 - val_loss: 1.0974 - val_acc: 0.5328

Epoch 00234: val_loss did not improve from 1.09577
Epoch 235/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0559 - acc: 0.5478 - val_loss: 1.0971 - val_acc: 0.5385

Epoch 00235: val_loss did not improve from 1.09577
Epoch 236/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0549 - acc: 0.5498 - val_loss: 1.0935 - val_acc: 0.5395

Epoch 00236: val_loss improved from 1.09577 to 1.09348, saving model to model2/236-1.0935.hdf5
Epoch 237/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0561 - acc: 0.5428 - val_loss: 1.0952 - val_acc: 0.5390

Epoch 00237: val_loss did not improve from 1.09348
Epoch 238/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0542 - acc: 0.5516 - val_loss: 1.1029 - val_acc: 0.5318

Epoch 00238: val_loss did not improve from 1.09348
Epoch 239/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0537 - acc: 0.5478 - val_loss: 1.1083 - val_acc: 0.5226

Epoch 00239: val_loss did not improve from 1.09348
Epoch 240/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0541 - acc: 0.5478 - val_loss: 1.0973 - val_acc: 0.5303

Epoch 00240: val_loss did not improve from 1.09348
Epoch 241/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0595 - acc: 0.5417 - val_loss: 1.1139 - val_acc: 0.5164

Epoch 00241: val_loss did not improve from 1.09348
Epoch 242/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0630 - acc: 0.5434 - val_loss: 1.0969 - val_acc: 0.5385

Epoch 00242: val_loss did not improve from 1.09348
Epoch 243/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0568 - acc: 0.5434 - val_loss: 1.1052 - val_acc: 0.5256

Epoch 00243: val_loss did not improve from 1.09348
Epoch 244/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0620 - acc: 0.5404 - val_loss: 1.1221 - val_acc: 0.5046

Epoch 00244: val_loss did not improve from 1.09348
Epoch 245/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0663 - acc: 0.5316 - val_loss: 1.1022 - val_acc: 0.5262

Epoch 00245: val_loss did not improve from 1.09348
Epoch 246/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0615 - acc: 0.5434 - val_loss: 1.0931 - val_acc: 0.5328

Epoch 00246: val_loss improved from 1.09348 to 1.09312, saving model to model2/246-1.0931.hdf5
Epoch 247/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0554 - acc: 0.5415 - val_loss: 1.0998 - val_acc: 0.5338

Epoch 00247: val_loss did not improve from 1.09312
Epoch 248/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0582 - acc: 0.5384 - val_loss: 1.1268 - val_acc: 0.5133

Epoch 00248: val_loss did not improve from 1.09312
Epoch 249/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0803 - acc: 0.5329 - val_loss: 1.0936 - val_acc: 0.5441

Epoch 00249: val_loss did not improve from 1.09312
Epoch 250/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0577 - acc: 0.5404 - val_loss: 1.1163 - val_acc: 0.5190

Epoch 00250: val_loss did not improve from 1.09312
Epoch 251/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0623 - acc: 0.5428 - val_loss: 1.0952 - val_acc: 0.5364

Epoch 00251: val_loss did not improve from 1.09312
Epoch 252/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0664 - acc: 0.5327 - val_loss: 1.1037 - val_acc: 0.5262

Epoch 00252: val_loss did not improve from 1.09312
Epoch 253/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0619 - acc: 0.5463 - val_loss: 1.0930 - val_acc: 0.5385

Epoch 00253: val_loss improved from 1.09312 to 1.09304, saving model to model2/253-1.0930.hdf5
Epoch 254/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0537 - acc: 0.5470 - val_loss: 1.1218 - val_acc: 0.5138

Epoch 00254: val_loss did not improve from 1.09304
Epoch 255/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0565 - acc: 0.5412 - val_loss: 1.0940 - val_acc: 0.5421

Epoch 00255: val_loss did not improve from 1.09304
Epoch 256/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0527 - acc: 0.5467 - val_loss: 1.0945 - val_acc: 0.5323

Epoch 00256: val_loss did not improve from 1.09304
Epoch 257/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0518 - acc: 0.5465 - val_loss: 1.0907 - val_acc: 0.5385

Epoch 00257: val_loss improved from 1.09304 to 1.09068, saving model to model2/257-1.0907.hdf5
Epoch 258/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0537 - acc: 0.5509 - val_loss: 1.1009 - val_acc: 0.5277

Epoch 00258: val_loss did not improve from 1.09068
Epoch 259/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0565 - acc: 0.5465 - val_loss: 1.0909 - val_acc: 0.5415

Epoch 00259: val_loss did not improve from 1.09068
Epoch 260/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0640 - acc: 0.5362 - val_loss: 1.1144 - val_acc: 0.5236

Epoch 00260: val_loss did not improve from 1.09068
Epoch 261/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0764 - acc: 0.5254 - val_loss: 1.0972 - val_acc: 0.5282

Epoch 00261: val_loss did not improve from 1.09068
Epoch 262/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0726 - acc: 0.5316 - val_loss: 1.0918 - val_acc: 0.5359

Epoch 00262: val_loss did not improve from 1.09068
Epoch 263/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0538 - acc: 0.5443 - val_loss: 1.0948 - val_acc: 0.5272

Epoch 00263: val_loss did not improve from 1.09068
Epoch 264/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0562 - acc: 0.5379 - val_loss: 1.1226 - val_acc: 0.5082

Epoch 00264: val_loss did not improve from 1.09068
Epoch 265/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0651 - acc: 0.5329 - val_loss: 1.0876 - val_acc: 0.5379

Epoch 00265: val_loss improved from 1.09068 to 1.08758, saving model to model2/265-1.0876.hdf5
Epoch 266/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0504 - acc: 0.5485 - val_loss: 1.0885 - val_acc: 0.5400

Epoch 00266: val_loss did not improve from 1.08758
Epoch 267/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0525 - acc: 0.5536 - val_loss: 1.1195 - val_acc: 0.5108

Epoch 00267: val_loss did not improve from 1.08758
Epoch 268/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0587 - acc: 0.5377 - val_loss: 1.1274 - val_acc: 0.5015

Epoch 00268: val_loss did not improve from 1.08758
Epoch 269/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0574 - acc: 0.5371 - val_loss: 1.0946 - val_acc: 0.5287

Epoch 00269: val_loss did not improve from 1.08758
Epoch 270/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0570 - acc: 0.5296 - val_loss: 1.0892 - val_acc: 0.5405

Epoch 00270: val_loss did not improve from 1.08758
Epoch 271/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0490 - acc: 0.5522 - val_loss: 1.0955 - val_acc: 0.5287

Epoch 00271: val_loss did not improve from 1.08758
Epoch 272/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0492 - acc: 0.5467 - val_loss: 1.0892 - val_acc: 0.5390

Epoch 00272: val_loss did not improve from 1.08758
Epoch 273/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0526 - acc: 0.5505 - val_loss: 1.0875 - val_acc: 0.5426

Epoch 00273: val_loss improved from 1.08758 to 1.08752, saving model to model2/273-1.0875.hdf5
Epoch 274/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0516 - acc: 0.5456 - val_loss: 1.1189 - val_acc: 0.5215

Epoch 00274: val_loss did not improve from 1.08752
Epoch 275/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0617 - acc: 0.5390 - val_loss: 1.0919 - val_acc: 0.5405

Epoch 00275: val_loss did not improve from 1.08752
Epoch 276/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0544 - acc: 0.5421 - val_loss: 1.0868 - val_acc: 0.5415

Epoch 00276: val_loss improved from 1.08752 to 1.08679, saving model to model2/276-1.0868.hdf5
Epoch 277/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0524 - acc: 0.5452 - val_loss: 1.0890 - val_acc: 0.5328

Epoch 00277: val_loss did not improve from 1.08679
Epoch 278/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0603 - acc: 0.5364 - val_loss: 1.1119 - val_acc: 0.5215

Epoch 00278: val_loss did not improve from 1.08679
Epoch 279/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0534 - acc: 0.5388 - val_loss: 1.0864 - val_acc: 0.5426

Epoch 00279: val_loss improved from 1.08679 to 1.08638, saving model to model2/279-1.0864.hdf5
Epoch 280/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0484 - acc: 0.5476 - val_loss: 1.0870 - val_acc: 0.5405

Epoch 00280: val_loss did not improve from 1.08638
Epoch 281/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0465 - acc: 0.5536 - val_loss: 1.0870 - val_acc: 0.5410

Epoch 00281: val_loss did not improve from 1.08638
Epoch 282/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0477 - acc: 0.5516 - val_loss: 1.0876 - val_acc: 0.5436

Epoch 00282: val_loss did not improve from 1.08638
Epoch 283/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0465 - acc: 0.5525 - val_loss: 1.0911 - val_acc: 0.5369

Epoch 00283: val_loss did not improve from 1.08638
Epoch 284/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0474 - acc: 0.5551 - val_loss: 1.1154 - val_acc: 0.5097

Epoch 00284: val_loss did not improve from 1.08638
Epoch 285/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0517 - acc: 0.5470 - val_loss: 1.0884 - val_acc: 0.5426

Epoch 00285: val_loss did not improve from 1.08638
Epoch 286/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0477 - acc: 0.5492 - val_loss: 1.0856 - val_acc: 0.5436

Epoch 00286: val_loss improved from 1.08638 to 1.08557, saving model to model2/286-1.0856.hdf5
Epoch 287/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0532 - acc: 0.5498 - val_loss: 1.0947 - val_acc: 0.5364

Epoch 00287: val_loss did not improve from 1.08557
Epoch 288/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0482 - acc: 0.5476 - val_loss: 1.0953 - val_acc: 0.5292

Epoch 00288: val_loss did not improve from 1.08557
Epoch 289/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0503 - acc: 0.5437 - val_loss: 1.1052 - val_acc: 0.5267

Epoch 00289: val_loss did not improve from 1.08557
Epoch 290/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0496 - acc: 0.5456 - val_loss: 1.0848 - val_acc: 0.5451

Epoch 00290: val_loss improved from 1.08557 to 1.08484, saving model to model2/290-1.0848.hdf5
Epoch 291/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0474 - acc: 0.5481 - val_loss: 1.0969 - val_acc: 0.5267

Epoch 00291: val_loss did not improve from 1.08484
Epoch 292/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0481 - acc: 0.5489 - val_loss: 1.0944 - val_acc: 0.5359

Epoch 00292: val_loss did not improve from 1.08484
Epoch 293/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0506 - acc: 0.5516 - val_loss: 1.0944 - val_acc: 0.5318

Epoch 00293: val_loss did not improve from 1.08484
Epoch 294/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0516 - acc: 0.5379 - val_loss: 1.0862 - val_acc: 0.5431

Epoch 00294: val_loss did not improve from 1.08484
Epoch 295/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0461 - acc: 0.5465 - val_loss: 1.0853 - val_acc: 0.5421

Epoch 00295: val_loss did not improve from 1.08484
Epoch 296/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0545 - acc: 0.5386 - val_loss: 1.1117 - val_acc: 0.5128

Epoch 00296: val_loss did not improve from 1.08484
Epoch 297/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0530 - acc: 0.5408 - val_loss: 1.0852 - val_acc: 0.5441

Epoch 00297: val_loss did not improve from 1.08484
Epoch 298/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0565 - acc: 0.5388 - val_loss: 1.0970 - val_acc: 0.5267

Epoch 00298: val_loss did not improve from 1.08484
Epoch 299/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0481 - acc: 0.5470 - val_loss: 1.1018 - val_acc: 0.5251

Epoch 00299: val_loss did not improve from 1.08484
Epoch 300/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0608 - acc: 0.5434 - val_loss: 1.1561 - val_acc: 0.4846

Epoch 00300: val_loss did not improve from 1.08484
Epoch 301/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0688 - acc: 0.5346 - val_loss: 1.1109 - val_acc: 0.5221

Epoch 00301: val_loss did not improve from 1.08484
Epoch 302/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0550 - acc: 0.5511 - val_loss: 1.0924 - val_acc: 0.5338

Epoch 00302: val_loss did not improve from 1.08484
Epoch 303/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0618 - acc: 0.5344 - val_loss: 1.1070 - val_acc: 0.5236

Epoch 00303: val_loss did not improve from 1.08484
Epoch 304/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0551 - acc: 0.5450 - val_loss: 1.0900 - val_acc: 0.5390

Epoch 00304: val_loss did not improve from 1.08484
Epoch 305/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0469 - acc: 0.5516 - val_loss: 1.0981 - val_acc: 0.5287

Epoch 00305: val_loss did not improve from 1.08484
Epoch 306/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0485 - acc: 0.5507 - val_loss: 1.0953 - val_acc: 0.5364

Epoch 00306: val_loss did not improve from 1.08484
Epoch 307/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0556 - acc: 0.5419 - val_loss: 1.0880 - val_acc: 0.5467

Epoch 00307: val_loss did not improve from 1.08484
Epoch 308/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0498 - acc: 0.5496 - val_loss: 1.1294 - val_acc: 0.5051

Epoch 00308: val_loss did not improve from 1.08484
Epoch 309/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0639 - acc: 0.5340 - val_loss: 1.1087 - val_acc: 0.5200

Epoch 00309: val_loss did not improve from 1.08484
Epoch 310/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0523 - acc: 0.5382 - val_loss: 1.0934 - val_acc: 0.5282

Epoch 00310: val_loss did not improve from 1.08484
Epoch 311/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0454 - acc: 0.5549 - val_loss: 1.0968 - val_acc: 0.5292

Epoch 00311: val_loss did not improve from 1.08484
Epoch 312/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0455 - acc: 0.5448 - val_loss: 1.1164 - val_acc: 0.5123

Epoch 00312: val_loss did not improve from 1.08484
Epoch 313/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0493 - acc: 0.5384 - val_loss: 1.0922 - val_acc: 0.5364

Epoch 00313: val_loss did not improve from 1.08484
Epoch 314/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0462 - acc: 0.5522 - val_loss: 1.0884 - val_acc: 0.5262

Epoch 00314: val_loss did not improve from 1.08484
Epoch 315/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0526 - acc: 0.5384 - val_loss: 1.0868 - val_acc: 0.5395

Epoch 00315: val_loss did not improve from 1.08484
Epoch 316/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0506 - acc: 0.5445 - val_loss: 1.0984 - val_acc: 0.5313

Epoch 00316: val_loss did not improve from 1.08484
Epoch 317/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0437 - acc: 0.5509 - val_loss: 1.0852 - val_acc: 0.5374

Epoch 00317: val_loss did not improve from 1.08484
Epoch 318/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0453 - acc: 0.5507 - val_loss: 1.0961 - val_acc: 0.5297

Epoch 00318: val_loss did not improve from 1.08484
Epoch 319/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0445 - acc: 0.5489 - val_loss: 1.0906 - val_acc: 0.5374

Epoch 00319: val_loss did not improve from 1.08484
Epoch 320/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0486 - acc: 0.5476 - val_loss: 1.0937 - val_acc: 0.5354

Epoch 00320: val_loss did not improve from 1.08484
Epoch 321/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0442 - acc: 0.5531 - val_loss: 1.0863 - val_acc: 0.5415

Epoch 00321: val_loss did not improve from 1.08484
Epoch 322/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0438 - acc: 0.5538 - val_loss: 1.0866 - val_acc: 0.5482

Epoch 00322: val_loss did not improve from 1.08484
Epoch 323/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0438 - acc: 0.5544 - val_loss: 1.0858 - val_acc: 0.5441

Epoch 00323: val_loss did not improve from 1.08484
Epoch 324/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0407 - acc: 0.5498 - val_loss: 1.0826 - val_acc: 0.5400

Epoch 00324: val_loss improved from 1.08484 to 1.08261, saving model to model2/324-1.0826.hdf5
Epoch 325/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0406 - acc: 0.5527 - val_loss: 1.0840 - val_acc: 0.5472

Epoch 00325: val_loss did not improve from 1.08261
Epoch 326/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0421 - acc: 0.5492 - val_loss: 1.0871 - val_acc: 0.5369

Epoch 00326: val_loss did not improve from 1.08261
Epoch 327/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0589 - acc: 0.5335 - val_loss: 1.0878 - val_acc: 0.5467

Epoch 00327: val_loss did not improve from 1.08261
Epoch 328/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0484 - acc: 0.5516 - val_loss: 1.1028 - val_acc: 0.5267

Epoch 00328: val_loss did not improve from 1.08261
Epoch 329/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0517 - acc: 0.5450 - val_loss: 1.0872 - val_acc: 0.5415

Epoch 00329: val_loss did not improve from 1.08261
Epoch 330/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0440 - acc: 0.5551 - val_loss: 1.0880 - val_acc: 0.5379

Epoch 00330: val_loss did not improve from 1.08261
Epoch 331/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0431 - acc: 0.5562 - val_loss: 1.0873 - val_acc: 0.5390

Epoch 00331: val_loss did not improve from 1.08261
Epoch 332/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0414 - acc: 0.5527 - val_loss: 1.1060 - val_acc: 0.5338

Epoch 00332: val_loss did not improve from 1.08261
Epoch 333/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0510 - acc: 0.5426 - val_loss: 1.0863 - val_acc: 0.5426

Epoch 00333: val_loss did not improve from 1.08261
Epoch 334/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0401 - acc: 0.5507 - val_loss: 1.0865 - val_acc: 0.5344

Epoch 00334: val_loss did not improve from 1.08261
Epoch 335/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0450 - acc: 0.5494 - val_loss: 1.0929 - val_acc: 0.5349

Epoch 00335: val_loss did not improve from 1.08261
Epoch 336/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0425 - acc: 0.5540 - val_loss: 1.0877 - val_acc: 0.5415

Epoch 00336: val_loss did not improve from 1.08261
Epoch 337/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0441 - acc: 0.5492 - val_loss: 1.0915 - val_acc: 0.5456

Epoch 00337: val_loss did not improve from 1.08261
Epoch 338/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0442 - acc: 0.5494 - val_loss: 1.0843 - val_acc: 0.5451

Epoch 00338: val_loss did not improve from 1.08261
Epoch 339/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0425 - acc: 0.5492 - val_loss: 1.0850 - val_acc: 0.5400

Epoch 00339: val_loss did not improve from 1.08261
Epoch 340/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0457 - acc: 0.5518 - val_loss: 1.0871 - val_acc: 0.5379

Epoch 00340: val_loss did not improve from 1.08261
Epoch 341/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0446 - acc: 0.5509 - val_loss: 1.0872 - val_acc: 0.5431

Epoch 00341: val_loss did not improve from 1.08261
Epoch 342/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0454 - acc: 0.5494 - val_loss: 1.1246 - val_acc: 0.5097

Epoch 00342: val_loss did not improve from 1.08261
Epoch 343/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0540 - acc: 0.5459 - val_loss: 1.0927 - val_acc: 0.5354

Epoch 00343: val_loss did not improve from 1.08261
Epoch 344/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0393 - acc: 0.5525 - val_loss: 1.0838 - val_acc: 0.5395

Epoch 00344: val_loss did not improve from 1.08261
Epoch 345/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0400 - acc: 0.5547 - val_loss: 1.1053 - val_acc: 0.5282

Epoch 00345: val_loss did not improve from 1.08261
Epoch 346/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0547 - acc: 0.5404 - val_loss: 1.0855 - val_acc: 0.5513

Epoch 00346: val_loss did not improve from 1.08261
Epoch 347/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0435 - acc: 0.5518 - val_loss: 1.0837 - val_acc: 0.5400

Epoch 00347: val_loss did not improve from 1.08261
Epoch 348/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0389 - acc: 0.5520 - val_loss: 1.0867 - val_acc: 0.5410

Epoch 00348: val_loss did not improve from 1.08261
Epoch 349/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0411 - acc: 0.5505 - val_loss: 1.0851 - val_acc: 0.5487

Epoch 00349: val_loss did not improve from 1.08261
Epoch 350/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0381 - acc: 0.5549 - val_loss: 1.1048 - val_acc: 0.5256

Epoch 00350: val_loss did not improve from 1.08261
Epoch 351/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0466 - acc: 0.5401 - val_loss: 1.0878 - val_acc: 0.5451

Epoch 00351: val_loss did not improve from 1.08261
Epoch 352/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0443 - acc: 0.5483 - val_loss: 1.0858 - val_acc: 0.5364

Epoch 00352: val_loss did not improve from 1.08261
Epoch 353/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0485 - acc: 0.5465 - val_loss: 1.1218 - val_acc: 0.5026

Epoch 00353: val_loss did not improve from 1.08261
Epoch 354/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0475 - acc: 0.5417 - val_loss: 1.0903 - val_acc: 0.5313

Epoch 00354: val_loss did not improve from 1.08261
Epoch 355/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0392 - acc: 0.5536 - val_loss: 1.0928 - val_acc: 0.5323

Epoch 00355: val_loss did not improve from 1.08261
Epoch 356/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0407 - acc: 0.5492 - val_loss: 1.0892 - val_acc: 0.5369

Epoch 00356: val_loss did not improve from 1.08261
Epoch 357/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0366 - acc: 0.5562 - val_loss: 1.0825 - val_acc: 0.5467

Epoch 00357: val_loss improved from 1.08261 to 1.08251, saving model to model2/357-1.0825.hdf5
Epoch 358/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0396 - acc: 0.5549 - val_loss: 1.0818 - val_acc: 0.5523

Epoch 00358: val_loss improved from 1.08251 to 1.08178, saving model to model2/358-1.0818.hdf5
Epoch 359/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0377 - acc: 0.5580 - val_loss: 1.0856 - val_acc: 0.5410

Epoch 00359: val_loss did not improve from 1.08178
Epoch 360/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0370 - acc: 0.5558 - val_loss: 1.0950 - val_acc: 0.5303

Epoch 00360: val_loss did not improve from 1.08178
Epoch 361/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0560 - acc: 0.5423 - val_loss: 1.0905 - val_acc: 0.5323

Epoch 00361: val_loss did not improve from 1.08178
Epoch 362/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0385 - acc: 0.5529 - val_loss: 1.0845 - val_acc: 0.5400

Epoch 00362: val_loss did not improve from 1.08178
Epoch 363/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0432 - acc: 0.5465 - val_loss: 1.0889 - val_acc: 0.5338

Epoch 00363: val_loss did not improve from 1.08178
Epoch 364/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0392 - acc: 0.5525 - val_loss: 1.0915 - val_acc: 0.5308

Epoch 00364: val_loss did not improve from 1.08178
Epoch 365/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0361 - acc: 0.5520 - val_loss: 1.0970 - val_acc: 0.5221

Epoch 00365: val_loss did not improve from 1.08178
Epoch 366/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0388 - acc: 0.5465 - val_loss: 1.0821 - val_acc: 0.5482

Epoch 00366: val_loss did not improve from 1.08178
Epoch 367/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0357 - acc: 0.5584 - val_loss: 1.0934 - val_acc: 0.5308

Epoch 00367: val_loss did not improve from 1.08178
Epoch 368/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0392 - acc: 0.5505 - val_loss: 1.0880 - val_acc: 0.5405

Epoch 00368: val_loss did not improve from 1.08178
Epoch 369/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0395 - acc: 0.564 - 0s 3us/step - loss: 1.0370 - acc: 0.5511 - val_loss: 1.0995 - val_acc: 0.5262

Epoch 00369: val_loss did not improve from 1.08178
Epoch 370/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0544 - acc: 0.5426 - val_loss: 1.0904 - val_acc: 0.5421

Epoch 00370: val_loss did not improve from 1.08178
Epoch 371/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0485 - acc: 0.5410 - val_loss: 1.0849 - val_acc: 0.5390

Epoch 00371: val_loss did not improve from 1.08178
Epoch 372/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0668 - acc: 0.538 - 0s 3us/step - loss: 1.0400 - acc: 0.5450 - val_loss: 1.0893 - val_acc: 0.5344

Epoch 00372: val_loss did not improve from 1.08178
Epoch 373/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0498 - acc: 0.5428 - val_loss: 1.1152 - val_acc: 0.5092

Epoch 00373: val_loss did not improve from 1.08178
Epoch 374/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0434 - acc: 0.5478 - val_loss: 1.0840 - val_acc: 0.5431

Epoch 00374: val_loss did not improve from 1.08178
Epoch 375/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0393 - acc: 0.5481 - val_loss: 1.0910 - val_acc: 0.5328

Epoch 00375: val_loss did not improve from 1.08178
Epoch 376/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0404 - acc: 0.5529 - val_loss: 1.0861 - val_acc: 0.5431

Epoch 00376: val_loss did not improve from 1.08178
Epoch 377/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0371 - acc: 0.5562 - val_loss: 1.1412 - val_acc: 0.4882

Epoch 00377: val_loss did not improve from 1.08178
Epoch 378/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0531 - acc: 0.5368 - val_loss: 1.0956 - val_acc: 0.5349

Epoch 00378: val_loss did not improve from 1.08178
Epoch 379/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0399 - acc: 0.5533 - val_loss: 1.1052 - val_acc: 0.5174

Epoch 00379: val_loss did not improve from 1.08178
Epoch 380/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0490 - acc: 0.5434 - val_loss: 1.0859 - val_acc: 0.5390

Epoch 00380: val_loss did not improve from 1.08178
Epoch 381/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0402 - acc: 0.5542 - val_loss: 1.1059 - val_acc: 0.5159

Epoch 00381: val_loss did not improve from 1.08178
Epoch 382/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0436 - acc: 0.5470 - val_loss: 1.0858 - val_acc: 0.5431

Epoch 00382: val_loss did not improve from 1.08178
Epoch 383/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0399 - acc: 0.5569 - val_loss: 1.0851 - val_acc: 0.5492

Epoch 00383: val_loss did not improve from 1.08178
Epoch 384/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0361 - acc: 0.5562 - val_loss: 1.0856 - val_acc: 0.5462

Epoch 00384: val_loss did not improve from 1.08178
Epoch 385/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0347 - acc: 0.5494 - val_loss: 1.0897 - val_acc: 0.5359

Epoch 00385: val_loss did not improve from 1.08178
Epoch 386/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0425 - acc: 0.5498 - val_loss: 1.1313 - val_acc: 0.4974

Epoch 00386: val_loss did not improve from 1.08178
Epoch 387/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0505 - acc: 0.5432 - val_loss: 1.0946 - val_acc: 0.5318

Epoch 00387: val_loss did not improve from 1.08178
Epoch 388/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0382 - acc: 0.5533 - val_loss: 1.1048 - val_acc: 0.5318

Epoch 00388: val_loss did not improve from 1.08178
Epoch 389/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0565 - acc: 0.5406 - val_loss: 1.0958 - val_acc: 0.5415

Epoch 00389: val_loss did not improve from 1.08178
Epoch 390/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0451 - acc: 0.5445 - val_loss: 1.0871 - val_acc: 0.5354

Epoch 00390: val_loss did not improve from 1.08178
Epoch 391/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0412 - acc: 0.5500 - val_loss: 1.0953 - val_acc: 0.5282

Epoch 00391: val_loss did not improve from 1.08178
Epoch 392/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0516 - acc: 0.5384 - val_loss: 1.1075 - val_acc: 0.5241

Epoch 00392: val_loss did not improve from 1.08178
Epoch 393/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0429 - acc: 0.5492 - val_loss: 1.0867 - val_acc: 0.5354

Epoch 00393: val_loss did not improve from 1.08178
Epoch 394/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0416 - acc: 0.5525 - val_loss: 1.1014 - val_acc: 0.5210

Epoch 00394: val_loss did not improve from 1.08178
Epoch 395/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0381 - acc: 0.5485 - val_loss: 1.0958 - val_acc: 0.5328

Epoch 00395: val_loss did not improve from 1.08178
Epoch 396/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0497 - acc: 0.5474 - val_loss: 1.0880 - val_acc: 0.5410

Epoch 00396: val_loss did not improve from 1.08178
Epoch 397/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0401 - acc: 0.5452 - val_loss: 1.0859 - val_acc: 0.5318

Epoch 00397: val_loss did not improve from 1.08178
Epoch 398/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0378 - acc: 0.5533 - val_loss: 1.0918 - val_acc: 0.5385

Epoch 00398: val_loss did not improve from 1.08178
Epoch 399/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0500 - acc: 0.5445 - val_loss: 1.0851 - val_acc: 0.5508

Epoch 00399: val_loss did not improve from 1.08178
Epoch 400/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0483 - acc: 0.5465 - val_loss: 1.0956 - val_acc: 0.5246

Epoch 00400: val_loss did not improve from 1.08178
Epoch 401/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0384 - acc: 0.5522 - val_loss: 1.0975 - val_acc: 0.5226

Epoch 00401: val_loss did not improve from 1.08178
Epoch 402/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0387 - acc: 0.5492 - val_loss: 1.0816 - val_acc: 0.5446

Epoch 00402: val_loss improved from 1.08178 to 1.08160, saving model to model2/402-1.0816.hdf5
Epoch 403/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0438 - acc: 0.5421 - val_loss: 1.0956 - val_acc: 0.5344

Epoch 00403: val_loss did not improve from 1.08160
Epoch 404/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0452 - acc: 0.5463 - val_loss: 1.0859 - val_acc: 0.5385

Epoch 00404: val_loss did not improve from 1.08160
Epoch 405/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0336 - acc: 0.5558 - val_loss: 1.0858 - val_acc: 0.5451

Epoch 00405: val_loss did not improve from 1.08160
Epoch 406/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0354 - acc: 0.5615 - val_loss: 1.0845 - val_acc: 0.5410

Epoch 00406: val_loss did not improve from 1.08160
Epoch 407/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0472 - acc: 0.5456 - val_loss: 1.0854 - val_acc: 0.5426

Epoch 00407: val_loss did not improve from 1.08160
Epoch 408/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0340 - acc: 0.5553 - val_loss: 1.0919 - val_acc: 0.5308

Epoch 00408: val_loss did not improve from 1.08160
Epoch 409/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0333 - acc: 0.5558 - val_loss: 1.0874 - val_acc: 0.5472

Epoch 00409: val_loss did not improve from 1.08160
Epoch 410/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0421 - acc: 0.5498 - val_loss: 1.0846 - val_acc: 0.5518

Epoch 00410: val_loss did not improve from 1.08160
Epoch 411/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0338 - acc: 0.5580 - val_loss: 1.0857 - val_acc: 0.5482

Epoch 00411: val_loss did not improve from 1.08160
Epoch 412/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0393 - acc: 0.5536 - val_loss: 1.0831 - val_acc: 0.5513

Epoch 00412: val_loss did not improve from 1.08160
Epoch 413/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0321 - acc: 0.5527 - val_loss: 1.1006 - val_acc: 0.5231

Epoch 00413: val_loss did not improve from 1.08160
Epoch 414/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0430 - acc: 0.5437 - val_loss: 1.0901 - val_acc: 0.5338

Epoch 00414: val_loss did not improve from 1.08160
Epoch 415/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0356 - acc: 0.5544 - val_loss: 1.1018 - val_acc: 0.5292

Epoch 00415: val_loss did not improve from 1.08160
Epoch 416/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0435 - acc: 0.5474 - val_loss: 1.0919 - val_acc: 0.5431

Epoch 00416: val_loss did not improve from 1.08160
Epoch 417/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0395 - acc: 0.5507 - val_loss: 1.1021 - val_acc: 0.5215

Epoch 00417: val_loss did not improve from 1.08160
Epoch 418/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0453 - acc: 0.5470 - val_loss: 1.0946 - val_acc: 0.5287

Epoch 00418: val_loss did not improve from 1.08160
Epoch 419/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0333 - acc: 0.5505 - val_loss: 1.0808 - val_acc: 0.5374

Epoch 00419: val_loss improved from 1.08160 to 1.08080, saving model to model2/419-1.0808.hdf5
Epoch 420/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0311 - acc: 0.5505 - val_loss: 1.0851 - val_acc: 0.5390

Epoch 00420: val_loss did not improve from 1.08080
Epoch 421/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0387 - acc: 0.5529 - val_loss: 1.1364 - val_acc: 0.4954

Epoch 00421: val_loss did not improve from 1.08080
Epoch 422/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0448 - acc: 0.5483 - val_loss: 1.0896 - val_acc: 0.5349

Epoch 00422: val_loss did not improve from 1.08080
Epoch 423/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0331 - acc: 0.5547 - val_loss: 1.0878 - val_acc: 0.5364

Epoch 00423: val_loss did not improve from 1.08080
Epoch 424/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0299 - acc: 0.556 - 0s 3us/step - loss: 1.0356 - acc: 0.5520 - val_loss: 1.1236 - val_acc: 0.5077

Epoch 00424: val_loss did not improve from 1.08080
Epoch 425/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0460 - acc: 0.5417 - val_loss: 1.0900 - val_acc: 0.5303

Epoch 00425: val_loss did not improve from 1.08080
Epoch 426/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0312 - acc: 0.5593 - val_loss: 1.0850 - val_acc: 0.5441

Epoch 00426: val_loss did not improve from 1.08080
Epoch 427/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0360 - acc: 0.5485 - val_loss: 1.1093 - val_acc: 0.5185

Epoch 00427: val_loss did not improve from 1.08080
Epoch 428/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0384 - acc: 0.5527 - val_loss: 1.0910 - val_acc: 0.5313

Epoch 00428: val_loss did not improve from 1.08080
Epoch 429/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0335 - acc: 0.5509 - val_loss: 1.0878 - val_acc: 0.5472

Epoch 00429: val_loss did not improve from 1.08080
Epoch 430/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0398 - acc: 0.5432 - val_loss: 1.0926 - val_acc: 0.5308

Epoch 00430: val_loss did not improve from 1.08080
Epoch 431/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0411 - acc: 0.5426 - val_loss: 1.0863 - val_acc: 0.5395

Epoch 00431: val_loss did not improve from 1.08080
Epoch 432/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0378 - acc: 0.5419 - val_loss: 1.1295 - val_acc: 0.5262

Epoch 00432: val_loss did not improve from 1.08080
Epoch 433/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0478 - acc: 0.5463 - val_loss: 1.0853 - val_acc: 0.5462

Epoch 00433: val_loss did not improve from 1.08080
Epoch 434/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0371 - acc: 0.5590 - val_loss: 1.1275 - val_acc: 0.5036

Epoch 00434: val_loss did not improve from 1.08080
Epoch 435/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0433 - acc: 0.5527 - val_loss: 1.0886 - val_acc: 0.5354

Epoch 00435: val_loss did not improve from 1.08080
Epoch 436/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0332 - acc: 0.5511 - val_loss: 1.0878 - val_acc: 0.5467

Epoch 00436: val_loss did not improve from 1.08080
Epoch 437/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0387 - acc: 0.5533 - val_loss: 1.0865 - val_acc: 0.5400

Epoch 00437: val_loss did not improve from 1.08080
Epoch 438/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0337 - acc: 0.5516 - val_loss: 1.0891 - val_acc: 0.5303

Epoch 00438: val_loss did not improve from 1.08080
Epoch 439/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0371 - acc: 0.5542 - val_loss: 1.1000 - val_acc: 0.5236

Epoch 00439: val_loss did not improve from 1.08080
Epoch 440/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0320 - acc: 0.5516 - val_loss: 1.0982 - val_acc: 0.5267

Epoch 00440: val_loss did not improve from 1.08080
Epoch 441/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0316 - acc: 0.5540 - val_loss: 1.0835 - val_acc: 0.5436

Epoch 00441: val_loss did not improve from 1.08080
Epoch 442/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0322 - acc: 0.5575 - val_loss: 1.0884 - val_acc: 0.5379

Epoch 00442: val_loss did not improve from 1.08080
Epoch 443/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0334 - acc: 0.5604 - val_loss: 1.0883 - val_acc: 0.5318

Epoch 00443: val_loss did not improve from 1.08080
Epoch 444/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0312 - acc: 0.5597 - val_loss: 1.0876 - val_acc: 0.5400

Epoch 00444: val_loss did not improve from 1.08080
Epoch 445/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0299 - acc: 0.5560 - val_loss: 1.0846 - val_acc: 0.5462

Epoch 00445: val_loss did not improve from 1.08080
Epoch 446/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0294 - acc: 0.5573 - val_loss: 1.0909 - val_acc: 0.5513

Epoch 00446: val_loss did not improve from 1.08080
Epoch 447/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0333 - acc: 0.5553 - val_loss: 1.1012 - val_acc: 0.5313

Epoch 00447: val_loss did not improve from 1.08080
Epoch 448/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0408 - acc: 0.5503 - val_loss: 1.0955 - val_acc: 0.5308

Epoch 00448: val_loss did not improve from 1.08080
Epoch 449/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0333 - acc: 0.5531 - val_loss: 1.0827 - val_acc: 0.5492

Epoch 00449: val_loss did not improve from 1.08080
Epoch 450/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0305 - acc: 0.5566 - val_loss: 1.0905 - val_acc: 0.5323

Epoch 00450: val_loss did not improve from 1.08080
Epoch 451/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0343 - acc: 0.5551 - val_loss: 1.0842 - val_acc: 0.5482

Epoch 00451: val_loss did not improve from 1.08080
Epoch 452/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0312 - acc: 0.5540 - val_loss: 1.0898 - val_acc: 0.5359

Epoch 00452: val_loss did not improve from 1.08080
Epoch 453/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0309 - acc: 0.5527 - val_loss: 1.0982 - val_acc: 0.5272

Epoch 00453: val_loss did not improve from 1.08080
Epoch 454/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0372 - acc: 0.5500 - val_loss: 1.0939 - val_acc: 0.5333

Epoch 00454: val_loss did not improve from 1.08080
Epoch 455/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0337 - acc: 0.5547 - val_loss: 1.0855 - val_acc: 0.5456

Epoch 00455: val_loss did not improve from 1.08080
Epoch 456/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0294 - acc: 0.5562 - val_loss: 1.1194 - val_acc: 0.5103

Epoch 00456: val_loss did not improve from 1.08080
Epoch 457/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0399 - acc: 0.5461 - val_loss: 1.0961 - val_acc: 0.5297

Epoch 00457: val_loss did not improve from 1.08080
Epoch 458/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0346 - acc: 0.5496 - val_loss: 1.0862 - val_acc: 0.5338

Epoch 00458: val_loss did not improve from 1.08080
Epoch 459/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0313 - acc: 0.5564 - val_loss: 1.0901 - val_acc: 0.5369

Epoch 00459: val_loss did not improve from 1.08080
Epoch 460/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0319 - acc: 0.5549 - val_loss: 1.1084 - val_acc: 0.5185

Epoch 00460: val_loss did not improve from 1.08080
Epoch 461/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0341 - acc: 0.5461 - val_loss: 1.0903 - val_acc: 0.5344

Epoch 00461: val_loss did not improve from 1.08080
Epoch 462/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0413 - acc: 0.5399 - val_loss: 1.0847 - val_acc: 0.5451

Epoch 00462: val_loss did not improve from 1.08080
Epoch 463/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0287 - acc: 0.5604 - val_loss: 1.0829 - val_acc: 0.5400

Epoch 00463: val_loss did not improve from 1.08080
Epoch 464/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0284 - acc: 0.5560 - val_loss: 1.1068 - val_acc: 0.5303

Epoch 00464: val_loss did not improve from 1.08080
Epoch 465/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0504 - acc: 0.5445 - val_loss: 1.0831 - val_acc: 0.5538

Epoch 00465: val_loss did not improve from 1.08080
Epoch 466/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0336 - acc: 0.5472 - val_loss: 1.0894 - val_acc: 0.5318

Epoch 00466: val_loss did not improve from 1.08080
Epoch 467/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0305 - acc: 0.5492 - val_loss: 1.0830 - val_acc: 0.5497

Epoch 00467: val_loss did not improve from 1.08080
Epoch 468/3000
4547/4547 [==============================] - ETA: 0s - loss: 0.9720 - acc: 0.580 - 0s 4us/step - loss: 1.0337 - acc: 0.5531 - val_loss: 1.0936 - val_acc: 0.5338

Epoch 00468: val_loss did not improve from 1.08080
Epoch 469/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0349 - acc: 0.5566 - val_loss: 1.0878 - val_acc: 0.5349

Epoch 00469: val_loss did not improve from 1.08080
Epoch 470/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0310 - acc: 0.5551 - val_loss: 1.0864 - val_acc: 0.5390

Epoch 00470: val_loss did not improve from 1.08080
Epoch 471/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0263 - acc: 0.5604 - val_loss: 1.0896 - val_acc: 0.5421

Epoch 00471: val_loss did not improve from 1.08080
Epoch 472/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0312 - acc: 0.5586 - val_loss: 1.0907 - val_acc: 0.5333

Epoch 00472: val_loss did not improve from 1.08080
Epoch 473/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0293 - acc: 0.5544 - val_loss: 1.0931 - val_acc: 0.5303

Epoch 00473: val_loss did not improve from 1.08080
Epoch 474/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0293 - acc: 0.5573 - val_loss: 1.0898 - val_acc: 0.5405

Epoch 00474: val_loss did not improve from 1.08080
Epoch 475/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0323 - acc: 0.5639 - val_loss: 1.0970 - val_acc: 0.5318

Epoch 00475: val_loss did not improve from 1.08080
Epoch 476/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0325 - acc: 0.5516 - val_loss: 1.0885 - val_acc: 0.5390

Epoch 00476: val_loss did not improve from 1.08080
Epoch 477/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0363 - acc: 0.5562 - val_loss: 1.0895 - val_acc: 0.5472

Epoch 00477: val_loss did not improve from 1.08080
Epoch 478/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0394 - acc: 0.5439 - val_loss: 1.0952 - val_acc: 0.5272

Epoch 00478: val_loss did not improve from 1.08080
Epoch 479/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0328 - acc: 0.5547 - val_loss: 1.0816 - val_acc: 0.5487

Epoch 00479: val_loss did not improve from 1.08080
Epoch 480/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0265 - acc: 0.5597 - val_loss: 1.0839 - val_acc: 0.5426

Epoch 00480: val_loss did not improve from 1.08080
Epoch 481/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0264 - acc: 0.5621 - val_loss: 1.0830 - val_acc: 0.5462

Epoch 00481: val_loss did not improve from 1.08080
Epoch 482/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0300 - acc: 0.5569 - val_loss: 1.0897 - val_acc: 0.5379

Epoch 00482: val_loss did not improve from 1.08080
Epoch 483/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0284 - acc: 0.5562 - val_loss: 1.0836 - val_acc: 0.5415

Epoch 00483: val_loss did not improve from 1.08080
Epoch 484/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0282 - acc: 0.5571 - val_loss: 1.1283 - val_acc: 0.5046

Epoch 00484: val_loss did not improve from 1.08080
Epoch 485/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0493 - acc: 0.5379 - val_loss: 1.1251 - val_acc: 0.5128

Epoch 00485: val_loss did not improve from 1.08080
Epoch 486/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0364 - acc: 0.5514 - val_loss: 1.0858 - val_acc: 0.5374

Epoch 00486: val_loss did not improve from 1.08080
Epoch 487/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0299 - acc: 0.5659 - val_loss: 1.0820 - val_acc: 0.5497

Epoch 00487: val_loss did not improve from 1.08080
Epoch 488/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0287 - acc: 0.5582 - val_loss: 1.0861 - val_acc: 0.5379

Epoch 00488: val_loss did not improve from 1.08080
Epoch 489/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0293 - acc: 0.5549 - val_loss: 1.0895 - val_acc: 0.5344

Epoch 00489: val_loss did not improve from 1.08080
Epoch 490/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0296 - acc: 0.5500 - val_loss: 1.0844 - val_acc: 0.5415

Epoch 00490: val_loss did not improve from 1.08080
Epoch 491/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0323 - acc: 0.5518 - val_loss: 1.0851 - val_acc: 0.5446

Epoch 00491: val_loss did not improve from 1.08080
Epoch 492/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0338 - acc: 0.5540 - val_loss: 1.0917 - val_acc: 0.5297

Epoch 00492: val_loss did not improve from 1.08080
Epoch 493/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0293 - acc: 0.5514 - val_loss: 1.0803 - val_acc: 0.5462

Epoch 00493: val_loss improved from 1.08080 to 1.08027, saving model to model2/493-1.0803.hdf5
Epoch 494/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0262 - acc: 0.5547 - val_loss: 1.0819 - val_acc: 0.5385

Epoch 00494: val_loss did not improve from 1.08027
Epoch 495/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0275 - acc: 0.5514 - val_loss: 1.0963 - val_acc: 0.5328

Epoch 00495: val_loss did not improve from 1.08027
Epoch 496/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0287 - acc: 0.5604 - val_loss: 1.0838 - val_acc: 0.5523

Epoch 00496: val_loss did not improve from 1.08027
Epoch 497/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0338 - acc: 0.5507 - val_loss: 1.0875 - val_acc: 0.5400

Epoch 00497: val_loss did not improve from 1.08027
Epoch 498/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0321 - acc: 0.5498 - val_loss: 1.0996 - val_acc: 0.5215

Epoch 00498: val_loss did not improve from 1.08027
Epoch 499/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0305 - acc: 0.5485 - val_loss: 1.0861 - val_acc: 0.5431

Epoch 00499: val_loss did not improve from 1.08027
Epoch 500/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0278 - acc: 0.5588 - val_loss: 1.0911 - val_acc: 0.5374

Epoch 00500: val_loss did not improve from 1.08027
Epoch 501/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0299 - acc: 0.5544 - val_loss: 1.1083 - val_acc: 0.5236

Epoch 00501: val_loss did not improve from 1.08027
Epoch 502/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0332 - acc: 0.5492 - val_loss: 1.0888 - val_acc: 0.5374

Epoch 00502: val_loss did not improve from 1.08027
Epoch 503/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0348 - acc: 0.5520 - val_loss: 1.0866 - val_acc: 0.5405

Epoch 00503: val_loss did not improve from 1.08027
Epoch 504/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0339 - acc: 0.5505 - val_loss: 1.0838 - val_acc: 0.5405

Epoch 00504: val_loss did not improve from 1.08027
Epoch 505/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0250 - acc: 0.5626 - val_loss: 1.0830 - val_acc: 0.5436

Epoch 00505: val_loss did not improve from 1.08027
Epoch 506/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0269 - acc: 0.5601 - val_loss: 1.0886 - val_acc: 0.5385

Epoch 00506: val_loss did not improve from 1.08027
Epoch 507/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0322 - acc: 0.5478 - val_loss: 1.0877 - val_acc: 0.5446

Epoch 00507: val_loss did not improve from 1.08027
Epoch 508/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0266 - acc: 0.5573 - val_loss: 1.0853 - val_acc: 0.5405

Epoch 00508: val_loss did not improve from 1.08027
Epoch 509/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0241 - acc: 0.5573 - val_loss: 1.0869 - val_acc: 0.5395

Epoch 00509: val_loss did not improve from 1.08027
Epoch 510/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0268 - acc: 0.5571 - val_loss: 1.1052 - val_acc: 0.5251

Epoch 00510: val_loss did not improve from 1.08027
Epoch 511/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0389 - acc: 0.5441 - val_loss: 1.0850 - val_acc: 0.5379

Epoch 00511: val_loss did not improve from 1.08027
Epoch 512/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0291 - acc: 0.5586 - val_loss: 1.1008 - val_acc: 0.5190

Epoch 00512: val_loss did not improve from 1.08027
Epoch 513/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0294 - acc: 0.5540 - val_loss: 1.0857 - val_acc: 0.5374

Epoch 00513: val_loss did not improve from 1.08027
Epoch 514/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0244 - acc: 0.5601 - val_loss: 1.0818 - val_acc: 0.5497

Epoch 00514: val_loss did not improve from 1.08027
Epoch 515/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0336 - acc: 0.5476 - val_loss: 1.0879 - val_acc: 0.5426

Epoch 00515: val_loss did not improve from 1.08027
Epoch 516/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0306 - acc: 0.5558 - val_loss: 1.0836 - val_acc: 0.5477

Epoch 00516: val_loss did not improve from 1.08027
Epoch 517/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0257 - acc: 0.5529 - val_loss: 1.0846 - val_acc: 0.5431

Epoch 00517: val_loss did not improve from 1.08027
Epoch 518/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0233 - acc: 0.5623 - val_loss: 1.0878 - val_acc: 0.5390

Epoch 00518: val_loss did not improve from 1.08027
Epoch 519/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0354 - acc: 0.5509 - val_loss: 1.0844 - val_acc: 0.5379

Epoch 00519: val_loss did not improve from 1.08027
Epoch 520/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0290 - acc: 0.5566 - val_loss: 1.1237 - val_acc: 0.5072

Epoch 00520: val_loss did not improve from 1.08027
Epoch 521/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0433 - acc: 0.5476 - val_loss: 1.1054 - val_acc: 0.5292

Epoch 00521: val_loss did not improve from 1.08027
Epoch 522/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0535 - acc: 0.5454 - val_loss: 1.1147 - val_acc: 0.5190

Epoch 00522: val_loss did not improve from 1.08027
Epoch 523/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0478 - acc: 0.5382 - val_loss: 1.0867 - val_acc: 0.5405

Epoch 00523: val_loss did not improve from 1.08027
Epoch 524/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0337 - acc: 0.5463 - val_loss: 1.0872 - val_acc: 0.5308

Epoch 00524: val_loss did not improve from 1.08027
Epoch 525/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0275 - acc: 0.5531 - val_loss: 1.0844 - val_acc: 0.5482

Epoch 00525: val_loss did not improve from 1.08027
Epoch 526/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0264 - acc: 0.5599 - val_loss: 1.0870 - val_acc: 0.5441

Epoch 00526: val_loss did not improve from 1.08027
Epoch 527/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0259 - acc: 0.5608 - val_loss: 1.1653 - val_acc: 0.4826

Epoch 00527: val_loss did not improve from 1.08027
Epoch 528/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0478 - acc: 0.5437 - val_loss: 1.1109 - val_acc: 0.5205

Epoch 00528: val_loss did not improve from 1.08027
Epoch 529/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0346 - acc: 0.5500 - val_loss: 1.0864 - val_acc: 0.5390

Epoch 00529: val_loss did not improve from 1.08027
Epoch 530/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0271 - acc: 0.5606 - val_loss: 1.0872 - val_acc: 0.5441

Epoch 00530: val_loss did not improve from 1.08027
Epoch 531/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0293 - acc: 0.5610 - val_loss: 1.0880 - val_acc: 0.5282

Epoch 00531: val_loss did not improve from 1.08027
Epoch 532/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0268 - acc: 0.5540 - val_loss: 1.0867 - val_acc: 0.5410

Epoch 00532: val_loss did not improve from 1.08027
Epoch 533/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0252 - acc: 0.5588 - val_loss: 1.0853 - val_acc: 0.5410

Epoch 00533: val_loss did not improve from 1.08027
Epoch 534/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0236 - acc: 0.5584 - val_loss: 1.1418 - val_acc: 0.4954

Epoch 00534: val_loss did not improve from 1.08027
Epoch 535/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0439 - acc: 0.5406 - val_loss: 1.0866 - val_acc: 0.5446

Epoch 00535: val_loss did not improve from 1.08027
Epoch 536/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0275 - acc: 0.5564 - val_loss: 1.0886 - val_acc: 0.5379

Epoch 00536: val_loss did not improve from 1.08027
Epoch 537/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0325 - acc: 0.5483 - val_loss: 1.1027 - val_acc: 0.5251

Epoch 00537: val_loss did not improve from 1.08027
Epoch 538/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0429 - acc: 0.5419 - val_loss: 1.1023 - val_acc: 0.5251

Epoch 00538: val_loss did not improve from 1.08027
Epoch 539/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0283 - acc: 0.5575 - val_loss: 1.0873 - val_acc: 0.5374

Epoch 00539: val_loss did not improve from 1.08027
Epoch 540/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0264 - acc: 0.5623 - val_loss: 1.1013 - val_acc: 0.5318

Epoch 00540: val_loss did not improve from 1.08027
Epoch 541/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0384 - acc: 0.5430 - val_loss: 1.0850 - val_acc: 0.5426

Epoch 00541: val_loss did not improve from 1.08027
Epoch 542/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0296 - acc: 0.5529 - val_loss: 1.0935 - val_acc: 0.5318

Epoch 00542: val_loss did not improve from 1.08027
Epoch 543/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5628 - val_loss: 1.0849 - val_acc: 0.5379

Epoch 00543: val_loss did not improve from 1.08027
Epoch 544/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0250 - acc: 0.5632 - val_loss: 1.0836 - val_acc: 0.5456

Epoch 00544: val_loss did not improve from 1.08027
Epoch 545/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0242 - acc: 0.5580 - val_loss: 1.0870 - val_acc: 0.5436

Epoch 00545: val_loss did not improve from 1.08027
Epoch 546/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0240 - acc: 0.5520 - val_loss: 1.0823 - val_acc: 0.5446

Epoch 00546: val_loss did not improve from 1.08027
Epoch 547/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0261 - acc: 0.5547 - val_loss: 1.0826 - val_acc: 0.5379

Epoch 00547: val_loss did not improve from 1.08027
Epoch 548/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0267 - acc: 0.5516 - val_loss: 1.0978 - val_acc: 0.5277

Epoch 00548: val_loss did not improve from 1.08027
Epoch 549/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0352 - acc: 0.5531 - val_loss: 1.0836 - val_acc: 0.5395

Epoch 00549: val_loss did not improve from 1.08027
Epoch 550/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0285 - acc: 0.5608 - val_loss: 1.0877 - val_acc: 0.5405

Epoch 00550: val_loss did not improve from 1.08027
Epoch 551/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0276 - acc: 0.5544 - val_loss: 1.0892 - val_acc: 0.5374

Epoch 00551: val_loss did not improve from 1.08027
Epoch 552/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0224 - acc: 0.5588 - val_loss: 1.0834 - val_acc: 0.5472

Epoch 00552: val_loss did not improve from 1.08027
Epoch 553/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0238 - acc: 0.5590 - val_loss: 1.0889 - val_acc: 0.5374

Epoch 00553: val_loss did not improve from 1.08027
Epoch 554/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0241 - acc: 0.5544 - val_loss: 1.0876 - val_acc: 0.5405

Epoch 00554: val_loss did not improve from 1.08027
Epoch 555/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0239 - acc: 0.5577 - val_loss: 1.0850 - val_acc: 0.5508

Epoch 00555: val_loss did not improve from 1.08027
Epoch 556/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0273 - acc: 0.5538 - val_loss: 1.1014 - val_acc: 0.5344

Epoch 00556: val_loss did not improve from 1.08027
Epoch 557/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5540 - val_loss: 1.0883 - val_acc: 0.5395

Epoch 00557: val_loss did not improve from 1.08027
Epoch 558/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0300 - acc: 0.5520 - val_loss: 1.0845 - val_acc: 0.5395

Epoch 00558: val_loss did not improve from 1.08027
Epoch 559/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0258 - acc: 0.5536 - val_loss: 1.0972 - val_acc: 0.5297

Epoch 00559: val_loss did not improve from 1.08027
Epoch 560/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0238 - acc: 0.5588 - val_loss: 1.0812 - val_acc: 0.5477

Epoch 00560: val_loss did not improve from 1.08027
Epoch 561/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0244 - acc: 0.5531 - val_loss: 1.0826 - val_acc: 0.5456

Epoch 00561: val_loss did not improve from 1.08027
Epoch 562/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0262 - acc: 0.5538 - val_loss: 1.0998 - val_acc: 0.5256

Epoch 00562: val_loss did not improve from 1.08027
Epoch 563/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5590 - val_loss: 1.0834 - val_acc: 0.5492

Epoch 00563: val_loss did not improve from 1.08027
Epoch 564/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0255 - acc: 0.5569 - val_loss: 1.0884 - val_acc: 0.5410

Epoch 00564: val_loss did not improve from 1.08027
Epoch 565/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0243 - acc: 0.5555 - val_loss: 1.1393 - val_acc: 0.5062

Epoch 00565: val_loss did not improve from 1.08027
Epoch 566/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0386 - acc: 0.5494 - val_loss: 1.0842 - val_acc: 0.5487

Epoch 00566: val_loss did not improve from 1.08027
Epoch 567/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0282 - acc: 0.5536 - val_loss: 1.0908 - val_acc: 0.5333

Epoch 00567: val_loss did not improve from 1.08027
Epoch 568/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0332 - acc: 0.5520 - val_loss: 1.0859 - val_acc: 0.5477

Epoch 00568: val_loss did not improve from 1.08027
Epoch 569/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0329 - acc: 0.5525 - val_loss: 1.0820 - val_acc: 0.5487

Epoch 00569: val_loss did not improve from 1.08027
Epoch 570/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0332 - acc: 0.5485 - val_loss: 1.0850 - val_acc: 0.5359

Epoch 00570: val_loss did not improve from 1.08027
Epoch 571/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0236 - acc: 0.5564 - val_loss: 1.0893 - val_acc: 0.5323

Epoch 00571: val_loss did not improve from 1.08027
Epoch 572/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0265 - acc: 0.5560 - val_loss: 1.0850 - val_acc: 0.5467

Epoch 00572: val_loss did not improve from 1.08027
Epoch 573/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0242 - acc: 0.5577 - val_loss: 1.0833 - val_acc: 0.5472

Epoch 00573: val_loss did not improve from 1.08027
Epoch 574/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0209 - acc: 0.5632 - val_loss: 1.0868 - val_acc: 0.5436

Epoch 00574: val_loss did not improve from 1.08027
Epoch 575/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0232 - acc: 0.5617 - val_loss: 1.0901 - val_acc: 0.5385

Epoch 00575: val_loss did not improve from 1.08027
Epoch 576/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0313 - acc: 0.5507 - val_loss: 1.0775 - val_acc: 0.5533

Epoch 00576: val_loss improved from 1.08027 to 1.07753, saving model to model2/576-1.0775.hdf5
Epoch 577/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0239 - acc: 0.5549 - val_loss: 1.0870 - val_acc: 0.5364

Epoch 00577: val_loss did not improve from 1.07753
Epoch 578/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0251 - acc: 0.5555 - val_loss: 1.0880 - val_acc: 0.5415

Epoch 00578: val_loss did not improve from 1.07753
Epoch 579/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0386 - acc: 0.5505 - val_loss: 1.0909 - val_acc: 0.5400

Epoch 00579: val_loss did not improve from 1.07753
Epoch 580/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0330 - acc: 0.5547 - val_loss: 1.0877 - val_acc: 0.5446

Epoch 00580: val_loss did not improve from 1.07753
Epoch 581/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0211 - acc: 0.5623 - val_loss: 1.0941 - val_acc: 0.5405

Epoch 00581: val_loss did not improve from 1.07753
Epoch 582/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0254 - acc: 0.5514 - val_loss: 1.0891 - val_acc: 0.5379

Epoch 00582: val_loss did not improve from 1.07753
Epoch 583/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0238 - acc: 0.5619 - val_loss: 1.0893 - val_acc: 0.5390

Epoch 00583: val_loss did not improve from 1.07753
Epoch 584/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0227 - acc: 0.5626 - val_loss: 1.0997 - val_acc: 0.5395

Epoch 00584: val_loss did not improve from 1.07753
Epoch 585/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0310 - acc: 0.5516 - val_loss: 1.0876 - val_acc: 0.5405

Epoch 00585: val_loss did not improve from 1.07753
Epoch 586/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0295 - acc: 0.5489 - val_loss: 1.0862 - val_acc: 0.5492

Epoch 00586: val_loss did not improve from 1.07753
Epoch 587/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0263 - acc: 0.5577 - val_loss: 1.0869 - val_acc: 0.5318

Epoch 00587: val_loss did not improve from 1.07753
Epoch 588/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0213 - acc: 0.5637 - val_loss: 1.0962 - val_acc: 0.5297

Epoch 00588: val_loss did not improve from 1.07753
Epoch 589/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0216 - acc: 0.5551 - val_loss: 1.0909 - val_acc: 0.5395

Epoch 00589: val_loss did not improve from 1.07753
Epoch 590/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0305 - acc: 0.5472 - val_loss: 1.0965 - val_acc: 0.5338

Epoch 00590: val_loss did not improve from 1.07753
Epoch 591/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0330 - acc: 0.5536 - val_loss: 1.0858 - val_acc: 0.5374

Epoch 00591: val_loss did not improve from 1.07753
Epoch 592/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0237 - acc: 0.5599 - val_loss: 1.0942 - val_acc: 0.5328

Epoch 00592: val_loss did not improve from 1.07753
Epoch 593/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0327 - acc: 0.5450 - val_loss: 1.1425 - val_acc: 0.4995

Epoch 00593: val_loss did not improve from 1.07753
Epoch 594/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0373 - acc: 0.5448 - val_loss: 1.0835 - val_acc: 0.5482

Epoch 00594: val_loss did not improve from 1.07753
Epoch 595/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0476 - acc: 0.5450 - val_loss: 1.0845 - val_acc: 0.5456

Epoch 00595: val_loss did not improve from 1.07753
Epoch 596/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0275 - acc: 0.5595 - val_loss: 1.1007 - val_acc: 0.5256

Epoch 00596: val_loss did not improve from 1.07753
Epoch 597/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5544 - val_loss: 1.0858 - val_acc: 0.5405

Epoch 00597: val_loss did not improve from 1.07753
Epoch 598/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0219 - acc: 0.5577 - val_loss: 1.1119 - val_acc: 0.5267

Epoch 00598: val_loss did not improve from 1.07753
Epoch 599/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0297 - acc: 0.5496 - val_loss: 1.0907 - val_acc: 0.5385

Epoch 00599: val_loss did not improve from 1.07753
Epoch 600/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0289 - acc: 0.5588 - val_loss: 1.0869 - val_acc: 0.5446

Epoch 00600: val_loss did not improve from 1.07753
Epoch 601/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0205 - acc: 0.5597 - val_loss: 1.0894 - val_acc: 0.5344

Epoch 00601: val_loss did not improve from 1.07753
Epoch 602/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0243 - acc: 0.5577 - val_loss: 1.0814 - val_acc: 0.5456

Epoch 00602: val_loss did not improve from 1.07753
Epoch 603/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0220 - acc: 0.5606 - val_loss: 1.1042 - val_acc: 0.5318

Epoch 00603: val_loss did not improve from 1.07753
Epoch 604/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0440 - acc: 0.5415 - val_loss: 1.0832 - val_acc: 0.5441

Epoch 00604: val_loss did not improve from 1.07753
Epoch 605/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0294 - acc: 0.5544 - val_loss: 1.0908 - val_acc: 0.5410

Epoch 00605: val_loss did not improve from 1.07753
Epoch 606/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0313 - acc: 0.5612 - val_loss: 1.0895 - val_acc: 0.5462

Epoch 00606: val_loss did not improve from 1.07753
Epoch 607/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0277 - acc: 0.5571 - val_loss: 1.0891 - val_acc: 0.5333

Epoch 00607: val_loss did not improve from 1.07753
Epoch 608/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0269 - acc: 0.5542 - val_loss: 1.0986 - val_acc: 0.5292

Epoch 00608: val_loss did not improve from 1.07753
Epoch 609/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0394 - acc: 0.5423 - val_loss: 1.0987 - val_acc: 0.5267

Epoch 00609: val_loss did not improve from 1.07753
Epoch 610/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0292 - acc: 0.5553 - val_loss: 1.0858 - val_acc: 0.5441

Epoch 00610: val_loss did not improve from 1.07753
Epoch 611/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0225 - acc: 0.5634 - val_loss: 1.0839 - val_acc: 0.5426

Epoch 00611: val_loss did not improve from 1.07753
Epoch 612/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0251 - acc: 0.5525 - val_loss: 1.0851 - val_acc: 0.5338

Epoch 00612: val_loss did not improve from 1.07753
Epoch 613/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0342 - acc: 0.5459 - val_loss: 1.0906 - val_acc: 0.5303

Epoch 00613: val_loss did not improve from 1.07753
Epoch 614/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0307 - acc: 0.5509 - val_loss: 1.0848 - val_acc: 0.5354

Epoch 00614: val_loss did not improve from 1.07753
Epoch 615/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0207 - acc: 0.5599 - val_loss: 1.0937 - val_acc: 0.5354

Epoch 00615: val_loss did not improve from 1.07753
Epoch 616/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0268 - acc: 0.5558 - val_loss: 1.0818 - val_acc: 0.5554

Epoch 00616: val_loss did not improve from 1.07753
Epoch 617/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0211 - acc: 0.5584 - val_loss: 1.1036 - val_acc: 0.5231

Epoch 00617: val_loss did not improve from 1.07753
Epoch 618/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0352 - acc: 0.5461 - val_loss: 1.0945 - val_acc: 0.5374

Epoch 00618: val_loss did not improve from 1.07753
Epoch 619/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0217 - acc: 0.5595 - val_loss: 1.0818 - val_acc: 0.5436

Epoch 00619: val_loss did not improve from 1.07753
Epoch 620/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0197 - acc: 0.5630 - val_loss: 1.0863 - val_acc: 0.5421

Epoch 00620: val_loss did not improve from 1.07753
Epoch 621/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0250 - acc: 0.5590 - val_loss: 1.0874 - val_acc: 0.5374

Epoch 00621: val_loss did not improve from 1.07753
Epoch 622/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0239 - acc: 0.5601 - val_loss: 1.0938 - val_acc: 0.5313

Epoch 00622: val_loss did not improve from 1.07753
Epoch 623/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0246 - acc: 0.5533 - val_loss: 1.0814 - val_acc: 0.5549

Epoch 00623: val_loss did not improve from 1.07753
Epoch 624/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0208 - acc: 0.5577 - val_loss: 1.0841 - val_acc: 0.5456

Epoch 00624: val_loss did not improve from 1.07753
Epoch 625/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0191 - acc: 0.5595 - val_loss: 1.0841 - val_acc: 0.5477

Epoch 00625: val_loss did not improve from 1.07753
Epoch 626/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0192 - acc: 0.5564 - val_loss: 1.1183 - val_acc: 0.5133

Epoch 00626: val_loss did not improve from 1.07753
Epoch 627/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0493 - acc: 0.5410 - val_loss: 1.1382 - val_acc: 0.4974

Epoch 00627: val_loss did not improve from 1.07753
Epoch 628/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0467 - acc: 0.5459 - val_loss: 1.1168 - val_acc: 0.5267

Epoch 00628: val_loss did not improve from 1.07753
Epoch 629/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0658 - acc: 0.5342 - val_loss: 1.1352 - val_acc: 0.5169

Epoch 00629: val_loss did not improve from 1.07753
Epoch 630/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0441 - acc: 0.5443 - val_loss: 1.0870 - val_acc: 0.5415

Epoch 00630: val_loss did not improve from 1.07753
Epoch 631/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0236 - acc: 0.5538 - val_loss: 1.0855 - val_acc: 0.5436

Epoch 00631: val_loss did not improve from 1.07753
Epoch 632/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0215 - acc: 0.5542 - val_loss: 1.0884 - val_acc: 0.5405

Epoch 00632: val_loss did not improve from 1.07753
Epoch 633/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0199 - acc: 0.5562 - val_loss: 1.0892 - val_acc: 0.5374

Epoch 00633: val_loss did not improve from 1.07753
Epoch 634/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0205 - acc: 0.5634 - val_loss: 1.0885 - val_acc: 0.5436

Epoch 00634: val_loss did not improve from 1.07753
Epoch 635/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0206 - acc: 0.5601 - val_loss: 1.0888 - val_acc: 0.5503

Epoch 00635: val_loss did not improve from 1.07753
Epoch 636/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0271 - acc: 0.5586 - val_loss: 1.0850 - val_acc: 0.5482

Epoch 00636: val_loss did not improve from 1.07753
Epoch 637/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0214 - acc: 0.5553 - val_loss: 1.0868 - val_acc: 0.5421

Epoch 00637: val_loss did not improve from 1.07753
Epoch 638/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0194 - acc: 0.5590 - val_loss: 1.0900 - val_acc: 0.5379

Epoch 00638: val_loss did not improve from 1.07753
Epoch 639/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0207 - acc: 0.5601 - val_loss: 1.0864 - val_acc: 0.5477

Epoch 00639: val_loss did not improve from 1.07753
Epoch 640/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0232 - acc: 0.5569 - val_loss: 1.1016 - val_acc: 0.5215

Epoch 00640: val_loss did not improve from 1.07753
Epoch 641/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0353 - acc: 0.5487 - val_loss: 1.0909 - val_acc: 0.5349

Epoch 00641: val_loss did not improve from 1.07753
Epoch 642/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0205 - acc: 0.5597 - val_loss: 1.0829 - val_acc: 0.5497

Epoch 00642: val_loss did not improve from 1.07753
Epoch 643/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0210 - acc: 0.5560 - val_loss: 1.0888 - val_acc: 0.5421

Epoch 00643: val_loss did not improve from 1.07753
Epoch 644/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0252 - acc: 0.5538 - val_loss: 1.0918 - val_acc: 0.5313

Epoch 00644: val_loss did not improve from 1.07753
Epoch 645/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0253 - acc: 0.5577 - val_loss: 1.1267 - val_acc: 0.5108

Epoch 00645: val_loss did not improve from 1.07753
Epoch 646/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0336 - acc: 0.5439 - val_loss: 1.0855 - val_acc: 0.5410

Epoch 00646: val_loss did not improve from 1.07753
Epoch 647/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0277 - acc: 0.5474 - val_loss: 1.1023 - val_acc: 0.5277

Epoch 00647: val_loss did not improve from 1.07753
Epoch 648/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0319 - acc: 0.5498 - val_loss: 1.0893 - val_acc: 0.5385

Epoch 00648: val_loss did not improve from 1.07753
Epoch 649/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0363 - acc: 0.5439 - val_loss: 1.1406 - val_acc: 0.4974

Epoch 00649: val_loss did not improve from 1.07753
Epoch 650/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0466 - acc: 0.5423 - val_loss: 1.1219 - val_acc: 0.5210

Epoch 00650: val_loss did not improve from 1.07753
Epoch 651/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0281 - acc: 0.5540 - val_loss: 1.0863 - val_acc: 0.5441

Epoch 00651: val_loss did not improve from 1.07753
Epoch 652/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0182 - acc: 0.5597 - val_loss: 1.0891 - val_acc: 0.5405

Epoch 00652: val_loss did not improve from 1.07753
Epoch 653/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0262 - acc: 0.5597 - val_loss: 1.0863 - val_acc: 0.5410

Epoch 00653: val_loss did not improve from 1.07753
Epoch 654/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0233 - acc: 0.5500 - val_loss: 1.0834 - val_acc: 0.5410

Epoch 00654: val_loss did not improve from 1.07753
Epoch 655/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0272 - acc: 0.5516 - val_loss: 1.1065 - val_acc: 0.5287

Epoch 00655: val_loss did not improve from 1.07753
Epoch 656/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0295 - acc: 0.5489 - val_loss: 1.0960 - val_acc: 0.5344

Epoch 00656: val_loss did not improve from 1.07753
Epoch 657/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0351 - acc: 0.5474 - val_loss: 1.1226 - val_acc: 0.5133

Epoch 00657: val_loss did not improve from 1.07753
Epoch 658/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0500 - acc: 0.5481 - val_loss: 1.0885 - val_acc: 0.5405

Epoch 00658: val_loss did not improve from 1.07753
Epoch 659/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0374 - acc: 0.5426 - val_loss: 1.0943 - val_acc: 0.5282

Epoch 00659: val_loss did not improve from 1.07753
Epoch 660/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0239 - acc: 0.5544 - val_loss: 1.1024 - val_acc: 0.5313

Epoch 00660: val_loss did not improve from 1.07753
Epoch 661/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0237 - acc: 0.5610 - val_loss: 1.0854 - val_acc: 0.5400

Epoch 00661: val_loss did not improve from 1.07753
Epoch 662/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0179 - acc: 0.5612 - val_loss: 1.0834 - val_acc: 0.5400

Epoch 00662: val_loss did not improve from 1.07753
Epoch 663/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0245 - acc: 0.5590 - val_loss: 1.1188 - val_acc: 0.5031

Epoch 00663: val_loss did not improve from 1.07753
Epoch 664/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0251 - acc: 0.5566 - val_loss: 1.0858 - val_acc: 0.5410

Epoch 00664: val_loss did not improve from 1.07753
Epoch 665/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0230 - acc: 0.5560 - val_loss: 1.0930 - val_acc: 0.5354

Epoch 00665: val_loss did not improve from 1.07753
Epoch 666/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0212 - acc: 0.5514 - val_loss: 1.0993 - val_acc: 0.5272

Epoch 00666: val_loss did not improve from 1.07753
Epoch 667/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0257 - acc: 0.5601 - val_loss: 1.1051 - val_acc: 0.5369

Epoch 00667: val_loss did not improve from 1.07753
Epoch 668/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0329 - acc: 0.5582 - val_loss: 1.0897 - val_acc: 0.5415

Epoch 00668: val_loss did not improve from 1.07753
Epoch 669/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0237 - acc: 0.5645 - val_loss: 1.0976 - val_acc: 0.5303

Epoch 00669: val_loss did not improve from 1.07753
Epoch 670/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0228 - acc: 0.5588 - val_loss: 1.0852 - val_acc: 0.5503

Epoch 00670: val_loss did not improve from 1.07753
Epoch 671/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0215 - acc: 0.5544 - val_loss: 1.0876 - val_acc: 0.5354

Epoch 00671: val_loss did not improve from 1.07753
Epoch 672/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0203 - acc: 0.5562 - val_loss: 1.0848 - val_acc: 0.5482

Epoch 00672: val_loss did not improve from 1.07753
Epoch 673/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0198 - acc: 0.5643 - val_loss: 1.0866 - val_acc: 0.5426

Epoch 00673: val_loss did not improve from 1.07753
Epoch 674/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0214 - acc: 0.5586 - val_loss: 1.0934 - val_acc: 0.5431

Epoch 00674: val_loss did not improve from 1.07753
Epoch 675/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0396 - acc: 0.5489 - val_loss: 1.0901 - val_acc: 0.5313

Epoch 00675: val_loss did not improve from 1.07753
Epoch 676/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0310 - acc: 0.5531 - val_loss: 1.0871 - val_acc: 0.5421

Epoch 00676: val_loss did not improve from 1.07753
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[14]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># save model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;result/my_model2.h5&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;result/my_model2.h5&#39;</span><span class="p">)</span>

<span class="c1"># Accuracy result</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Accuracy: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>

<span class="k">del</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>6497/6497 [==============================] - 0s 18us/step

 Accuracy: 0.5561
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="model-3">model 3<a class="anchor-link" href="#model-3">&#182;</a></h4><ul>
<li>input 12</li>
<li>4 hidden layer , 30 <em> 10 </em> 10 * 11 node</li>
<li>activation function : relu -&gt; softplus -&gt; softplus -&gt; softmax</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[15]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># modeling</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[16]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model update</span>
<span class="n">MODEL_DIR</span> <span class="o">=</span> <span class="s1">&#39;model3/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">)</span>

<span class="n">modelpath</span> <span class="o">=</span> <span class="s2">&quot;model3/</span><span class="si">{epoch:02d}</span><span class="s2">-</span><span class="si">{val_loss:.4f}</span><span class="s2">.hdf5&quot;</span>
<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">modelpath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">early_stopping_callback</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">history3</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping_callback</span><span class="p">,</span> <span class="n">checkpointer</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 4547 samples, validate on 1950 samples
Epoch 1/3000
4547/4547 [==============================] - 0s 72us/step - loss: 11.8192 - acc: 0.1674 - val_loss: 11.0252 - val_acc: 0.1631

Epoch 00001: val_loss improved from inf to 11.02519, saving model to model3/01-11.0252.hdf5
Epoch 2/3000
4547/4547 [==============================] - 0s 4us/step - loss: 9.8798 - acc: 0.1674 - val_loss: 7.1664 - val_acc: 0.1631

Epoch 00002: val_loss improved from 11.02519 to 7.16644, saving model to model3/02-7.1664.hdf5
Epoch 3/3000
4547/4547 [==============================] - 0s 4us/step - loss: 4.4359 - acc: 0.1988 - val_loss: 1.8244 - val_acc: 0.4369

Epoch 00003: val_loss improved from 7.16644 to 1.82437, saving model to model3/03-1.8244.hdf5
Epoch 4/3000
4547/4547 [==============================] - 0s 4us/step - loss: 2.0905 - acc: 0.4297 - val_loss: 2.2535 - val_acc: 0.4467

Epoch 00004: val_loss did not improve from 1.82437
Epoch 5/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.9499 - acc: 0.4273 - val_loss: 1.6694 - val_acc: 0.3995

Epoch 00005: val_loss improved from 1.82437 to 1.66938, saving model to model3/05-1.6694.hdf5
Epoch 6/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.5127 - acc: 0.3752 - val_loss: 1.5917 - val_acc: 0.3308

Epoch 00006: val_loss improved from 1.66938 to 1.59170, saving model to model3/06-1.5917.hdf5
Epoch 7/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.4698 - acc: 0.3715 - val_loss: 1.4914 - val_acc: 0.4431

Epoch 00007: val_loss improved from 1.59170 to 1.49137, saving model to model3/07-1.4914.hdf5
Epoch 8/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.4218 - acc: 0.4335 - val_loss: 1.4559 - val_acc: 0.4374

Epoch 00008: val_loss improved from 1.49137 to 1.45593, saving model to model3/08-1.4559.hdf5
Epoch 9/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3875 - acc: 0.4183 - val_loss: 1.4317 - val_acc: 0.4215

Epoch 00009: val_loss improved from 1.45593 to 1.43169, saving model to model3/09-1.4317.hdf5
Epoch 10/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3700 - acc: 0.4229 - val_loss: 1.4177 - val_acc: 0.4364

Epoch 00010: val_loss improved from 1.43169 to 1.41765, saving model to model3/10-1.4177.hdf5
Epoch 11/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3561 - acc: 0.4289 - val_loss: 1.3978 - val_acc: 0.4359

Epoch 00011: val_loss improved from 1.41765 to 1.39779, saving model to model3/11-1.3978.hdf5
Epoch 12/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3423 - acc: 0.4271 - val_loss: 1.3819 - val_acc: 0.4354

Epoch 00012: val_loss improved from 1.39779 to 1.38191, saving model to model3/12-1.3819.hdf5
Epoch 13/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3289 - acc: 0.4293 - val_loss: 1.3676 - val_acc: 0.4338

Epoch 00013: val_loss improved from 1.38191 to 1.36761, saving model to model3/13-1.3676.hdf5
Epoch 14/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3163 - acc: 0.4355 - val_loss: 1.3545 - val_acc: 0.4431

Epoch 00014: val_loss improved from 1.36761 to 1.35446, saving model to model3/14-1.3545.hdf5
Epoch 15/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3081 - acc: 0.4350 - val_loss: 1.3461 - val_acc: 0.4426

Epoch 00015: val_loss improved from 1.35446 to 1.34607, saving model to model3/15-1.3461.hdf5
Epoch 16/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2995 - acc: 0.4390 - val_loss: 1.3405 - val_acc: 0.4436

Epoch 00016: val_loss improved from 1.34607 to 1.34047, saving model to model3/16-1.3405.hdf5
Epoch 17/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2922 - acc: 0.4396 - val_loss: 1.3336 - val_acc: 0.4492

Epoch 00017: val_loss improved from 1.34047 to 1.33359, saving model to model3/17-1.3336.hdf5
Epoch 18/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2844 - acc: 0.4368 - val_loss: 1.3269 - val_acc: 0.4477

Epoch 00018: val_loss improved from 1.33359 to 1.32687, saving model to model3/18-1.3269.hdf5
Epoch 19/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2775 - acc: 0.4357 - val_loss: 1.3204 - val_acc: 0.4456

Epoch 00019: val_loss improved from 1.32687 to 1.32036, saving model to model3/19-1.3204.hdf5
Epoch 20/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2723 - acc: 0.4372 - val_loss: 1.3177 - val_acc: 0.4477

Epoch 00020: val_loss improved from 1.32036 to 1.31766, saving model to model3/20-1.3177.hdf5
Epoch 21/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2674 - acc: 0.4394 - val_loss: 1.3119 - val_acc: 0.4472

Epoch 00021: val_loss improved from 1.31766 to 1.31192, saving model to model3/21-1.3119.hdf5
Epoch 22/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2629 - acc: 0.4385 - val_loss: 1.3100 - val_acc: 0.4528

Epoch 00022: val_loss improved from 1.31192 to 1.31000, saving model to model3/22-1.3100.hdf5
Epoch 23/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2595 - acc: 0.4344 - val_loss: 1.3112 - val_acc: 0.4487

Epoch 00023: val_loss did not improve from 1.31000
Epoch 24/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2584 - acc: 0.4377 - val_loss: 1.3038 - val_acc: 0.4482

Epoch 00024: val_loss improved from 1.31000 to 1.30376, saving model to model3/24-1.3038.hdf5
Epoch 25/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2532 - acc: 0.4339 - val_loss: 1.3072 - val_acc: 0.4554

Epoch 00025: val_loss did not improve from 1.30376
Epoch 26/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2490 - acc: 0.4482 - val_loss: 1.2987 - val_acc: 0.4544

Epoch 00026: val_loss improved from 1.30376 to 1.29873, saving model to model3/26-1.2987.hdf5
Epoch 27/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2452 - acc: 0.4401 - val_loss: 1.2941 - val_acc: 0.4503

Epoch 00027: val_loss improved from 1.29873 to 1.29408, saving model to model3/27-1.2941.hdf5
Epoch 28/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2435 - acc: 0.4352 - val_loss: 1.2932 - val_acc: 0.4569

Epoch 00028: val_loss improved from 1.29408 to 1.29319, saving model to model3/28-1.2932.hdf5
Epoch 29/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2393 - acc: 0.4577 - val_loss: 1.2907 - val_acc: 0.4549

Epoch 00029: val_loss improved from 1.29319 to 1.29069, saving model to model3/29-1.2907.hdf5
Epoch 30/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2383 - acc: 0.4359 - val_loss: 1.2861 - val_acc: 0.4533

Epoch 00030: val_loss improved from 1.29069 to 1.28606, saving model to model3/30-1.2861.hdf5
Epoch 31/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2358 - acc: 0.4506 - val_loss: 1.2881 - val_acc: 0.4605

Epoch 00031: val_loss did not improve from 1.28606
Epoch 32/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2320 - acc: 0.4418 - val_loss: 1.2841 - val_acc: 0.4523

Epoch 00032: val_loss improved from 1.28606 to 1.28408, saving model to model3/32-1.2841.hdf5
Epoch 33/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2293 - acc: 0.4366 - val_loss: 1.2818 - val_acc: 0.4503

Epoch 00033: val_loss improved from 1.28408 to 1.28177, saving model to model3/33-1.2818.hdf5
Epoch 34/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2254 - acc: 0.4480 - val_loss: 1.2797 - val_acc: 0.4564

Epoch 00034: val_loss improved from 1.28177 to 1.27967, saving model to model3/34-1.2797.hdf5
Epoch 35/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2224 - acc: 0.4425 - val_loss: 1.2780 - val_acc: 0.4600

Epoch 00035: val_loss improved from 1.27967 to 1.27796, saving model to model3/35-1.2780.hdf5
Epoch 36/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2194 - acc: 0.4535 - val_loss: 1.2798 - val_acc: 0.4651

Epoch 00036: val_loss did not improve from 1.27796
Epoch 37/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2189 - acc: 0.4621 - val_loss: 1.2726 - val_acc: 0.4631

Epoch 00037: val_loss improved from 1.27796 to 1.27261, saving model to model3/37-1.2726.hdf5
Epoch 38/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2158 - acc: 0.4427 - val_loss: 1.2744 - val_acc: 0.4569

Epoch 00038: val_loss did not improve from 1.27261
Epoch 39/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2126 - acc: 0.4513 - val_loss: 1.2692 - val_acc: 0.4559

Epoch 00039: val_loss improved from 1.27261 to 1.26922, saving model to model3/39-1.2692.hdf5
Epoch 40/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2115 - acc: 0.4603 - val_loss: 1.2676 - val_acc: 0.4610

Epoch 00040: val_loss improved from 1.26922 to 1.26757, saving model to model3/40-1.2676.hdf5
Epoch 41/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.2067 - acc: 0.4585 - val_loss: 1.2596 - val_acc: 0.4636

Epoch 00041: val_loss improved from 1.26757 to 1.25961, saving model to model3/41-1.2596.hdf5
Epoch 42/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2050 - acc: 0.4517 - val_loss: 1.2670 - val_acc: 0.4672

Epoch 00042: val_loss did not improve from 1.25961
Epoch 43/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2093 - acc: 0.4711 - val_loss: 1.2619 - val_acc: 0.4626

Epoch 00043: val_loss did not improve from 1.25961
Epoch 44/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2042 - acc: 0.4513 - val_loss: 1.2634 - val_acc: 0.4646

Epoch 00044: val_loss did not improve from 1.25961
Epoch 45/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1987 - acc: 0.4550 - val_loss: 1.2527 - val_acc: 0.4662

Epoch 00045: val_loss improved from 1.25961 to 1.25271, saving model to model3/45-1.2527.hdf5
Epoch 46/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1977 - acc: 0.4658 - val_loss: 1.2502 - val_acc: 0.4662

Epoch 00046: val_loss improved from 1.25271 to 1.25020, saving model to model3/46-1.2502.hdf5
Epoch 47/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1961 - acc: 0.4687 - val_loss: 1.2456 - val_acc: 0.4682

Epoch 00047: val_loss improved from 1.25020 to 1.24558, saving model to model3/47-1.2456.hdf5
Epoch 48/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1940 - acc: 0.4671 - val_loss: 1.2543 - val_acc: 0.4764

Epoch 00048: val_loss did not improve from 1.24558
Epoch 49/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1902 - acc: 0.4706 - val_loss: 1.2446 - val_acc: 0.4692

Epoch 00049: val_loss improved from 1.24558 to 1.24456, saving model to model3/49-1.2446.hdf5
Epoch 50/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1903 - acc: 0.4689 - val_loss: 1.2365 - val_acc: 0.4708

Epoch 00050: val_loss improved from 1.24456 to 1.23649, saving model to model3/50-1.2365.hdf5
Epoch 51/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1862 - acc: 0.4638 - val_loss: 1.2614 - val_acc: 0.4805

Epoch 00051: val_loss did not improve from 1.23649
Epoch 52/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1916 - acc: 0.4772 - val_loss: 1.2349 - val_acc: 0.4667

Epoch 00052: val_loss improved from 1.23649 to 1.23486, saving model to model3/52-1.2349.hdf5
Epoch 53/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1835 - acc: 0.4733 - val_loss: 1.2317 - val_acc: 0.4785

Epoch 00053: val_loss improved from 1.23486 to 1.23166, saving model to model3/53-1.2317.hdf5
Epoch 54/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1898 - acc: 0.4660 - val_loss: 1.2410 - val_acc: 0.4882

Epoch 00054: val_loss did not improve from 1.23166
Epoch 55/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1829 - acc: 0.4713 - val_loss: 1.2326 - val_acc: 0.4841

Epoch 00055: val_loss did not improve from 1.23166
Epoch 56/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1749 - acc: 0.4878 - val_loss: 1.2225 - val_acc: 0.4759

Epoch 00056: val_loss improved from 1.23166 to 1.22254, saving model to model3/56-1.2225.hdf5
Epoch 57/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1758 - acc: 0.4874 - val_loss: 1.2257 - val_acc: 0.4785

Epoch 00057: val_loss did not improve from 1.22254
Epoch 58/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1736 - acc: 0.4779 - val_loss: 1.2353 - val_acc: 0.4923

Epoch 00058: val_loss did not improve from 1.22254
Epoch 59/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1703 - acc: 0.4744 - val_loss: 1.2271 - val_acc: 0.4908

Epoch 00059: val_loss did not improve from 1.22254
Epoch 60/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1695 - acc: 0.4843 - val_loss: 1.2130 - val_acc: 0.4810

Epoch 00060: val_loss improved from 1.22254 to 1.21296, saving model to model3/60-1.2130.hdf5
Epoch 61/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1652 - acc: 0.4834 - val_loss: 1.2138 - val_acc: 0.4836

Epoch 00061: val_loss did not improve from 1.21296
Epoch 62/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1598 - acc: 0.4832 - val_loss: 1.2102 - val_acc: 0.4862

Epoch 00062: val_loss improved from 1.21296 to 1.21017, saving model to model3/62-1.2102.hdf5
Epoch 63/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1579 - acc: 0.4922 - val_loss: 1.2212 - val_acc: 0.4964

Epoch 00063: val_loss did not improve from 1.21017
Epoch 64/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1554 - acc: 0.4922 - val_loss: 1.2050 - val_acc: 0.5077

Epoch 00064: val_loss improved from 1.21017 to 1.20503, saving model to model3/64-1.2050.hdf5
Epoch 65/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1501 - acc: 0.5014 - val_loss: 1.2003 - val_acc: 0.4903

Epoch 00065: val_loss improved from 1.20503 to 1.20032, saving model to model3/65-1.2003.hdf5
Epoch 66/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1516 - acc: 0.4999 - val_loss: 1.1990 - val_acc: 0.4882

Epoch 00066: val_loss improved from 1.20032 to 1.19895, saving model to model3/66-1.1990.hdf5
Epoch 67/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1475 - acc: 0.4970 - val_loss: 1.1955 - val_acc: 0.5036

Epoch 00067: val_loss improved from 1.19895 to 1.19551, saving model to model3/67-1.1955.hdf5
Epoch 68/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1464 - acc: 0.4942 - val_loss: 1.1934 - val_acc: 0.4928

Epoch 00068: val_loss improved from 1.19551 to 1.19341, saving model to model3/68-1.1934.hdf5
Epoch 69/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1407 - acc: 0.5074 - val_loss: 1.1916 - val_acc: 0.5082

Epoch 00069: val_loss improved from 1.19341 to 1.19164, saving model to model3/69-1.1916.hdf5
Epoch 70/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1371 - acc: 0.4959 - val_loss: 1.2116 - val_acc: 0.5051

Epoch 00070: val_loss did not improve from 1.19164
Epoch 71/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1383 - acc: 0.5012 - val_loss: 1.1842 - val_acc: 0.4990

Epoch 00071: val_loss improved from 1.19164 to 1.18419, saving model to model3/71-1.1842.hdf5
Epoch 72/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1523 - acc: 0.4911 - val_loss: 1.2109 - val_acc: 0.5031

Epoch 00072: val_loss did not improve from 1.18419
Epoch 73/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1348 - acc: 0.5107 - val_loss: 1.1819 - val_acc: 0.5077

Epoch 00073: val_loss improved from 1.18419 to 1.18191, saving model to model3/73-1.1819.hdf5
Epoch 74/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1267 - acc: 0.4995 - val_loss: 1.1761 - val_acc: 0.5062

Epoch 00074: val_loss improved from 1.18191 to 1.17611, saving model to model3/74-1.1761.hdf5
Epoch 75/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1225 - acc: 0.5100 - val_loss: 1.1791 - val_acc: 0.5133

Epoch 00075: val_loss did not improve from 1.17611
Epoch 76/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1190 - acc: 0.5157 - val_loss: 1.1699 - val_acc: 0.5123

Epoch 00076: val_loss improved from 1.17611 to 1.16991, saving model to model3/76-1.1699.hdf5
Epoch 77/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1204 - acc: 0.5058 - val_loss: 1.1809 - val_acc: 0.5097

Epoch 00077: val_loss did not improve from 1.16991
Epoch 78/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1193 - acc: 0.5080 - val_loss: 1.1656 - val_acc: 0.5062

Epoch 00078: val_loss improved from 1.16991 to 1.16564, saving model to model3/78-1.1656.hdf5
Epoch 79/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1136 - acc: 0.5111 - val_loss: 1.1874 - val_acc: 0.5046

Epoch 00079: val_loss did not improve from 1.16564
Epoch 80/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1215 - acc: 0.5069 - val_loss: 1.1676 - val_acc: 0.5236

Epoch 00080: val_loss did not improve from 1.16564
Epoch 81/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1125 - acc: 0.5113 - val_loss: 1.1707 - val_acc: 0.5108

Epoch 00081: val_loss did not improve from 1.16564
Epoch 82/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1084 - acc: 0.5091 - val_loss: 1.1649 - val_acc: 0.5118

Epoch 00082: val_loss improved from 1.16564 to 1.16488, saving model to model3/82-1.1649.hdf5
Epoch 83/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1050 - acc: 0.5199 - val_loss: 1.1599 - val_acc: 0.5174

Epoch 00083: val_loss improved from 1.16488 to 1.15993, saving model to model3/83-1.1599.hdf5
Epoch 84/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1050 - acc: 0.5199 - val_loss: 1.1651 - val_acc: 0.4979

Epoch 00084: val_loss did not improve from 1.15993
Epoch 85/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1086 - acc: 0.5126 - val_loss: 1.1527 - val_acc: 0.5144

Epoch 00085: val_loss improved from 1.15993 to 1.15266, saving model to model3/85-1.1527.hdf5
Epoch 86/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1067 - acc: 0.5113 - val_loss: 1.2582 - val_acc: 0.4841

Epoch 00086: val_loss did not improve from 1.15266
Epoch 87/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1466 - acc: 0.5019 - val_loss: 1.1612 - val_acc: 0.5103

Epoch 00087: val_loss did not improve from 1.15266
Epoch 88/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1199 - acc: 0.5146 - val_loss: 1.1614 - val_acc: 0.5123

Epoch 00088: val_loss did not improve from 1.15266
Epoch 89/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1058 - acc: 0.5137 - val_loss: 1.1580 - val_acc: 0.5215

Epoch 00089: val_loss did not improve from 1.15266
Epoch 90/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1004 - acc: 0.5234 - val_loss: 1.1620 - val_acc: 0.5215

Epoch 00090: val_loss did not improve from 1.15266
Epoch 91/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0994 - acc: 0.5201 - val_loss: 1.1481 - val_acc: 0.5246

Epoch 00091: val_loss improved from 1.15266 to 1.14812, saving model to model3/91-1.1481.hdf5
Epoch 92/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1028 - acc: 0.5115 - val_loss: 1.1464 - val_acc: 0.5190

Epoch 00092: val_loss improved from 1.14812 to 1.14640, saving model to model3/92-1.1464.hdf5
Epoch 93/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1041 - acc: 0.5181 - val_loss: 1.1589 - val_acc: 0.5236

Epoch 00093: val_loss did not improve from 1.14640
Epoch 94/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0936 - acc: 0.5221 - val_loss: 1.1590 - val_acc: 0.5195

Epoch 00094: val_loss did not improve from 1.14640
Epoch 95/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0992 - acc: 0.5181 - val_loss: 1.1496 - val_acc: 0.5169

Epoch 00095: val_loss did not improve from 1.14640
Epoch 96/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0938 - acc: 0.5199 - val_loss: 1.1404 - val_acc: 0.5195

Epoch 00096: val_loss improved from 1.14640 to 1.14036, saving model to model3/96-1.1404.hdf5
Epoch 97/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0923 - acc: 0.5269 - val_loss: 1.1426 - val_acc: 0.5210

Epoch 00097: val_loss did not improve from 1.14036
Epoch 98/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0919 - acc: 0.5258 - val_loss: 1.1467 - val_acc: 0.5195

Epoch 00098: val_loss did not improve from 1.14036
Epoch 99/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0948 - acc: 0.5190 - val_loss: 1.1412 - val_acc: 0.5154

Epoch 00099: val_loss did not improve from 1.14036
Epoch 100/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0927 - acc: 0.5199 - val_loss: 1.1541 - val_acc: 0.5062

Epoch 00100: val_loss did not improve from 1.14036
Epoch 101/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0977 - acc: 0.5124 - val_loss: 1.1425 - val_acc: 0.5215

Epoch 00101: val_loss did not improve from 1.14036
Epoch 102/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0869 - acc: 0.5329 - val_loss: 1.1364 - val_acc: 0.5246

Epoch 00102: val_loss improved from 1.14036 to 1.13642, saving model to model3/102-1.1364.hdf5
Epoch 103/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0858 - acc: 0.5283 - val_loss: 1.2092 - val_acc: 0.4872

Epoch 00103: val_loss did not improve from 1.13642
Epoch 104/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1126 - acc: 0.5100 - val_loss: 1.1453 - val_acc: 0.5226

Epoch 00104: val_loss did not improve from 1.13642
Epoch 105/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1019 - acc: 0.5100 - val_loss: 1.1808 - val_acc: 0.5051

Epoch 00105: val_loss did not improve from 1.13642
Epoch 106/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1054 - acc: 0.5148 - val_loss: 1.1427 - val_acc: 0.5190

Epoch 00106: val_loss did not improve from 1.13642
Epoch 107/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1021 - acc: 0.5089 - val_loss: 1.1496 - val_acc: 0.5056

Epoch 00107: val_loss did not improve from 1.13642
Epoch 108/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0921 - acc: 0.5206 - val_loss: 1.1534 - val_acc: 0.5164

Epoch 00108: val_loss did not improve from 1.13642
Epoch 109/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0961 - acc: 0.5159 - val_loss: 1.1497 - val_acc: 0.5215

Epoch 00109: val_loss did not improve from 1.13642
Epoch 110/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0859 - acc: 0.5186 - val_loss: 1.1418 - val_acc: 0.5221

Epoch 00110: val_loss did not improve from 1.13642
Epoch 111/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0826 - acc: 0.5214 - val_loss: 1.1382 - val_acc: 0.5164

Epoch 00111: val_loss did not improve from 1.13642
Epoch 112/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0829 - acc: 0.5236 - val_loss: 1.1368 - val_acc: 0.5185

Epoch 00112: val_loss did not improve from 1.13642
Epoch 113/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0816 - acc: 0.5272 - val_loss: 1.1396 - val_acc: 0.5210

Epoch 00113: val_loss did not improve from 1.13642
Epoch 114/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0797 - acc: 0.5291 - val_loss: 1.1365 - val_acc: 0.5113

Epoch 00114: val_loss did not improve from 1.13642
Epoch 115/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0897 - acc: 0.5236 - val_loss: 1.1657 - val_acc: 0.5169

Epoch 00115: val_loss did not improve from 1.13642
Epoch 116/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0996 - acc: 0.5151 - val_loss: 1.1291 - val_acc: 0.5231

Epoch 00116: val_loss improved from 1.13642 to 1.12905, saving model to model3/116-1.1291.hdf5
Epoch 117/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0788 - acc: 0.5201 - val_loss: 1.1308 - val_acc: 0.5215

Epoch 00117: val_loss did not improve from 1.12905
Epoch 118/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0813 - acc: 0.5338 - val_loss: 1.1479 - val_acc: 0.5138

Epoch 00118: val_loss did not improve from 1.12905
Epoch 119/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1015 - acc: 0.5113 - val_loss: 1.1323 - val_acc: 0.5221

Epoch 00119: val_loss did not improve from 1.12905
Epoch 120/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0808 - acc: 0.5256 - val_loss: 1.1326 - val_acc: 0.5205

Epoch 00120: val_loss did not improve from 1.12905
Epoch 121/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0848 - acc: 0.5254 - val_loss: 1.1318 - val_acc: 0.5221

Epoch 00121: val_loss did not improve from 1.12905
Epoch 122/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0789 - acc: 0.5335 - val_loss: 1.1465 - val_acc: 0.5159

Epoch 00122: val_loss did not improve from 1.12905
Epoch 123/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0846 - acc: 0.5280 - val_loss: 1.1588 - val_acc: 0.5092

Epoch 00123: val_loss did not improve from 1.12905
Epoch 124/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1040 - acc: 0.5179 - val_loss: 1.1310 - val_acc: 0.5138

Epoch 00124: val_loss did not improve from 1.12905
Epoch 125/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0870 - acc: 0.5210 - val_loss: 1.1406 - val_acc: 0.5056

Epoch 00125: val_loss did not improve from 1.12905
Epoch 126/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0777 - acc: 0.5371 - val_loss: 1.1255 - val_acc: 0.5251

Epoch 00126: val_loss improved from 1.12905 to 1.12549, saving model to model3/126-1.1255.hdf5
Epoch 127/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0746 - acc: 0.5320 - val_loss: 1.1353 - val_acc: 0.5267

Epoch 00127: val_loss did not improve from 1.12549
Epoch 128/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0745 - acc: 0.5283 - val_loss: 1.1588 - val_acc: 0.5015

Epoch 00128: val_loss did not improve from 1.12549
Epoch 129/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0771 - acc: 0.5324 - val_loss: 1.1330 - val_acc: 0.5241

Epoch 00129: val_loss did not improve from 1.12549
Epoch 130/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0747 - acc: 0.5291 - val_loss: 1.1302 - val_acc: 0.5210

Epoch 00130: val_loss did not improve from 1.12549
Epoch 131/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0776 - acc: 0.5258 - val_loss: 1.1293 - val_acc: 0.5195

Epoch 00131: val_loss did not improve from 1.12549
Epoch 132/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0732 - acc: 0.5375 - val_loss: 1.1249 - val_acc: 0.5267

Epoch 00132: val_loss improved from 1.12549 to 1.12494, saving model to model3/132-1.1249.hdf5
Epoch 133/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0700 - acc: 0.5393 - val_loss: 1.1377 - val_acc: 0.5164

Epoch 00133: val_loss did not improve from 1.12494
Epoch 134/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0744 - acc: 0.5318 - val_loss: 1.1347 - val_acc: 0.5123

Epoch 00134: val_loss did not improve from 1.12494
Epoch 135/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0790 - acc: 0.5287 - val_loss: 1.1235 - val_acc: 0.5200

Epoch 00135: val_loss improved from 1.12494 to 1.12351, saving model to model3/135-1.1235.hdf5
Epoch 136/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0765 - acc: 0.5289 - val_loss: 1.1423 - val_acc: 0.5174

Epoch 00136: val_loss did not improve from 1.12351
Epoch 137/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0840 - acc: 0.5195 - val_loss: 1.1377 - val_acc: 0.5154

Epoch 00137: val_loss did not improve from 1.12351
Epoch 138/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0790 - acc: 0.5267 - val_loss: 1.1263 - val_acc: 0.5282

Epoch 00138: val_loss did not improve from 1.12351
Epoch 139/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0809 - acc: 0.5256 - val_loss: 1.1234 - val_acc: 0.5267

Epoch 00139: val_loss improved from 1.12351 to 1.12336, saving model to model3/139-1.1234.hdf5
Epoch 140/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0743 - acc: 0.5283 - val_loss: 1.1345 - val_acc: 0.5103

Epoch 00140: val_loss did not improve from 1.12336
Epoch 141/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0718 - acc: 0.5280 - val_loss: 1.1259 - val_acc: 0.5292

Epoch 00141: val_loss did not improve from 1.12336
Epoch 142/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0685 - acc: 0.5406 - val_loss: 1.1373 - val_acc: 0.5200

Epoch 00142: val_loss did not improve from 1.12336
Epoch 143/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0734 - acc: 0.5364 - val_loss: 1.1270 - val_acc: 0.5282

Epoch 00143: val_loss did not improve from 1.12336
Epoch 144/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0821 - acc: 0.5294 - val_loss: 1.1404 - val_acc: 0.5021

Epoch 00144: val_loss did not improve from 1.12336
Epoch 145/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0858 - acc: 0.5269 - val_loss: 1.1221 - val_acc: 0.5303

Epoch 00145: val_loss improved from 1.12336 to 1.12207, saving model to model3/145-1.1221.hdf5
Epoch 146/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0797 - acc: 0.5300 - val_loss: 1.1328 - val_acc: 0.5251

Epoch 00146: val_loss did not improve from 1.12207
Epoch 147/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0711 - acc: 0.5305 - val_loss: 1.1435 - val_acc: 0.5103

Epoch 00147: val_loss did not improve from 1.12207
Epoch 148/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0767 - acc: 0.5256 - val_loss: 1.1219 - val_acc: 0.5164

Epoch 00148: val_loss improved from 1.12207 to 1.12187, saving model to model3/148-1.1219.hdf5
Epoch 149/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0719 - acc: 0.5401 - val_loss: 1.1304 - val_acc: 0.5241

Epoch 00149: val_loss did not improve from 1.12187
Epoch 150/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0723 - acc: 0.5342 - val_loss: 1.1405 - val_acc: 0.5113

Epoch 00150: val_loss did not improve from 1.12187
Epoch 151/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0669 - acc: 0.5300 - val_loss: 1.1184 - val_acc: 0.5226

Epoch 00151: val_loss improved from 1.12187 to 1.11839, saving model to model3/151-1.1184.hdf5
Epoch 152/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0649 - acc: 0.5386 - val_loss: 1.1235 - val_acc: 0.5205

Epoch 00152: val_loss did not improve from 1.11839
Epoch 153/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0658 - acc: 0.5408 - val_loss: 1.1271 - val_acc: 0.5195

Epoch 00153: val_loss did not improve from 1.11839
Epoch 154/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0716 - acc: 0.5351 - val_loss: 1.1327 - val_acc: 0.5072

Epoch 00154: val_loss did not improve from 1.11839
Epoch 155/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0755 - acc: 0.5234 - val_loss: 1.1358 - val_acc: 0.5226

Epoch 00155: val_loss did not improve from 1.11839
Epoch 156/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0710 - acc: 0.5324 - val_loss: 1.1212 - val_acc: 0.5236

Epoch 00156: val_loss did not improve from 1.11839
Epoch 157/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0679 - acc: 0.5353 - val_loss: 1.1235 - val_acc: 0.5113

Epoch 00157: val_loss did not improve from 1.11839
Epoch 158/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0665 - acc: 0.5397 - val_loss: 1.1239 - val_acc: 0.5267

Epoch 00158: val_loss did not improve from 1.11839
Epoch 159/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0655 - acc: 0.5412 - val_loss: 1.1172 - val_acc: 0.5256

Epoch 00159: val_loss improved from 1.11839 to 1.11715, saving model to model3/159-1.1172.hdf5
Epoch 160/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0620 - acc: 0.5450 - val_loss: 1.1162 - val_acc: 0.5256

Epoch 00160: val_loss improved from 1.11715 to 1.11623, saving model to model3/160-1.1162.hdf5
Epoch 161/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0616 - acc: 0.5393 - val_loss: 1.1318 - val_acc: 0.5149

Epoch 00161: val_loss did not improve from 1.11623
Epoch 162/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0757 - acc: 0.5294 - val_loss: 1.1206 - val_acc: 0.5164

Epoch 00162: val_loss did not improve from 1.11623
Epoch 163/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0627 - acc: 0.5390 - val_loss: 1.1183 - val_acc: 0.5323

Epoch 00163: val_loss did not improve from 1.11623
Epoch 164/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0609 - acc: 0.5415 - val_loss: 1.1309 - val_acc: 0.5092

Epoch 00164: val_loss did not improve from 1.11623
Epoch 165/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0865 - acc: 0.5217 - val_loss: 1.1126 - val_acc: 0.5308

Epoch 00165: val_loss improved from 1.11623 to 1.11256, saving model to model3/165-1.1126.hdf5
Epoch 166/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0603 - acc: 0.5448 - val_loss: 1.1175 - val_acc: 0.5144

Epoch 00166: val_loss did not improve from 1.11256
Epoch 167/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0618 - acc: 0.5410 - val_loss: 1.1094 - val_acc: 0.5359

Epoch 00167: val_loss improved from 1.11256 to 1.10938, saving model to model3/167-1.1094.hdf5
Epoch 168/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0594 - acc: 0.5465 - val_loss: 1.1217 - val_acc: 0.5231

Epoch 00168: val_loss did not improve from 1.10938
Epoch 169/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0653 - acc: 0.5434 - val_loss: 1.1441 - val_acc: 0.5072

Epoch 00169: val_loss did not improve from 1.10938
Epoch 170/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0741 - acc: 0.5256 - val_loss: 1.1550 - val_acc: 0.5072

Epoch 00170: val_loss did not improve from 1.10938
Epoch 171/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0792 - acc: 0.5192 - val_loss: 1.1151 - val_acc: 0.5246

Epoch 00171: val_loss did not improve from 1.10938
Epoch 172/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0712 - acc: 0.5397 - val_loss: 1.1147 - val_acc: 0.5267

Epoch 00172: val_loss did not improve from 1.10938
Epoch 173/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0584 - acc: 0.5445 - val_loss: 1.1207 - val_acc: 0.5251

Epoch 00173: val_loss did not improve from 1.10938
Epoch 174/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0581 - acc: 0.5489 - val_loss: 1.1147 - val_acc: 0.5287

Epoch 00174: val_loss did not improve from 1.10938
Epoch 175/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0555 - acc: 0.5461 - val_loss: 1.1199 - val_acc: 0.5174

Epoch 00175: val_loss did not improve from 1.10938
Epoch 176/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0615 - acc: 0.5382 - val_loss: 1.1165 - val_acc: 0.5292

Epoch 00176: val_loss did not improve from 1.10938
Epoch 177/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0549 - acc: 0.5434 - val_loss: 1.1129 - val_acc: 0.5349

Epoch 00177: val_loss did not improve from 1.10938
Epoch 178/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0579 - acc: 0.5426 - val_loss: 1.1314 - val_acc: 0.5185

Epoch 00178: val_loss did not improve from 1.10938
Epoch 179/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0733 - acc: 0.5346 - val_loss: 1.1162 - val_acc: 0.5133

Epoch 00179: val_loss did not improve from 1.10938
Epoch 180/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0597 - acc: 0.5390 - val_loss: 1.1102 - val_acc: 0.5395

Epoch 00180: val_loss did not improve from 1.10938
Epoch 181/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0589 - acc: 0.5401 - val_loss: 1.1107 - val_acc: 0.5313

Epoch 00181: val_loss did not improve from 1.10938
Epoch 182/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0617 - acc: 0.5364 - val_loss: 1.1247 - val_acc: 0.5190

Epoch 00182: val_loss did not improve from 1.10938
Epoch 183/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0672 - acc: 0.5379 - val_loss: 1.1193 - val_acc: 0.5195

Epoch 00183: val_loss did not improve from 1.10938
Epoch 184/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0623 - acc: 0.5355 - val_loss: 1.1391 - val_acc: 0.5056

Epoch 00184: val_loss did not improve from 1.10938
Epoch 185/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0775 - acc: 0.5234 - val_loss: 1.1133 - val_acc: 0.5292

Epoch 00185: val_loss did not improve from 1.10938
Epoch 186/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0541 - acc: 0.5470 - val_loss: 1.1517 - val_acc: 0.5077

Epoch 00186: val_loss did not improve from 1.10938
Epoch 187/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0654 - acc: 0.5305 - val_loss: 1.1153 - val_acc: 0.5292

Epoch 00187: val_loss did not improve from 1.10938
Epoch 188/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0677 - acc: 0.5300 - val_loss: 1.1079 - val_acc: 0.5323

Epoch 00188: val_loss improved from 1.10938 to 1.10790, saving model to model3/188-1.1079.hdf5
Epoch 189/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0579 - acc: 0.5364 - val_loss: 1.1442 - val_acc: 0.5092

Epoch 00189: val_loss did not improve from 1.10790
Epoch 190/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0880 - acc: 0.5219 - val_loss: 1.1215 - val_acc: 0.5221

Epoch 00190: val_loss did not improve from 1.10790
Epoch 191/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0797 - acc: 0.5305 - val_loss: 1.1252 - val_acc: 0.5164

Epoch 00191: val_loss did not improve from 1.10790
Epoch 192/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0634 - acc: 0.5338 - val_loss: 1.1370 - val_acc: 0.5123

Epoch 00192: val_loss did not improve from 1.10790
Epoch 193/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0735 - acc: 0.5245 - val_loss: 1.1591 - val_acc: 0.5113

Epoch 00193: val_loss did not improve from 1.10790
Epoch 194/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0763 - acc: 0.5298 - val_loss: 1.1210 - val_acc: 0.5323

Epoch 00194: val_loss did not improve from 1.10790
Epoch 195/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0739 - acc: 0.5199 - val_loss: 1.1209 - val_acc: 0.5154

Epoch 00195: val_loss did not improve from 1.10790
Epoch 196/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0753 - acc: 0.5228 - val_loss: 1.1063 - val_acc: 0.5344

Epoch 00196: val_loss improved from 1.10790 to 1.10626, saving model to model3/196-1.1063.hdf5
Epoch 197/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0597 - acc: 0.5430 - val_loss: 1.1106 - val_acc: 0.5333

Epoch 00197: val_loss did not improve from 1.10626
Epoch 198/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0568 - acc: 0.5384 - val_loss: 1.1043 - val_acc: 0.5354

Epoch 00198: val_loss improved from 1.10626 to 1.10426, saving model to model3/198-1.1043.hdf5
Epoch 199/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0579 - acc: 0.5338 - val_loss: 1.1086 - val_acc: 0.5344

Epoch 00199: val_loss did not improve from 1.10426
Epoch 200/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0530 - acc: 0.5494 - val_loss: 1.1098 - val_acc: 0.5421

Epoch 00200: val_loss did not improve from 1.10426
Epoch 201/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0549 - acc: 0.5373 - val_loss: 1.1141 - val_acc: 0.5179

Epoch 00201: val_loss did not improve from 1.10426
Epoch 202/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0674 - acc: 0.5291 - val_loss: 1.1224 - val_acc: 0.5221

Epoch 00202: val_loss did not improve from 1.10426
Epoch 203/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0638 - acc: 0.5333 - val_loss: 1.1060 - val_acc: 0.5282

Epoch 00203: val_loss did not improve from 1.10426
Epoch 204/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0571 - acc: 0.5408 - val_loss: 1.1044 - val_acc: 0.5364

Epoch 00204: val_loss did not improve from 1.10426
Epoch 205/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0544 - acc: 0.5467 - val_loss: 1.1049 - val_acc: 0.5410

Epoch 00205: val_loss did not improve from 1.10426
Epoch 206/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0548 - acc: 0.5397 - val_loss: 1.1070 - val_acc: 0.5390

Epoch 00206: val_loss did not improve from 1.10426
Epoch 207/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0628 - acc: 0.5333 - val_loss: 1.1059 - val_acc: 0.5338

Epoch 00207: val_loss did not improve from 1.10426
Epoch 208/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0655 - acc: 0.5333 - val_loss: 1.1074 - val_acc: 0.5241

Epoch 00208: val_loss did not improve from 1.10426
Epoch 209/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0600 - acc: 0.5390 - val_loss: 1.1105 - val_acc: 0.5333

Epoch 00209: val_loss did not improve from 1.10426
Epoch 210/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0543 - acc: 0.5375 - val_loss: 1.1103 - val_acc: 0.5251

Epoch 00210: val_loss did not improve from 1.10426
Epoch 211/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0538 - acc: 0.5421 - val_loss: 1.1040 - val_acc: 0.5359

Epoch 00211: val_loss improved from 1.10426 to 1.10396, saving model to model3/211-1.1040.hdf5
Epoch 212/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0520 - acc: 0.5415 - val_loss: 1.1095 - val_acc: 0.5333

Epoch 00212: val_loss did not improve from 1.10396
Epoch 213/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0547 - acc: 0.5397 - val_loss: 1.1062 - val_acc: 0.5328

Epoch 00213: val_loss did not improve from 1.10396
Epoch 214/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0593 - acc: 0.5366 - val_loss: 1.1114 - val_acc: 0.5221

Epoch 00214: val_loss did not improve from 1.10396
Epoch 215/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0540 - acc: 0.5395 - val_loss: 1.1122 - val_acc: 0.5190

Epoch 00215: val_loss did not improve from 1.10396
Epoch 216/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0605 - acc: 0.5364 - val_loss: 1.1173 - val_acc: 0.5333

Epoch 00216: val_loss did not improve from 1.10396
Epoch 217/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0541 - acc: 0.5379 - val_loss: 1.1449 - val_acc: 0.5036

Epoch 00217: val_loss did not improve from 1.10396
Epoch 218/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0536 - acc: 0.5434 - val_loss: 1.1155 - val_acc: 0.5236

Epoch 00218: val_loss did not improve from 1.10396
Epoch 219/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0532 - acc: 0.5452 - val_loss: 1.1125 - val_acc: 0.5092

Epoch 00219: val_loss did not improve from 1.10396
Epoch 220/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0586 - acc: 0.5309 - val_loss: 1.1088 - val_acc: 0.5221

Epoch 00220: val_loss did not improve from 1.10396
Epoch 221/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0501 - acc: 0.5421 - val_loss: 1.1110 - val_acc: 0.5313

Epoch 00221: val_loss did not improve from 1.10396
Epoch 222/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0535 - acc: 0.5448 - val_loss: 1.1143 - val_acc: 0.5215

Epoch 00222: val_loss did not improve from 1.10396
Epoch 223/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0675 - acc: 0.5331 - val_loss: 1.1059 - val_acc: 0.5277

Epoch 00223: val_loss did not improve from 1.10396
Epoch 224/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0536 - acc: 0.5382 - val_loss: 1.1297 - val_acc: 0.5195

Epoch 00224: val_loss did not improve from 1.10396
Epoch 225/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0584 - acc: 0.5331 - val_loss: 1.1104 - val_acc: 0.5190

Epoch 00225: val_loss did not improve from 1.10396
Epoch 226/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0527 - acc: 0.5412 - val_loss: 1.1290 - val_acc: 0.5144

Epoch 00226: val_loss did not improve from 1.10396
Epoch 227/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0688 - acc: 0.5298 - val_loss: 1.1152 - val_acc: 0.5323

Epoch 00227: val_loss did not improve from 1.10396
Epoch 228/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0614 - acc: 0.5340 - val_loss: 1.1047 - val_acc: 0.5236

Epoch 00228: val_loss did not improve from 1.10396
Epoch 229/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0534 - acc: 0.5454 - val_loss: 1.1030 - val_acc: 0.5354

Epoch 00229: val_loss improved from 1.10396 to 1.10298, saving model to model3/229-1.1030.hdf5
Epoch 230/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0483 - acc: 0.5450 - val_loss: 1.1051 - val_acc: 0.5251

Epoch 00230: val_loss did not improve from 1.10298
Epoch 231/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0472 - acc: 0.5474 - val_loss: 1.1031 - val_acc: 0.5328

Epoch 00231: val_loss did not improve from 1.10298
Epoch 232/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0464 - acc: 0.5445 - val_loss: 1.1204 - val_acc: 0.5195

Epoch 00232: val_loss did not improve from 1.10298
Epoch 233/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0526 - acc: 0.5412 - val_loss: 1.0974 - val_acc: 0.5354

Epoch 00233: val_loss improved from 1.10298 to 1.09736, saving model to model3/233-1.0974.hdf5
Epoch 234/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0521 - acc: 0.5417 - val_loss: 1.1197 - val_acc: 0.5236

Epoch 00234: val_loss did not improve from 1.09736
Epoch 235/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0492 - acc: 0.5417 - val_loss: 1.0998 - val_acc: 0.5451

Epoch 00235: val_loss did not improve from 1.09736
Epoch 236/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0470 - acc: 0.5494 - val_loss: 1.1055 - val_acc: 0.5215

Epoch 00236: val_loss did not improve from 1.09736
Epoch 237/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0520 - acc: 0.5318 - val_loss: 1.1038 - val_acc: 0.5328

Epoch 00237: val_loss did not improve from 1.09736
Epoch 238/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0455 - acc: 0.5478 - val_loss: 1.1033 - val_acc: 0.5395

Epoch 00238: val_loss did not improve from 1.09736
Epoch 239/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0459 - acc: 0.5445 - val_loss: 1.1276 - val_acc: 0.5138

Epoch 00239: val_loss did not improve from 1.09736
Epoch 240/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0529 - acc: 0.5333 - val_loss: 1.1081 - val_acc: 0.5262

Epoch 00240: val_loss did not improve from 1.09736
Epoch 241/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0538 - acc: 0.5377 - val_loss: 1.1097 - val_acc: 0.5313

Epoch 00241: val_loss did not improve from 1.09736
Epoch 242/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0522 - acc: 0.5445 - val_loss: 1.1270 - val_acc: 0.5215

Epoch 00242: val_loss did not improve from 1.09736
Epoch 243/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0502 - acc: 0.5505 - val_loss: 1.1098 - val_acc: 0.5338

Epoch 00243: val_loss did not improve from 1.09736
Epoch 244/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0517 - acc: 0.5401 - val_loss: 1.1140 - val_acc: 0.5210

Epoch 00244: val_loss did not improve from 1.09736
Epoch 245/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0515 - acc: 0.5401 - val_loss: 1.1088 - val_acc: 0.5344

Epoch 00245: val_loss did not improve from 1.09736
Epoch 246/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0495 - acc: 0.5410 - val_loss: 1.1071 - val_acc: 0.5344

Epoch 00246: val_loss did not improve from 1.09736
Epoch 247/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0596 - acc: 0.5357 - val_loss: 1.1528 - val_acc: 0.4882

Epoch 00247: val_loss did not improve from 1.09736
Epoch 248/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0656 - acc: 0.5333 - val_loss: 1.1031 - val_acc: 0.5241

Epoch 00248: val_loss did not improve from 1.09736
Epoch 249/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0580 - acc: 0.5355 - val_loss: 1.1047 - val_acc: 0.5436

Epoch 00249: val_loss did not improve from 1.09736
Epoch 250/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0495 - acc: 0.5439 - val_loss: 1.1180 - val_acc: 0.5205

Epoch 00250: val_loss did not improve from 1.09736
Epoch 251/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0574 - acc: 0.5426 - val_loss: 1.1070 - val_acc: 0.5256

Epoch 00251: val_loss did not improve from 1.09736
Epoch 252/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0667 - acc: 0.5320 - val_loss: 1.1062 - val_acc: 0.5318

Epoch 00252: val_loss did not improve from 1.09736
Epoch 253/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0533 - acc: 0.5423 - val_loss: 1.1019 - val_acc: 0.5272

Epoch 00253: val_loss did not improve from 1.09736
Epoch 254/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0434 - acc: 0.5474 - val_loss: 1.1068 - val_acc: 0.5292

Epoch 00254: val_loss did not improve from 1.09736
Epoch 255/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0423 - acc: 0.5509 - val_loss: 1.1085 - val_acc: 0.5241

Epoch 00255: val_loss did not improve from 1.09736
Epoch 256/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0523 - acc: 0.5426 - val_loss: 1.1069 - val_acc: 0.5349

Epoch 00256: val_loss did not improve from 1.09736
Epoch 257/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0451 - acc: 0.5421 - val_loss: 1.1026 - val_acc: 0.5333

Epoch 00257: val_loss did not improve from 1.09736
Epoch 258/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0494 - acc: 0.5390 - val_loss: 1.1173 - val_acc: 0.5210

Epoch 00258: val_loss did not improve from 1.09736
Epoch 259/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0599 - acc: 0.5305 - val_loss: 1.1093 - val_acc: 0.5344

Epoch 00259: val_loss did not improve from 1.09736
Epoch 260/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0537 - acc: 0.5406 - val_loss: 1.1329 - val_acc: 0.5051

Epoch 00260: val_loss did not improve from 1.09736
Epoch 261/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0725 - acc: 0.5269 - val_loss: 1.1122 - val_acc: 0.5236

Epoch 00261: val_loss did not improve from 1.09736
Epoch 262/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0624 - acc: 0.5322 - val_loss: 1.0985 - val_acc: 0.5282

Epoch 00262: val_loss did not improve from 1.09736
Epoch 263/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0453 - acc: 0.5496 - val_loss: 1.1125 - val_acc: 0.5200

Epoch 00263: val_loss did not improve from 1.09736
Epoch 264/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0502 - acc: 0.5423 - val_loss: 1.1216 - val_acc: 0.5256

Epoch 00264: val_loss did not improve from 1.09736
Epoch 265/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0521 - acc: 0.5344 - val_loss: 1.0946 - val_acc: 0.5446

Epoch 00265: val_loss improved from 1.09736 to 1.09462, saving model to model3/265-1.0946.hdf5
Epoch 266/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0429 - acc: 0.5474 - val_loss: 1.0958 - val_acc: 0.5333

Epoch 00266: val_loss did not improve from 1.09462
Epoch 267/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0445 - acc: 0.5481 - val_loss: 1.1120 - val_acc: 0.5123

Epoch 00267: val_loss did not improve from 1.09462
Epoch 268/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0514 - acc: 0.5430 - val_loss: 1.1322 - val_acc: 0.5318

Epoch 00268: val_loss did not improve from 1.09462
Epoch 269/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0454 - acc: 0.5430 - val_loss: 1.1007 - val_acc: 0.5205

Epoch 00269: val_loss did not improve from 1.09462
Epoch 270/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0467 - acc: 0.5388 - val_loss: 1.0972 - val_acc: 0.5431

Epoch 00270: val_loss did not improve from 1.09462
Epoch 271/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0421 - acc: 0.5448 - val_loss: 1.0963 - val_acc: 0.5308

Epoch 00271: val_loss did not improve from 1.09462
Epoch 272/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0435 - acc: 0.5445 - val_loss: 1.1005 - val_acc: 0.5354

Epoch 00272: val_loss did not improve from 1.09462
Epoch 273/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0466 - acc: 0.5452 - val_loss: 1.1013 - val_acc: 0.5323

Epoch 00273: val_loss did not improve from 1.09462
Epoch 274/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0445 - acc: 0.5459 - val_loss: 1.1209 - val_acc: 0.5251

Epoch 00274: val_loss did not improve from 1.09462
Epoch 275/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0495 - acc: 0.5437 - val_loss: 1.1067 - val_acc: 0.5292

Epoch 00275: val_loss did not improve from 1.09462
Epoch 276/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0512 - acc: 0.5408 - val_loss: 1.0962 - val_acc: 0.5323

Epoch 00276: val_loss did not improve from 1.09462
Epoch 277/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0451 - acc: 0.5465 - val_loss: 1.1136 - val_acc: 0.5462

Epoch 00277: val_loss did not improve from 1.09462
Epoch 278/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0549 - acc: 0.5349 - val_loss: 1.1086 - val_acc: 0.5267

Epoch 00278: val_loss did not improve from 1.09462
Epoch 279/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0487 - acc: 0.5388 - val_loss: 1.0966 - val_acc: 0.5323

Epoch 00279: val_loss did not improve from 1.09462
Epoch 280/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0460 - acc: 0.5426 - val_loss: 1.0947 - val_acc: 0.5379

Epoch 00280: val_loss did not improve from 1.09462
Epoch 281/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0379 - acc: 0.5489 - val_loss: 1.1056 - val_acc: 0.5231

Epoch 00281: val_loss did not improve from 1.09462
Epoch 282/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0402 - acc: 0.5445 - val_loss: 1.1067 - val_acc: 0.5215

Epoch 00282: val_loss did not improve from 1.09462
Epoch 283/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0487 - acc: 0.5390 - val_loss: 1.1051 - val_acc: 0.5292

Epoch 00283: val_loss did not improve from 1.09462
Epoch 284/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0434 - acc: 0.5459 - val_loss: 1.1143 - val_acc: 0.5251

Epoch 00284: val_loss did not improve from 1.09462
Epoch 285/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0437 - acc: 0.5428 - val_loss: 1.0940 - val_acc: 0.5359

Epoch 00285: val_loss improved from 1.09462 to 1.09397, saving model to model3/285-1.0940.hdf5
Epoch 286/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0423 - acc: 0.5445 - val_loss: 1.0962 - val_acc: 0.5390

Epoch 00286: val_loss did not improve from 1.09397
Epoch 287/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0411 - acc: 0.5542 - val_loss: 1.0969 - val_acc: 0.5405

Epoch 00287: val_loss did not improve from 1.09397
Epoch 288/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0398 - acc: 0.5489 - val_loss: 1.0978 - val_acc: 0.5313

Epoch 00288: val_loss did not improve from 1.09397
Epoch 289/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0419 - acc: 0.5423 - val_loss: 1.1063 - val_acc: 0.5174

Epoch 00289: val_loss did not improve from 1.09397
Epoch 290/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0398 - acc: 0.5489 - val_loss: 1.0932 - val_acc: 0.5313

Epoch 00290: val_loss improved from 1.09397 to 1.09318, saving model to model3/290-1.0932.hdf5
Epoch 291/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0436 - acc: 0.5463 - val_loss: 1.1141 - val_acc: 0.5190

Epoch 00291: val_loss did not improve from 1.09318
Epoch 292/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0461 - acc: 0.5412 - val_loss: 1.1011 - val_acc: 0.5282

Epoch 00292: val_loss did not improve from 1.09318
Epoch 293/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0433 - acc: 0.5481 - val_loss: 1.0983 - val_acc: 0.5205

Epoch 00293: val_loss did not improve from 1.09318
Epoch 294/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0425 - acc: 0.5445 - val_loss: 1.1009 - val_acc: 0.5303

Epoch 00294: val_loss did not improve from 1.09318
Epoch 295/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0375 - acc: 0.5503 - val_loss: 1.1020 - val_acc: 0.5282

Epoch 00295: val_loss did not improve from 1.09318
Epoch 296/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0548 - acc: 0.5393 - val_loss: 1.1053 - val_acc: 0.5369

Epoch 00296: val_loss did not improve from 1.09318
Epoch 297/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0392 - acc: 0.5489 - val_loss: 1.0994 - val_acc: 0.5246

Epoch 00297: val_loss did not improve from 1.09318
Epoch 298/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0498 - acc: 0.5364 - val_loss: 1.0917 - val_acc: 0.5344

Epoch 00298: val_loss improved from 1.09318 to 1.09167, saving model to model3/298-1.0917.hdf5
Epoch 299/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0359 - acc: 0.5527 - val_loss: 1.1237 - val_acc: 0.5200

Epoch 00299: val_loss did not improve from 1.09167
Epoch 300/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0509 - acc: 0.5489 - val_loss: 1.1170 - val_acc: 0.5246

Epoch 00300: val_loss did not improve from 1.09167
Epoch 301/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0414 - acc: 0.5423 - val_loss: 1.0920 - val_acc: 0.5328

Epoch 00301: val_loss did not improve from 1.09167
Epoch 302/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0381 - acc: 0.5516 - val_loss: 1.1010 - val_acc: 0.5251

Epoch 00302: val_loss did not improve from 1.09167
Epoch 303/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0466 - acc: 0.5419 - val_loss: 1.0948 - val_acc: 0.5256

Epoch 00303: val_loss did not improve from 1.09167
Epoch 304/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0541 - acc: 0.5399 - val_loss: 1.0968 - val_acc: 0.5333

Epoch 00304: val_loss did not improve from 1.09167
Epoch 305/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0391 - acc: 0.5511 - val_loss: 1.0932 - val_acc: 0.5410

Epoch 00305: val_loss did not improve from 1.09167
Epoch 306/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0399 - acc: 0.5518 - val_loss: 1.0959 - val_acc: 0.5385

Epoch 00306: val_loss did not improve from 1.09167
Epoch 307/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0388 - acc: 0.5454 - val_loss: 1.0941 - val_acc: 0.5323

Epoch 00307: val_loss did not improve from 1.09167
Epoch 308/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0392 - acc: 0.5434 - val_loss: 1.1402 - val_acc: 0.5072

Epoch 00308: val_loss did not improve from 1.09167
Epoch 309/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0529 - acc: 0.5481 - val_loss: 1.0991 - val_acc: 0.5297

Epoch 00309: val_loss did not improve from 1.09167
Epoch 310/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0419 - acc: 0.5423 - val_loss: 1.0965 - val_acc: 0.5303

Epoch 00310: val_loss did not improve from 1.09167
Epoch 311/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0364 - acc: 0.5500 - val_loss: 1.0993 - val_acc: 0.5328

Epoch 00311: val_loss did not improve from 1.09167
Epoch 312/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0354 - acc: 0.5489 - val_loss: 1.1043 - val_acc: 0.5354

Epoch 00312: val_loss did not improve from 1.09167
Epoch 313/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0389 - acc: 0.5437 - val_loss: 1.0919 - val_acc: 0.5318

Epoch 00313: val_loss did not improve from 1.09167
Epoch 314/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0348 - acc: 0.5525 - val_loss: 1.0959 - val_acc: 0.5221

Epoch 00314: val_loss did not improve from 1.09167
Epoch 315/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0441 - acc: 0.5397 - val_loss: 1.0941 - val_acc: 0.5379

Epoch 00315: val_loss did not improve from 1.09167
Epoch 316/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0375 - acc: 0.5507 - val_loss: 1.0948 - val_acc: 0.5308

Epoch 00316: val_loss did not improve from 1.09167
Epoch 317/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0367 - acc: 0.5448 - val_loss: 1.0969 - val_acc: 0.5379

Epoch 00317: val_loss did not improve from 1.09167
Epoch 318/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0465 - acc: 0.5448 - val_loss: 1.1056 - val_acc: 0.5369

Epoch 00318: val_loss did not improve from 1.09167
Epoch 319/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0426 - acc: 0.5351 - val_loss: 1.1010 - val_acc: 0.5231

Epoch 00319: val_loss did not improve from 1.09167
Epoch 320/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0475 - acc: 0.5423 - val_loss: 1.1255 - val_acc: 0.5210

Epoch 00320: val_loss did not improve from 1.09167
Epoch 321/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0460 - acc: 0.5474 - val_loss: 1.0966 - val_acc: 0.5308

Epoch 00321: val_loss did not improve from 1.09167
Epoch 322/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0384 - acc: 0.5514 - val_loss: 1.0895 - val_acc: 0.5349

Epoch 00322: val_loss improved from 1.09167 to 1.08951, saving model to model3/322-1.0895.hdf5
Epoch 323/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0351 - acc: 0.5580 - val_loss: 1.0931 - val_acc: 0.5328

Epoch 00323: val_loss did not improve from 1.08951
Epoch 324/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0385 - acc: 0.5533 - val_loss: 1.0914 - val_acc: 0.5395

Epoch 00324: val_loss did not improve from 1.08951
Epoch 325/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0365 - acc: 0.5527 - val_loss: 1.0884 - val_acc: 0.5405

Epoch 00325: val_loss improved from 1.08951 to 1.08838, saving model to model3/325-1.0884.hdf5
Epoch 326/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0363 - acc: 0.5516 - val_loss: 1.0924 - val_acc: 0.5390

Epoch 00326: val_loss did not improve from 1.08838
Epoch 327/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0506 - acc: 0.5355 - val_loss: 1.0974 - val_acc: 0.5354

Epoch 00327: val_loss did not improve from 1.08838
Epoch 328/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0400 - acc: 0.5538 - val_loss: 1.1092 - val_acc: 0.5144

Epoch 00328: val_loss did not improve from 1.08838
Epoch 329/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0424 - acc: 0.5474 - val_loss: 1.1029 - val_acc: 0.5272

Epoch 00329: val_loss did not improve from 1.08838
Epoch 330/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0412 - acc: 0.5395 - val_loss: 1.1116 - val_acc: 0.5359

Epoch 00330: val_loss did not improve from 1.08838
Epoch 331/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0373 - acc: 0.5467 - val_loss: 1.0899 - val_acc: 0.5364

Epoch 00331: val_loss did not improve from 1.08838
Epoch 332/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0367 - acc: 0.5514 - val_loss: 1.1329 - val_acc: 0.5056

Epoch 00332: val_loss did not improve from 1.08838
Epoch 333/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0523 - acc: 0.5459 - val_loss: 1.0936 - val_acc: 0.5292

Epoch 00333: val_loss did not improve from 1.08838
Epoch 334/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0367 - acc: 0.5463 - val_loss: 1.0915 - val_acc: 0.5323

Epoch 00334: val_loss did not improve from 1.08838
Epoch 335/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0368 - acc: 0.5562 - val_loss: 1.0975 - val_acc: 0.5426

Epoch 00335: val_loss did not improve from 1.08838
Epoch 336/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0364 - acc: 0.5509 - val_loss: 1.0946 - val_acc: 0.5256

Epoch 00336: val_loss did not improve from 1.08838
Epoch 337/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0328 - acc: 0.5575 - val_loss: 1.1102 - val_acc: 0.5185

Epoch 00337: val_loss did not improve from 1.08838
Epoch 338/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0475 - acc: 0.5434 - val_loss: 1.0929 - val_acc: 0.5292

Epoch 00338: val_loss did not improve from 1.08838
Epoch 339/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0347 - acc: 0.5423 - val_loss: 1.0893 - val_acc: 0.5292

Epoch 00339: val_loss did not improve from 1.08838
Epoch 340/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0355 - acc: 0.5560 - val_loss: 1.0904 - val_acc: 0.5344

Epoch 00340: val_loss did not improve from 1.08838
Epoch 341/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0315 - acc: 0.5555 - val_loss: 1.0905 - val_acc: 0.5359

Epoch 00341: val_loss did not improve from 1.08838
Epoch 342/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0367 - acc: 0.5474 - val_loss: 1.1054 - val_acc: 0.5267

Epoch 00342: val_loss did not improve from 1.08838
Epoch 343/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0339 - acc: 0.5496 - val_loss: 1.0895 - val_acc: 0.5359

Epoch 00343: val_loss did not improve from 1.08838
Epoch 344/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0348 - acc: 0.5500 - val_loss: 1.1052 - val_acc: 0.5338

Epoch 00344: val_loss did not improve from 1.08838
Epoch 345/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0385 - acc: 0.5459 - val_loss: 1.0986 - val_acc: 0.5231

Epoch 00345: val_loss did not improve from 1.08838
Epoch 346/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0443 - acc: 0.5478 - val_loss: 1.0878 - val_acc: 0.5415

Epoch 00346: val_loss improved from 1.08838 to 1.08783, saving model to model3/346-1.0878.hdf5
Epoch 347/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0370 - acc: 0.5527 - val_loss: 1.0942 - val_acc: 0.5354

Epoch 00347: val_loss did not improve from 1.08783
Epoch 348/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0348 - acc: 0.5507 - val_loss: 1.0937 - val_acc: 0.5395

Epoch 00348: val_loss did not improve from 1.08783
Epoch 349/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0323 - acc: 0.5507 - val_loss: 1.0871 - val_acc: 0.5338

Epoch 00349: val_loss improved from 1.08783 to 1.08713, saving model to model3/349-1.0871.hdf5
Epoch 350/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0353 - acc: 0.5518 - val_loss: 1.1171 - val_acc: 0.5272

Epoch 00350: val_loss did not improve from 1.08713
Epoch 351/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0448 - acc: 0.5428 - val_loss: 1.1124 - val_acc: 0.5190

Epoch 00351: val_loss did not improve from 1.08713
Epoch 352/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0463 - acc: 0.5399 - val_loss: 1.0920 - val_acc: 0.5349

Epoch 00352: val_loss did not improve from 1.08713
Epoch 353/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0411 - acc: 0.5481 - val_loss: 1.1543 - val_acc: 0.5169

Epoch 00353: val_loss did not improve from 1.08713
Epoch 354/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0432 - acc: 0.5434 - val_loss: 1.0896 - val_acc: 0.5344

Epoch 00354: val_loss did not improve from 1.08713
Epoch 355/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0314 - acc: 0.5492 - val_loss: 1.1044 - val_acc: 0.5226

Epoch 00355: val_loss did not improve from 1.08713
Epoch 356/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0399 - acc: 0.5430 - val_loss: 1.0894 - val_acc: 0.5364

Epoch 00356: val_loss did not improve from 1.08713
Epoch 357/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0297 - acc: 0.5569 - val_loss: 1.0858 - val_acc: 0.5436

Epoch 00357: val_loss improved from 1.08713 to 1.08577, saving model to model3/357-1.0858.hdf5
Epoch 358/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0329 - acc: 0.5522 - val_loss: 1.0849 - val_acc: 0.5344

Epoch 00358: val_loss improved from 1.08577 to 1.08494, saving model to model3/358-1.0849.hdf5
Epoch 359/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0327 - acc: 0.5549 - val_loss: 1.0965 - val_acc: 0.5277

Epoch 00359: val_loss did not improve from 1.08494
Epoch 360/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0309 - acc: 0.5595 - val_loss: 1.0866 - val_acc: 0.5338

Epoch 00360: val_loss did not improve from 1.08494
Epoch 361/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0379 - acc: 0.5456 - val_loss: 1.0920 - val_acc: 0.5231

Epoch 00361: val_loss did not improve from 1.08494
Epoch 362/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0306 - acc: 0.5533 - val_loss: 1.0866 - val_acc: 0.5359

Epoch 00362: val_loss did not improve from 1.08494
Epoch 363/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0342 - acc: 0.5489 - val_loss: 1.0893 - val_acc: 0.5456

Epoch 00363: val_loss did not improve from 1.08494
Epoch 364/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0288 - acc: 0.5551 - val_loss: 1.0979 - val_acc: 0.5231

Epoch 00364: val_loss did not improve from 1.08494
Epoch 365/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0284 - acc: 0.5498 - val_loss: 1.0829 - val_acc: 0.5436

Epoch 00365: val_loss improved from 1.08494 to 1.08291, saving model to model3/365-1.0829.hdf5
Epoch 366/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0280 - acc: 0.5529 - val_loss: 1.0849 - val_acc: 0.5426

Epoch 00366: val_loss did not improve from 1.08291
Epoch 367/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0312 - acc: 0.5527 - val_loss: 1.1194 - val_acc: 0.5251

Epoch 00367: val_loss did not improve from 1.08291
Epoch 368/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0381 - acc: 0.5445 - val_loss: 1.0859 - val_acc: 0.5297

Epoch 00368: val_loss did not improve from 1.08291
Epoch 369/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0352 - acc: 0.5485 - val_loss: 1.1059 - val_acc: 0.5328

Epoch 00369: val_loss did not improve from 1.08291
Epoch 370/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0498 - acc: 0.5417 - val_loss: 1.0998 - val_acc: 0.5231

Epoch 00370: val_loss did not improve from 1.08291
Epoch 371/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0525 - acc: 0.5329 - val_loss: 1.0936 - val_acc: 0.5282

Epoch 00371: val_loss did not improve from 1.08291
Epoch 372/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0348 - acc: 0.5452 - val_loss: 1.0951 - val_acc: 0.5282

Epoch 00372: val_loss did not improve from 1.08291
Epoch 373/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0388 - acc: 0.5503 - val_loss: 1.0961 - val_acc: 0.5328

Epoch 00373: val_loss did not improve from 1.08291
Epoch 374/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0380 - acc: 0.5485 - val_loss: 1.0846 - val_acc: 0.5297

Epoch 00374: val_loss did not improve from 1.08291
Epoch 375/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0371 - acc: 0.5461 - val_loss: 1.0913 - val_acc: 0.5364

Epoch 00375: val_loss did not improve from 1.08291
Epoch 376/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0316 - acc: 0.5577 - val_loss: 1.0894 - val_acc: 0.5277

Epoch 00376: val_loss did not improve from 1.08291
Epoch 377/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0358 - acc: 0.5461 - val_loss: 1.1317 - val_acc: 0.5164

Epoch 00377: val_loss did not improve from 1.08291
Epoch 378/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0430 - acc: 0.5463 - val_loss: 1.0903 - val_acc: 0.5426

Epoch 00378: val_loss did not improve from 1.08291
Epoch 379/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0300 - acc: 0.5478 - val_loss: 1.1061 - val_acc: 0.5328

Epoch 00379: val_loss did not improve from 1.08291
Epoch 380/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0394 - acc: 0.5518 - val_loss: 1.0886 - val_acc: 0.5226

Epoch 00380: val_loss did not improve from 1.08291
Epoch 381/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0297 - acc: 0.5540 - val_loss: 1.0926 - val_acc: 0.5349

Epoch 00381: val_loss did not improve from 1.08291
Epoch 382/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0324 - acc: 0.5483 - val_loss: 1.0973 - val_acc: 0.5385

Epoch 00382: val_loss did not improve from 1.08291
Epoch 383/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0319 - acc: 0.5522 - val_loss: 1.0909 - val_acc: 0.5308

Epoch 00383: val_loss did not improve from 1.08291
Epoch 384/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0309 - acc: 0.5544 - val_loss: 1.0856 - val_acc: 0.5323

Epoch 00384: val_loss did not improve from 1.08291
Epoch 385/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0276 - acc: 0.5487 - val_loss: 1.0927 - val_acc: 0.5369

Epoch 00385: val_loss did not improve from 1.08291
Epoch 386/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0380 - acc: 0.5474 - val_loss: 1.1051 - val_acc: 0.5241

Epoch 00386: val_loss did not improve from 1.08291
Epoch 387/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0364 - acc: 0.5395 - val_loss: 1.0802 - val_acc: 0.5390

Epoch 00387: val_loss improved from 1.08291 to 1.08025, saving model to model3/387-1.0802.hdf5
Epoch 388/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0351 - acc: 0.5496 - val_loss: 1.0856 - val_acc: 0.5374

Epoch 00388: val_loss did not improve from 1.08025
Epoch 389/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0298 - acc: 0.5507 - val_loss: 1.0878 - val_acc: 0.5431

Epoch 00389: val_loss did not improve from 1.08025
Epoch 390/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0302 - acc: 0.5536 - val_loss: 1.0837 - val_acc: 0.5354

Epoch 00390: val_loss did not improve from 1.08025
Epoch 391/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0320 - acc: 0.5533 - val_loss: 1.0933 - val_acc: 0.5277

Epoch 00391: val_loss did not improve from 1.08025
Epoch 392/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0381 - acc: 0.5483 - val_loss: 1.0916 - val_acc: 0.5246

Epoch 00392: val_loss did not improve from 1.08025
Epoch 393/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0313 - acc: 0.5459 - val_loss: 1.0882 - val_acc: 0.5344

Epoch 00393: val_loss did not improve from 1.08025
Epoch 394/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0369 - acc: 0.5445 - val_loss: 1.0970 - val_acc: 0.5374

Epoch 00394: val_loss did not improve from 1.08025
Epoch 395/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0383 - acc: 0.5439 - val_loss: 1.0994 - val_acc: 0.5221

Epoch 00395: val_loss did not improve from 1.08025
Epoch 396/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0456 - acc: 0.5494 - val_loss: 1.0884 - val_acc: 0.5262

Epoch 00396: val_loss did not improve from 1.08025
Epoch 397/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0362 - acc: 0.5474 - val_loss: 1.0975 - val_acc: 0.5379

Epoch 00397: val_loss did not improve from 1.08025
Epoch 398/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0376 - acc: 0.5454 - val_loss: 1.0955 - val_acc: 0.5226

Epoch 00398: val_loss did not improve from 1.08025
Epoch 399/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0494 - acc: 0.5443 - val_loss: 1.0926 - val_acc: 0.5251

Epoch 00399: val_loss did not improve from 1.08025
Epoch 400/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0549 - acc: 0.5452 - val_loss: 1.1056 - val_acc: 0.5354

Epoch 00400: val_loss did not improve from 1.08025
Epoch 401/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0321 - acc: 0.5520 - val_loss: 1.0852 - val_acc: 0.5359

Epoch 00401: val_loss did not improve from 1.08025
Epoch 402/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0290 - acc: 0.5597 - val_loss: 1.0827 - val_acc: 0.5313

Epoch 00402: val_loss did not improve from 1.08025
Epoch 403/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0343 - acc: 0.5481 - val_loss: 1.0991 - val_acc: 0.5272

Epoch 00403: val_loss did not improve from 1.08025
Epoch 404/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0398 - acc: 0.5382 - val_loss: 1.0783 - val_acc: 0.5421

Epoch 00404: val_loss improved from 1.08025 to 1.07832, saving model to model3/404-1.0783.hdf5
Epoch 405/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0264 - acc: 0.5540 - val_loss: 1.0884 - val_acc: 0.5349

Epoch 00405: val_loss did not improve from 1.07832
Epoch 406/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0295 - acc: 0.5551 - val_loss: 1.0822 - val_acc: 0.5328

Epoch 00406: val_loss did not improve from 1.07832
Epoch 407/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0387 - acc: 0.5439 - val_loss: 1.0805 - val_acc: 0.5379

Epoch 00407: val_loss did not improve from 1.07832
Epoch 408/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0290 - acc: 0.5547 - val_loss: 1.1016 - val_acc: 0.5390

Epoch 00408: val_loss did not improve from 1.07832
Epoch 409/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0304 - acc: 0.5544 - val_loss: 1.0809 - val_acc: 0.5400

Epoch 00409: val_loss did not improve from 1.07832
Epoch 410/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0300 - acc: 0.5542 - val_loss: 1.0836 - val_acc: 0.5374

Epoch 00410: val_loss did not improve from 1.07832
Epoch 411/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0279 - acc: 0.5542 - val_loss: 1.0850 - val_acc: 0.5374

Epoch 00411: val_loss did not improve from 1.07832
Epoch 412/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0365 - acc: 0.5472 - val_loss: 1.0858 - val_acc: 0.5205

Epoch 00412: val_loss did not improve from 1.07832
Epoch 413/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0274 - acc: 0.5593 - val_loss: 1.1019 - val_acc: 0.5313

Epoch 00413: val_loss did not improve from 1.07832
Epoch 414/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0364 - acc: 0.5467 - val_loss: 1.0799 - val_acc: 0.5405

Epoch 00414: val_loss did not improve from 1.07832
Epoch 415/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0315 - acc: 0.5494 - val_loss: 1.0893 - val_acc: 0.5251

Epoch 00415: val_loss did not improve from 1.07832
Epoch 416/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0351 - acc: 0.5430 - val_loss: 1.0822 - val_acc: 0.5359

Epoch 00416: val_loss did not improve from 1.07832
Epoch 417/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0253 - acc: 0.5608 - val_loss: 1.1063 - val_acc: 0.5205

Epoch 00417: val_loss did not improve from 1.07832
Epoch 418/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0343 - acc: 0.5564 - val_loss: 1.0842 - val_acc: 0.5364

Epoch 00418: val_loss did not improve from 1.07832
Epoch 419/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0317 - acc: 0.5500 - val_loss: 1.0822 - val_acc: 0.5385

Epoch 00419: val_loss did not improve from 1.07832
Epoch 420/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0301 - acc: 0.5538 - val_loss: 1.0950 - val_acc: 0.5292

Epoch 00420: val_loss did not improve from 1.07832
Epoch 421/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0441 - acc: 0.5441 - val_loss: 1.1652 - val_acc: 0.5128

Epoch 00421: val_loss did not improve from 1.07832
Epoch 422/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0551 - acc: 0.5393 - val_loss: 1.0811 - val_acc: 0.5354

Epoch 00422: val_loss did not improve from 1.07832
Epoch 423/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0350 - acc: 0.5470 - val_loss: 1.0842 - val_acc: 0.5385

Epoch 00423: val_loss did not improve from 1.07832
Epoch 424/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0287 - acc: 0.5558 - val_loss: 1.1423 - val_acc: 0.5123

Epoch 00424: val_loss did not improve from 1.07832
Epoch 425/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0463 - acc: 0.5459 - val_loss: 1.0957 - val_acc: 0.5313

Epoch 00425: val_loss did not improve from 1.07832
Epoch 426/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0257 - acc: 0.5538 - val_loss: 1.0887 - val_acc: 0.5354

Epoch 00426: val_loss did not improve from 1.07832
Epoch 427/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0278 - acc: 0.5516 - val_loss: 1.1034 - val_acc: 0.5241

Epoch 00427: val_loss did not improve from 1.07832
Epoch 428/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0331 - acc: 0.5514 - val_loss: 1.0916 - val_acc: 0.5241

Epoch 00428: val_loss did not improve from 1.07832
Epoch 429/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0280 - acc: 0.5478 - val_loss: 1.0829 - val_acc: 0.5410

Epoch 00429: val_loss did not improve from 1.07832
Epoch 430/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0334 - acc: 0.5452 - val_loss: 1.1011 - val_acc: 0.5221

Epoch 00430: val_loss did not improve from 1.07832
Epoch 431/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0418 - acc: 0.5379 - val_loss: 1.0840 - val_acc: 0.5421

Epoch 00431: val_loss did not improve from 1.07832
Epoch 432/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0385 - acc: 0.5472 - val_loss: 1.1210 - val_acc: 0.5149

Epoch 00432: val_loss did not improve from 1.07832
Epoch 433/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0406 - acc: 0.5498 - val_loss: 1.0826 - val_acc: 0.5390

Epoch 00433: val_loss did not improve from 1.07832
Epoch 434/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0369 - acc: 0.5472 - val_loss: 1.1327 - val_acc: 0.5221

Epoch 00434: val_loss did not improve from 1.07832
Epoch 435/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0394 - acc: 0.5494 - val_loss: 1.0800 - val_acc: 0.5400

Epoch 00435: val_loss did not improve from 1.07832
Epoch 436/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0249 - acc: 0.5560 - val_loss: 1.0801 - val_acc: 0.5405

Epoch 00436: val_loss did not improve from 1.07832
Epoch 437/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0248 - acc: 0.5558 - val_loss: 1.0792 - val_acc: 0.5369

Epoch 00437: val_loss did not improve from 1.07832
Epoch 438/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5558 - val_loss: 1.0790 - val_acc: 0.5344

Epoch 00438: val_loss did not improve from 1.07832
Epoch 439/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0234 - acc: 0.5584 - val_loss: 1.0831 - val_acc: 0.5379

Epoch 00439: val_loss did not improve from 1.07832
Epoch 440/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0228 - acc: 0.5566 - val_loss: 1.1039 - val_acc: 0.5277

Epoch 00440: val_loss did not improve from 1.07832
Epoch 441/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0284 - acc: 0.5520 - val_loss: 1.0827 - val_acc: 0.5344

Epoch 00441: val_loss did not improve from 1.07832
Epoch 442/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0254 - acc: 0.5577 - val_loss: 1.0812 - val_acc: 0.5354

Epoch 00442: val_loss did not improve from 1.07832
Epoch 443/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0261 - acc: 0.5584 - val_loss: 1.0764 - val_acc: 0.5410

Epoch 00443: val_loss improved from 1.07832 to 1.07636, saving model to model3/443-1.0764.hdf5
Epoch 444/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5531 - val_loss: 1.1010 - val_acc: 0.5190

Epoch 00444: val_loss did not improve from 1.07636
Epoch 445/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0302 - acc: 0.5533 - val_loss: 1.0800 - val_acc: 0.5421

Epoch 00445: val_loss did not improve from 1.07636
Epoch 446/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0239 - acc: 0.5544 - val_loss: 1.0911 - val_acc: 0.5328

Epoch 00446: val_loss did not improve from 1.07636
Epoch 447/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0331 - acc: 0.5494 - val_loss: 1.0956 - val_acc: 0.5262

Epoch 00447: val_loss did not improve from 1.07636
Epoch 448/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0368 - acc: 0.5481 - val_loss: 1.0861 - val_acc: 0.5323

Epoch 00448: val_loss did not improve from 1.07636
Epoch 449/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0265 - acc: 0.5540 - val_loss: 1.0813 - val_acc: 0.5349

Epoch 00449: val_loss did not improve from 1.07636
Epoch 450/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0247 - acc: 0.5540 - val_loss: 1.0887 - val_acc: 0.5318

Epoch 00450: val_loss did not improve from 1.07636
Epoch 451/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0291 - acc: 0.5540 - val_loss: 1.0797 - val_acc: 0.5451

Epoch 00451: val_loss did not improve from 1.07636
Epoch 452/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0265 - acc: 0.5531 - val_loss: 1.0792 - val_acc: 0.5395

Epoch 00452: val_loss did not improve from 1.07636
Epoch 453/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0246 - acc: 0.5558 - val_loss: 1.0972 - val_acc: 0.5190

Epoch 00453: val_loss did not improve from 1.07636
Epoch 454/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0337 - acc: 0.5492 - val_loss: 1.0873 - val_acc: 0.5395

Epoch 00454: val_loss did not improve from 1.07636
Epoch 455/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0377 - acc: 0.5492 - val_loss: 1.0776 - val_acc: 0.5410

Epoch 00455: val_loss did not improve from 1.07636
Epoch 456/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0241 - acc: 0.5569 - val_loss: 1.1104 - val_acc: 0.5267

Epoch 00456: val_loss did not improve from 1.07636
Epoch 457/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0433 - acc: 0.558 - 0s 3us/step - loss: 1.0314 - acc: 0.5470 - val_loss: 1.0858 - val_acc: 0.5277

Epoch 00457: val_loss did not improve from 1.07636
Epoch 458/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0243 - acc: 0.5503 - val_loss: 1.0835 - val_acc: 0.5374

Epoch 00458: val_loss did not improve from 1.07636
Epoch 459/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0270 - acc: 0.5494 - val_loss: 1.0757 - val_acc: 0.5364

Epoch 00459: val_loss improved from 1.07636 to 1.07574, saving model to model3/459-1.0757.hdf5
Epoch 460/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0244 - acc: 0.5558 - val_loss: 1.1300 - val_acc: 0.5236

Epoch 00460: val_loss did not improve from 1.07574
Epoch 461/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0378 - acc: 0.5505 - val_loss: 1.0861 - val_acc: 0.5282

Epoch 00461: val_loss did not improve from 1.07574
Epoch 462/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0400 - acc: 0.5443 - val_loss: 1.0830 - val_acc: 0.5369

Epoch 00462: val_loss did not improve from 1.07574
Epoch 463/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0256 - acc: 0.5584 - val_loss: 1.0783 - val_acc: 0.5436

Epoch 00463: val_loss did not improve from 1.07574
Epoch 464/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0233 - acc: 0.5529 - val_loss: 1.0879 - val_acc: 0.5313

Epoch 00464: val_loss did not improve from 1.07574
Epoch 465/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0336 - acc: 0.5465 - val_loss: 1.0800 - val_acc: 0.5364

Epoch 00465: val_loss did not improve from 1.07574
Epoch 466/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0254 - acc: 0.5485 - val_loss: 1.0803 - val_acc: 0.5333

Epoch 00466: val_loss did not improve from 1.07574
Epoch 467/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0205 - acc: 0.5586 - val_loss: 1.0787 - val_acc: 0.5436

Epoch 00467: val_loss did not improve from 1.07574
Epoch 468/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0276 - acc: 0.5498 - val_loss: 1.0846 - val_acc: 0.5313

Epoch 00468: val_loss did not improve from 1.07574
Epoch 469/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0307 - acc: 0.5540 - val_loss: 1.0859 - val_acc: 0.5379

Epoch 00469: val_loss did not improve from 1.07574
Epoch 470/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0254 - acc: 0.5544 - val_loss: 1.0873 - val_acc: 0.5303

Epoch 00470: val_loss did not improve from 1.07574
Epoch 471/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0214 - acc: 0.5623 - val_loss: 1.0765 - val_acc: 0.5390

Epoch 00471: val_loss did not improve from 1.07574
Epoch 472/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0217 - acc: 0.5610 - val_loss: 1.0756 - val_acc: 0.5415

Epoch 00472: val_loss improved from 1.07574 to 1.07558, saving model to model3/472-1.0756.hdf5
Epoch 473/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0219 - acc: 0.5564 - val_loss: 1.0777 - val_acc: 0.5338

Epoch 00473: val_loss did not improve from 1.07558
Epoch 474/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0208 - acc: 0.5619 - val_loss: 1.0808 - val_acc: 0.5374

Epoch 00474: val_loss did not improve from 1.07558
Epoch 475/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0226 - acc: 0.5623 - val_loss: 1.0967 - val_acc: 0.5262

Epoch 00475: val_loss did not improve from 1.07558
Epoch 476/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0275 - acc: 0.5500 - val_loss: 1.0866 - val_acc: 0.5369

Epoch 00476: val_loss did not improve from 1.07558
Epoch 477/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0320 - acc: 0.5474 - val_loss: 1.0897 - val_acc: 0.5354

Epoch 00477: val_loss did not improve from 1.07558
Epoch 478/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0348 - acc: 0.5441 - val_loss: 1.1039 - val_acc: 0.5323

Epoch 00478: val_loss did not improve from 1.07558
Epoch 479/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0368 - acc: 0.5494 - val_loss: 1.0911 - val_acc: 0.5359

Epoch 00479: val_loss did not improve from 1.07558
Epoch 480/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0249 - acc: 0.5604 - val_loss: 1.0730 - val_acc: 0.5400

Epoch 00480: val_loss improved from 1.07558 to 1.07297, saving model to model3/480-1.0730.hdf5
Epoch 481/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0263 - acc: 0.5586 - val_loss: 1.0758 - val_acc: 0.5374

Epoch 00481: val_loss did not improve from 1.07297
Epoch 482/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0210 - acc: 0.5628 - val_loss: 1.0877 - val_acc: 0.5395

Epoch 00482: val_loss did not improve from 1.07297
Epoch 483/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5527 - val_loss: 1.0806 - val_acc: 0.5467

Epoch 00483: val_loss did not improve from 1.07297
Epoch 484/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0221 - acc: 0.5588 - val_loss: 1.1205 - val_acc: 0.5251

Epoch 00484: val_loss did not improve from 1.07297
Epoch 485/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0340 - acc: 0.5496 - val_loss: 1.1028 - val_acc: 0.5282

Epoch 00485: val_loss did not improve from 1.07297
Epoch 486/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0312 - acc: 0.5489 - val_loss: 1.0772 - val_acc: 0.5374

Epoch 00486: val_loss did not improve from 1.07297
Epoch 487/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0209 - acc: 0.5590 - val_loss: 1.0758 - val_acc: 0.5426

Epoch 00487: val_loss did not improve from 1.07297
Epoch 488/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0241 - acc: 0.5507 - val_loss: 1.0874 - val_acc: 0.5456

Epoch 00488: val_loss did not improve from 1.07297
Epoch 489/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0227 - acc: 0.5547 - val_loss: 1.0897 - val_acc: 0.5344

Epoch 00489: val_loss did not improve from 1.07297
Epoch 490/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0245 - acc: 0.5544 - val_loss: 1.0955 - val_acc: 0.5169

Epoch 00490: val_loss did not improve from 1.07297
Epoch 491/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0342 - acc: 0.5478 - val_loss: 1.0742 - val_acc: 0.5395

Epoch 00491: val_loss did not improve from 1.07297
Epoch 492/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0312 - acc: 0.5553 - val_loss: 1.0848 - val_acc: 0.5405

Epoch 00492: val_loss did not improve from 1.07297
Epoch 493/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0213 - acc: 0.5538 - val_loss: 1.0745 - val_acc: 0.5415

Epoch 00493: val_loss did not improve from 1.07297
Epoch 494/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0209 - acc: 0.5560 - val_loss: 1.0745 - val_acc: 0.5374

Epoch 00494: val_loss did not improve from 1.07297
Epoch 495/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0199 - acc: 0.5617 - val_loss: 1.0790 - val_acc: 0.5359

Epoch 00495: val_loss did not improve from 1.07297
Epoch 496/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0191 - acc: 0.5639 - val_loss: 1.0754 - val_acc: 0.5359

Epoch 00496: val_loss did not improve from 1.07297
Epoch 497/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0292 - acc: 0.5533 - val_loss: 1.0748 - val_acc: 0.5436

Epoch 00497: val_loss did not improve from 1.07297
Epoch 498/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0279 - acc: 0.5566 - val_loss: 1.1154 - val_acc: 0.5369

Epoch 00498: val_loss did not improve from 1.07297
Epoch 499/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0315 - acc: 0.5527 - val_loss: 1.0777 - val_acc: 0.5338

Epoch 00499: val_loss did not improve from 1.07297
Epoch 500/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0282 - acc: 0.5560 - val_loss: 1.0842 - val_acc: 0.5297

Epoch 00500: val_loss did not improve from 1.07297
Epoch 501/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0250 - acc: 0.5507 - val_loss: 1.0952 - val_acc: 0.5390

Epoch 00501: val_loss did not improve from 1.07297
Epoch 502/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0244 - acc: 0.5558 - val_loss: 1.0775 - val_acc: 0.5390

Epoch 00502: val_loss did not improve from 1.07297
Epoch 503/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0252 - acc: 0.5555 - val_loss: 1.0784 - val_acc: 0.5395

Epoch 00503: val_loss did not improve from 1.07297
Epoch 504/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5544 - val_loss: 1.0778 - val_acc: 0.5359

Epoch 00504: val_loss did not improve from 1.07297
Epoch 505/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0185 - acc: 0.5525 - val_loss: 1.0736 - val_acc: 0.5364

Epoch 00505: val_loss did not improve from 1.07297
Epoch 506/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0190 - acc: 0.5590 - val_loss: 1.0794 - val_acc: 0.5318

Epoch 00506: val_loss did not improve from 1.07297
Epoch 507/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0211 - acc: 0.5604 - val_loss: 1.0757 - val_acc: 0.5421

Epoch 00507: val_loss did not improve from 1.07297
Epoch 508/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0176 - acc: 0.5604 - val_loss: 1.0752 - val_acc: 0.5379

Epoch 00508: val_loss did not improve from 1.07297
Epoch 509/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0162 - acc: 0.5630 - val_loss: 1.0745 - val_acc: 0.5390

Epoch 00509: val_loss did not improve from 1.07297
Epoch 510/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0199 - acc: 0.5536 - val_loss: 1.0907 - val_acc: 0.5195

Epoch 00510: val_loss did not improve from 1.07297
Epoch 511/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0292 - acc: 0.5465 - val_loss: 1.0792 - val_acc: 0.5292

Epoch 00511: val_loss did not improve from 1.07297
Epoch 512/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0244 - acc: 0.5531 - val_loss: 1.0873 - val_acc: 0.5313

Epoch 00512: val_loss did not improve from 1.07297
Epoch 513/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0222 - acc: 0.5573 - val_loss: 1.0824 - val_acc: 0.5374

Epoch 00513: val_loss did not improve from 1.07297
Epoch 514/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0188 - acc: 0.5582 - val_loss: 1.0839 - val_acc: 0.5359

Epoch 00514: val_loss did not improve from 1.07297
Epoch 515/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0329 - acc: 0.5487 - val_loss: 1.0849 - val_acc: 0.5313

Epoch 00515: val_loss did not improve from 1.07297
Epoch 516/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0298 - acc: 0.5529 - val_loss: 1.0771 - val_acc: 0.5379

Epoch 00516: val_loss did not improve from 1.07297
Epoch 517/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0228 - acc: 0.5601 - val_loss: 1.0809 - val_acc: 0.5338

Epoch 00517: val_loss did not improve from 1.07297
Epoch 518/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0192 - acc: 0.5562 - val_loss: 1.0854 - val_acc: 0.5246

Epoch 00518: val_loss did not improve from 1.07297
Epoch 519/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0369 - acc: 0.5465 - val_loss: 1.0906 - val_acc: 0.5277

Epoch 00519: val_loss did not improve from 1.07297
Epoch 520/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0260 - acc: 0.5498 - val_loss: 1.1043 - val_acc: 0.5262

Epoch 00520: val_loss did not improve from 1.07297
Epoch 521/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0293 - acc: 0.5525 - val_loss: 1.0784 - val_acc: 0.5338

Epoch 00521: val_loss did not improve from 1.07297
Epoch 522/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0332 - acc: 0.5544 - val_loss: 1.0821 - val_acc: 0.5323

Epoch 00522: val_loss did not improve from 1.07297
Epoch 523/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0308 - acc: 0.5481 - val_loss: 1.0705 - val_acc: 0.5472

Epoch 00523: val_loss improved from 1.07297 to 1.07054, saving model to model3/523-1.0705.hdf5
Epoch 524/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0233 - acc: 0.5483 - val_loss: 1.0837 - val_acc: 0.5303

Epoch 00524: val_loss did not improve from 1.07054
Epoch 525/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0262 - acc: 0.5553 - val_loss: 1.0788 - val_acc: 0.5395

Epoch 00525: val_loss did not improve from 1.07054
Epoch 526/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0232 - acc: 0.5582 - val_loss: 1.0806 - val_acc: 0.5344

Epoch 00526: val_loss did not improve from 1.07054
Epoch 527/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0269 - acc: 0.5487 - val_loss: 1.1388 - val_acc: 0.5144

Epoch 00527: val_loss did not improve from 1.07054
Epoch 528/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0472 - acc: 0.5388 - val_loss: 1.1458 - val_acc: 0.5036

Epoch 00528: val_loss did not improve from 1.07054
Epoch 529/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0409 - acc: 0.5478 - val_loss: 1.0817 - val_acc: 0.5308

Epoch 00529: val_loss did not improve from 1.07054
Epoch 530/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0236 - acc: 0.5522 - val_loss: 1.0829 - val_acc: 0.5267

Epoch 00530: val_loss did not improve from 1.07054
Epoch 531/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0278 - acc: 0.5454 - val_loss: 1.0824 - val_acc: 0.5338

Epoch 00531: val_loss did not improve from 1.07054
Epoch 532/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0213 - acc: 0.5555 - val_loss: 1.0756 - val_acc: 0.5369

Epoch 00532: val_loss did not improve from 1.07054
Epoch 533/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0198 - acc: 0.5619 - val_loss: 1.0886 - val_acc: 0.5287

Epoch 00533: val_loss did not improve from 1.07054
Epoch 534/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0240 - acc: 0.5503 - val_loss: 1.1446 - val_acc: 0.5103

Epoch 00534: val_loss did not improve from 1.07054
Epoch 535/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0419 - acc: 0.5439 - val_loss: 1.0757 - val_acc: 0.5338

Epoch 00535: val_loss did not improve from 1.07054
Epoch 536/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0281 - acc: 0.5542 - val_loss: 1.0798 - val_acc: 0.5303

Epoch 00536: val_loss did not improve from 1.07054
Epoch 537/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0327 - acc: 0.5500 - val_loss: 1.0733 - val_acc: 0.5369

Epoch 00537: val_loss did not improve from 1.07054
Epoch 538/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5590 - val_loss: 1.0744 - val_acc: 0.5338

Epoch 00538: val_loss did not improve from 1.07054
Epoch 539/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0225 - acc: 0.5522 - val_loss: 1.0740 - val_acc: 0.5390

Epoch 00539: val_loss did not improve from 1.07054
Epoch 540/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0193 - acc: 0.5584 - val_loss: 1.0770 - val_acc: 0.5390

Epoch 00540: val_loss did not improve from 1.07054
Epoch 541/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0257 - acc: 0.5465 - val_loss: 1.0766 - val_acc: 0.5379

Epoch 00541: val_loss did not improve from 1.07054
Epoch 542/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0241 - acc: 0.5560 - val_loss: 1.0773 - val_acc: 0.5349

Epoch 00542: val_loss did not improve from 1.07054
Epoch 543/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0193 - acc: 0.5571 - val_loss: 1.0742 - val_acc: 0.5436

Epoch 00543: val_loss did not improve from 1.07054
Epoch 544/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0223 - acc: 0.5514 - val_loss: 1.0781 - val_acc: 0.5431

Epoch 00544: val_loss did not improve from 1.07054
Epoch 545/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0181 - acc: 0.5604 - val_loss: 1.0756 - val_acc: 0.5308

Epoch 00545: val_loss did not improve from 1.07054
Epoch 546/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0180 - acc: 0.5558 - val_loss: 1.0790 - val_acc: 0.5426

Epoch 00546: val_loss did not improve from 1.07054
Epoch 547/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0233 - acc: 0.5549 - val_loss: 1.0818 - val_acc: 0.5282

Epoch 00547: val_loss did not improve from 1.07054
Epoch 548/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0254 - acc: 0.5516 - val_loss: 1.0870 - val_acc: 0.5410

Epoch 00548: val_loss did not improve from 1.07054
Epoch 549/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0265 - acc: 0.5571 - val_loss: 1.0763 - val_acc: 0.5369

Epoch 00549: val_loss did not improve from 1.07054
Epoch 550/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0226 - acc: 0.5573 - val_loss: 1.0746 - val_acc: 0.5369

Epoch 00550: val_loss did not improve from 1.07054
Epoch 551/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0202 - acc: 0.5540 - val_loss: 1.0726 - val_acc: 0.5426

Epoch 00551: val_loss did not improve from 1.07054
Epoch 552/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0150 - acc: 0.5577 - val_loss: 1.0717 - val_acc: 0.5410

Epoch 00552: val_loss did not improve from 1.07054
Epoch 553/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0169 - acc: 0.5564 - val_loss: 1.0754 - val_acc: 0.5333

Epoch 00553: val_loss did not improve from 1.07054
Epoch 554/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0184 - acc: 0.5544 - val_loss: 1.0787 - val_acc: 0.5400

Epoch 00554: val_loss did not improve from 1.07054
Epoch 555/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0166 - acc: 0.5577 - val_loss: 1.0793 - val_acc: 0.5338

Epoch 00555: val_loss did not improve from 1.07054
Epoch 556/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0207 - acc: 0.5514 - val_loss: 1.0917 - val_acc: 0.5303

Epoch 00556: val_loss did not improve from 1.07054
Epoch 557/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0205 - acc: 0.5630 - val_loss: 1.0794 - val_acc: 0.5344

Epoch 00557: val_loss did not improve from 1.07054
Epoch 558/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0261 - acc: 0.5536 - val_loss: 1.0705 - val_acc: 0.5400

Epoch 00558: val_loss improved from 1.07054 to 1.07054, saving model to model3/558-1.0705.hdf5
Epoch 559/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0235 - acc: 0.5580 - val_loss: 1.0964 - val_acc: 0.5441

Epoch 00559: val_loss did not improve from 1.07054
Epoch 560/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0221 - acc: 0.5584 - val_loss: 1.0727 - val_acc: 0.5395

Epoch 00560: val_loss did not improve from 1.07054
Epoch 561/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5564 - val_loss: 1.0708 - val_acc: 0.5410

Epoch 00561: val_loss did not improve from 1.07054
Epoch 562/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0182 - acc: 0.5580 - val_loss: 1.1049 - val_acc: 0.5313

Epoch 00562: val_loss did not improve from 1.07054
Epoch 563/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0215 - acc: 0.5584 - val_loss: 1.0746 - val_acc: 0.5390

Epoch 00563: val_loss did not improve from 1.07054
Epoch 564/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0173 - acc: 0.5590 - val_loss: 1.0735 - val_acc: 0.5405

Epoch 00564: val_loss did not improve from 1.07054
Epoch 565/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0168 - acc: 0.5588 - val_loss: 1.1207 - val_acc: 0.5128

Epoch 00565: val_loss did not improve from 1.07054
Epoch 566/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0356 - acc: 0.5494 - val_loss: 1.0941 - val_acc: 0.5395

Epoch 00566: val_loss did not improve from 1.07054
Epoch 567/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0210 - acc: 0.5577 - val_loss: 1.0757 - val_acc: 0.5364

Epoch 00567: val_loss did not improve from 1.07054
Epoch 568/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0180 - acc: 0.5601 - val_loss: 1.0804 - val_acc: 0.5236

Epoch 00568: val_loss did not improve from 1.07054
Epoch 569/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0256 - acc: 0.5525 - val_loss: 1.0807 - val_acc: 0.5385

Epoch 00569: val_loss did not improve from 1.07054
Epoch 570/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0272 - acc: 0.5492 - val_loss: 1.0863 - val_acc: 0.5246

Epoch 00570: val_loss did not improve from 1.07054
Epoch 571/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0173 - acc: 0.5555 - val_loss: 1.0759 - val_acc: 0.5369

Epoch 00571: val_loss did not improve from 1.07054
Epoch 572/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0180 - acc: 0.5558 - val_loss: 1.0747 - val_acc: 0.5421

Epoch 00572: val_loss did not improve from 1.07054
Epoch 573/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0170 - acc: 0.5544 - val_loss: 1.0749 - val_acc: 0.5400

Epoch 00573: val_loss did not improve from 1.07054
Epoch 574/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0183 - acc: 0.5582 - val_loss: 1.0744 - val_acc: 0.5349

Epoch 00574: val_loss did not improve from 1.07054
Epoch 575/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0170 - acc: 0.5593 - val_loss: 1.0780 - val_acc: 0.5338

Epoch 00575: val_loss did not improve from 1.07054
Epoch 576/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0249 - acc: 0.5542 - val_loss: 1.0790 - val_acc: 0.5221

Epoch 00576: val_loss did not improve from 1.07054
Epoch 577/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0249 - acc: 0.5503 - val_loss: 1.0731 - val_acc: 0.5431

Epoch 00577: val_loss did not improve from 1.07054
Epoch 578/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0215 - acc: 0.5560 - val_loss: 1.0712 - val_acc: 0.5379

Epoch 00578: val_loss did not improve from 1.07054
Epoch 579/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0206 - acc: 0.5483 - val_loss: 1.0716 - val_acc: 0.5436

Epoch 00579: val_loss did not improve from 1.07054
Epoch 580/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0175 - acc: 0.5597 - val_loss: 1.0689 - val_acc: 0.5426

Epoch 00580: val_loss improved from 1.07054 to 1.06887, saving model to model3/580-1.0689.hdf5
Epoch 581/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0135 - acc: 0.5593 - val_loss: 1.0704 - val_acc: 0.5431

Epoch 00581: val_loss did not improve from 1.06887
Epoch 582/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0148 - acc: 0.5586 - val_loss: 1.0735 - val_acc: 0.5451

Epoch 00582: val_loss did not improve from 1.06887
Epoch 583/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5628 - val_loss: 1.0697 - val_acc: 0.5467

Epoch 00583: val_loss did not improve from 1.06887
Epoch 584/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0139 - acc: 0.5564 - val_loss: 1.0783 - val_acc: 0.5395

Epoch 00584: val_loss did not improve from 1.06887
Epoch 585/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0189 - acc: 0.5588 - val_loss: 1.0707 - val_acc: 0.5349

Epoch 00585: val_loss did not improve from 1.06887
Epoch 586/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0167 - acc: 0.5601 - val_loss: 1.0742 - val_acc: 0.5446

Epoch 00586: val_loss did not improve from 1.06887
Epoch 587/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0145 - acc: 0.5639 - val_loss: 1.0733 - val_acc: 0.5513

Epoch 00587: val_loss did not improve from 1.06887
Epoch 588/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0175 - acc: 0.5586 - val_loss: 1.0828 - val_acc: 0.5415

Epoch 00588: val_loss did not improve from 1.06887
Epoch 589/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0194 - acc: 0.5623 - val_loss: 1.0730 - val_acc: 0.5400

Epoch 00589: val_loss did not improve from 1.06887
Epoch 590/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5544 - val_loss: 1.0718 - val_acc: 0.5446

Epoch 00590: val_loss did not improve from 1.06887
Epoch 591/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0137 - acc: 0.5595 - val_loss: 1.0740 - val_acc: 0.5354

Epoch 00591: val_loss did not improve from 1.06887
Epoch 592/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0217 - acc: 0.5590 - val_loss: 1.0743 - val_acc: 0.5354

Epoch 00592: val_loss did not improve from 1.06887
Epoch 593/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0194 - acc: 0.5478 - val_loss: 1.1498 - val_acc: 0.5041

Epoch 00593: val_loss did not improve from 1.06887
Epoch 594/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0410 - acc: 0.5406 - val_loss: 1.0695 - val_acc: 0.5369

Epoch 00594: val_loss did not improve from 1.06887
Epoch 595/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0372 - acc: 0.5461 - val_loss: 1.0860 - val_acc: 0.5313

Epoch 00595: val_loss did not improve from 1.06887
Epoch 596/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0199 - acc: 0.5562 - val_loss: 1.0661 - val_acc: 0.5436

Epoch 00596: val_loss improved from 1.06887 to 1.06611, saving model to model3/596-1.0661.hdf5
Epoch 597/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0174 - acc: 0.5553 - val_loss: 1.0775 - val_acc: 0.5374

Epoch 00597: val_loss did not improve from 1.06611
Epoch 598/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0170 - acc: 0.5590 - val_loss: 1.1146 - val_acc: 0.5133

Epoch 00598: val_loss did not improve from 1.06611
Epoch 599/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0226 - acc: 0.5500 - val_loss: 1.0704 - val_acc: 0.5477

Epoch 00599: val_loss did not improve from 1.06611
Epoch 600/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0149 - acc: 0.5582 - val_loss: 1.0732 - val_acc: 0.5385

Epoch 00600: val_loss did not improve from 1.06611
Epoch 601/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5597 - val_loss: 1.0710 - val_acc: 0.5477

Epoch 00601: val_loss did not improve from 1.06611
Epoch 602/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0157 - acc: 0.5571 - val_loss: 1.0740 - val_acc: 0.5400

Epoch 00602: val_loss did not improve from 1.06611
Epoch 603/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0146 - acc: 0.5599 - val_loss: 1.0884 - val_acc: 0.5303

Epoch 00603: val_loss did not improve from 1.06611
Epoch 604/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0307 - acc: 0.5461 - val_loss: 1.0708 - val_acc: 0.5379

Epoch 00604: val_loss did not improve from 1.06611
Epoch 605/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0212 - acc: 0.5571 - val_loss: 1.0725 - val_acc: 0.5395

Epoch 00605: val_loss did not improve from 1.06611
Epoch 606/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0204 - acc: 0.5529 - val_loss: 1.0798 - val_acc: 0.5323

Epoch 00606: val_loss did not improve from 1.06611
Epoch 607/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0240 - acc: 0.5525 - val_loss: 1.0750 - val_acc: 0.5405

Epoch 00607: val_loss did not improve from 1.06611
Epoch 608/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0182 - acc: 0.5540 - val_loss: 1.0797 - val_acc: 0.5359

Epoch 00608: val_loss did not improve from 1.06611
Epoch 609/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0223 - acc: 0.5551 - val_loss: 1.0822 - val_acc: 0.5313

Epoch 00609: val_loss did not improve from 1.06611
Epoch 610/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0177 - acc: 0.5571 - val_loss: 1.0698 - val_acc: 0.5446

Epoch 00610: val_loss did not improve from 1.06611
Epoch 611/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0154 - acc: 0.5569 - val_loss: 1.0700 - val_acc: 0.5374

Epoch 00611: val_loss did not improve from 1.06611
Epoch 612/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0135 - acc: 0.5615 - val_loss: 1.0816 - val_acc: 0.5405

Epoch 00612: val_loss did not improve from 1.06611
Epoch 613/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0183 - acc: 0.5564 - val_loss: 1.0773 - val_acc: 0.5349

Epoch 00613: val_loss did not improve from 1.06611
Epoch 614/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0170 - acc: 0.5518 - val_loss: 1.0724 - val_acc: 0.5436

Epoch 00614: val_loss did not improve from 1.06611
Epoch 615/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0213 - acc: 0.5549 - val_loss: 1.0873 - val_acc: 0.5292

Epoch 00615: val_loss did not improve from 1.06611
Epoch 616/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0178 - acc: 0.5494 - val_loss: 1.0668 - val_acc: 0.5518

Epoch 00616: val_loss did not improve from 1.06611
Epoch 617/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0133 - acc: 0.5542 - val_loss: 1.0956 - val_acc: 0.5318

Epoch 00617: val_loss did not improve from 1.06611
Epoch 618/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0354 - acc: 0.5406 - val_loss: 1.0824 - val_acc: 0.5338

Epoch 00618: val_loss did not improve from 1.06611
Epoch 619/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0365 - acc: 0.5388 - val_loss: 1.0700 - val_acc: 0.5431

Epoch 00619: val_loss did not improve from 1.06611
Epoch 620/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0167 - acc: 0.5544 - val_loss: 1.0707 - val_acc: 0.5400

Epoch 00620: val_loss did not improve from 1.06611
Epoch 621/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0194 - acc: 0.5538 - val_loss: 1.0725 - val_acc: 0.5364

Epoch 00621: val_loss did not improve from 1.06611
Epoch 622/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0211 - acc: 0.5586 - val_loss: 1.0823 - val_acc: 0.5405

Epoch 00622: val_loss did not improve from 1.06611
Epoch 623/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0215 - acc: 0.5575 - val_loss: 1.0699 - val_acc: 0.5395

Epoch 00623: val_loss did not improve from 1.06611
Epoch 624/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0147 - acc: 0.5595 - val_loss: 1.0879 - val_acc: 0.5379

Epoch 00624: val_loss did not improve from 1.06611
Epoch 625/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0179 - acc: 0.5597 - val_loss: 1.0815 - val_acc: 0.5364

Epoch 00625: val_loss did not improve from 1.06611
Epoch 626/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0170 - acc: 0.5538 - val_loss: 1.0945 - val_acc: 0.5241

Epoch 00626: val_loss did not improve from 1.06611
Epoch 627/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0325 - acc: 0.5443 - val_loss: 1.0941 - val_acc: 0.5256

Epoch 00627: val_loss did not improve from 1.06611
Epoch 628/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0241 - acc: 0.5536 - val_loss: 1.0942 - val_acc: 0.5282

Epoch 00628: val_loss did not improve from 1.06611
Epoch 629/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0426 - acc: 0.5459 - val_loss: 1.1049 - val_acc: 0.5159

Epoch 00629: val_loss did not improve from 1.06611
Epoch 630/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0295 - acc: 0.5481 - val_loss: 1.0741 - val_acc: 0.5344

Epoch 00630: val_loss did not improve from 1.06611
Epoch 631/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0193 - acc: 0.5516 - val_loss: 1.0679 - val_acc: 0.5462

Epoch 00631: val_loss did not improve from 1.06611
Epoch 632/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0129 - acc: 0.5610 - val_loss: 1.0723 - val_acc: 0.5354

Epoch 00632: val_loss did not improve from 1.06611
Epoch 633/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0135 - acc: 0.5588 - val_loss: 1.0757 - val_acc: 0.5410

Epoch 00633: val_loss did not improve from 1.06611
Epoch 634/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0146 - acc: 0.5615 - val_loss: 1.0876 - val_acc: 0.5344

Epoch 00634: val_loss did not improve from 1.06611
Epoch 635/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0198 - acc: 0.5582 - val_loss: 1.0722 - val_acc: 0.5482

Epoch 00635: val_loss did not improve from 1.06611
Epoch 636/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0218 - acc: 0.5536 - val_loss: 1.0792 - val_acc: 0.5287

Epoch 00636: val_loss did not improve from 1.06611
Epoch 637/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0188 - acc: 0.5560 - val_loss: 1.0804 - val_acc: 0.5385

Epoch 00637: val_loss did not improve from 1.06611
Epoch 638/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0192 - acc: 0.5522 - val_loss: 1.0889 - val_acc: 0.5246

Epoch 00638: val_loss did not improve from 1.06611
Epoch 639/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0156 - acc: 0.5569 - val_loss: 1.0865 - val_acc: 0.5313

Epoch 00639: val_loss did not improve from 1.06611
Epoch 640/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0230 - acc: 0.5485 - val_loss: 1.0708 - val_acc: 0.5426

Epoch 00640: val_loss did not improve from 1.06611
Epoch 641/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0183 - acc: 0.5597 - val_loss: 1.0765 - val_acc: 0.5344

Epoch 00641: val_loss did not improve from 1.06611
Epoch 642/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0143 - acc: 0.5593 - val_loss: 1.0723 - val_acc: 0.5421

Epoch 00642: val_loss did not improve from 1.06611
Epoch 643/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0148 - acc: 0.5586 - val_loss: 1.0808 - val_acc: 0.5267

Epoch 00643: val_loss did not improve from 1.06611
Epoch 644/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0235 - acc: 0.5549 - val_loss: 1.0696 - val_acc: 0.5415

Epoch 00644: val_loss did not improve from 1.06611
Epoch 645/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5577 - val_loss: 1.1059 - val_acc: 0.5349

Epoch 00645: val_loss did not improve from 1.06611
Epoch 646/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0229 - acc: 0.5514 - val_loss: 1.0749 - val_acc: 0.5364

Epoch 00646: val_loss did not improve from 1.06611
Epoch 647/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0202 - acc: 0.5547 - val_loss: 1.0848 - val_acc: 0.5333

Epoch 00647: val_loss did not improve from 1.06611
Epoch 648/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.0281 - acc: 0.5518 - val_loss: 1.0792 - val_acc: 0.5359

Epoch 00648: val_loss did not improve from 1.06611
Epoch 649/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0268 - acc: 0.5412 - val_loss: 1.1188 - val_acc: 0.5287

Epoch 00649: val_loss did not improve from 1.06611
Epoch 650/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0378 - acc: 0.5439 - val_loss: 1.0959 - val_acc: 0.5246

Epoch 00650: val_loss did not improve from 1.06611
Epoch 651/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0183 - acc: 0.5617 - val_loss: 1.0758 - val_acc: 0.5354

Epoch 00651: val_loss did not improve from 1.06611
Epoch 652/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0127 - acc: 0.5566 - val_loss: 1.0687 - val_acc: 0.5508

Epoch 00652: val_loss did not improve from 1.06611
Epoch 653/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0163 - acc: 0.5601 - val_loss: 1.0737 - val_acc: 0.5472

Epoch 00653: val_loss did not improve from 1.06611
Epoch 654/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0172 - acc: 0.5599 - val_loss: 1.0675 - val_acc: 0.5374

Epoch 00654: val_loss did not improve from 1.06611
Epoch 655/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0154 - acc: 0.5560 - val_loss: 1.0861 - val_acc: 0.5297

Epoch 00655: val_loss did not improve from 1.06611
Epoch 656/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0180 - acc: 0.5586 - val_loss: 1.0683 - val_acc: 0.5472

Epoch 00656: val_loss did not improve from 1.06611
Epoch 657/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0185 - acc: 0.5553 - val_loss: 1.0772 - val_acc: 0.5426

Epoch 00657: val_loss did not improve from 1.06611
Epoch 658/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0235 - acc: 0.5562 - val_loss: 1.0674 - val_acc: 0.5508

Epoch 00658: val_loss did not improve from 1.06611
Epoch 659/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0189 - acc: 0.5564 - val_loss: 1.0744 - val_acc: 0.5462

Epoch 00659: val_loss did not improve from 1.06611
Epoch 660/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0141 - acc: 0.5509 - val_loss: 1.0758 - val_acc: 0.5410

Epoch 00660: val_loss did not improve from 1.06611
Epoch 661/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0124 - acc: 0.5597 - val_loss: 1.0659 - val_acc: 0.5446

Epoch 00661: val_loss improved from 1.06611 to 1.06591, saving model to model3/661-1.0659.hdf5
Epoch 662/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0128 - acc: 0.5608 - val_loss: 1.0721 - val_acc: 0.5410

Epoch 00662: val_loss did not improve from 1.06591
Epoch 663/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5610 - val_loss: 1.0890 - val_acc: 0.5436

Epoch 00663: val_loss did not improve from 1.06591
Epoch 664/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0132 - acc: 0.5549 - val_loss: 1.0741 - val_acc: 0.5410

Epoch 00664: val_loss did not improve from 1.06591
Epoch 665/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0463 - acc: 0.508 - 0s 4us/step - loss: 1.0145 - acc: 0.5588 - val_loss: 1.0825 - val_acc: 0.5267

Epoch 00665: val_loss did not improve from 1.06591
Epoch 666/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0161 - acc: 0.5582 - val_loss: 1.0755 - val_acc: 0.5436

Epoch 00666: val_loss did not improve from 1.06591
Epoch 667/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0119 - acc: 0.5606 - val_loss: 1.0779 - val_acc: 0.5313

Epoch 00667: val_loss did not improve from 1.06591
Epoch 668/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0168 - acc: 0.5531 - val_loss: 1.0757 - val_acc: 0.5436

Epoch 00668: val_loss did not improve from 1.06591
Epoch 669/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0119 - acc: 0.5606 - val_loss: 1.0773 - val_acc: 0.5421

Epoch 00669: val_loss did not improve from 1.06591
Epoch 670/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0179 - acc: 0.5540 - val_loss: 1.0752 - val_acc: 0.5446

Epoch 00670: val_loss did not improve from 1.06591
Epoch 671/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0190 - acc: 0.5551 - val_loss: 1.0662 - val_acc: 0.5523

Epoch 00671: val_loss did not improve from 1.06591
Epoch 672/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0098 - acc: 0.5571 - val_loss: 1.0790 - val_acc: 0.5405

Epoch 00672: val_loss did not improve from 1.06591
Epoch 673/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0149 - acc: 0.5566 - val_loss: 1.0873 - val_acc: 0.5333

Epoch 00673: val_loss did not improve from 1.06591
Epoch 674/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0206 - acc: 0.5551 - val_loss: 1.0941 - val_acc: 0.5236

Epoch 00674: val_loss did not improve from 1.06591
Epoch 675/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0489 - acc: 0.5324 - val_loss: 1.0860 - val_acc: 0.5349

Epoch 00675: val_loss did not improve from 1.06591
Epoch 676/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0235 - acc: 0.5551 - val_loss: 1.0676 - val_acc: 0.5462

Epoch 00676: val_loss did not improve from 1.06591
Epoch 677/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0200 - acc: 0.5617 - val_loss: 1.1177 - val_acc: 0.5251

Epoch 00677: val_loss did not improve from 1.06591
Epoch 678/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0355 - acc: 0.5443 - val_loss: 1.0774 - val_acc: 0.5441

Epoch 00678: val_loss did not improve from 1.06591
Epoch 679/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0228 - acc: 0.5571 - val_loss: 1.0772 - val_acc: 0.5400

Epoch 00679: val_loss did not improve from 1.06591
Epoch 680/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0165 - acc: 0.5577 - val_loss: 1.0705 - val_acc: 0.5456

Epoch 00680: val_loss did not improve from 1.06591
Epoch 681/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0127 - acc: 0.5577 - val_loss: 1.0945 - val_acc: 0.5344

Epoch 00681: val_loss did not improve from 1.06591
Epoch 682/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0188 - acc: 0.5584 - val_loss: 1.0724 - val_acc: 0.5462

Epoch 00682: val_loss did not improve from 1.06591
Epoch 683/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0113 - acc: 0.5580 - val_loss: 1.0692 - val_acc: 0.5390

Epoch 00683: val_loss did not improve from 1.06591
Epoch 684/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0142 - acc: 0.5551 - val_loss: 1.0730 - val_acc: 0.5405

Epoch 00684: val_loss did not improve from 1.06591
Epoch 685/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0108 - acc: 0.5597 - val_loss: 1.0740 - val_acc: 0.5456

Epoch 00685: val_loss did not improve from 1.06591
Epoch 686/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0118 - acc: 0.5654 - val_loss: 1.0962 - val_acc: 0.5241

Epoch 00686: val_loss did not improve from 1.06591
Epoch 687/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0230 - acc: 0.5518 - val_loss: 1.0929 - val_acc: 0.5364

Epoch 00687: val_loss did not improve from 1.06591
Epoch 688/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0162 - acc: 0.5634 - val_loss: 1.0924 - val_acc: 0.5313

Epoch 00688: val_loss did not improve from 1.06591
Epoch 689/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0188 - acc: 0.5553 - val_loss: 1.0880 - val_acc: 0.5333

Epoch 00689: val_loss did not improve from 1.06591
Epoch 690/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0202 - acc: 0.5555 - val_loss: 1.0844 - val_acc: 0.5446

Epoch 00690: val_loss did not improve from 1.06591
Epoch 691/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0165 - acc: 0.5575 - val_loss: 1.0791 - val_acc: 0.5390

Epoch 00691: val_loss did not improve from 1.06591
Epoch 692/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0278 - acc: 0.5505 - val_loss: 1.0836 - val_acc: 0.5354

Epoch 00692: val_loss did not improve from 1.06591
Epoch 693/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0205 - acc: 0.5531 - val_loss: 1.0933 - val_acc: 0.5323

Epoch 00693: val_loss did not improve from 1.06591
Epoch 694/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0248 - acc: 0.5547 - val_loss: 1.1894 - val_acc: 0.4990

Epoch 00694: val_loss did not improve from 1.06591
Epoch 695/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0438 - acc: 0.5412 - val_loss: 1.0748 - val_acc: 0.5333

Epoch 00695: val_loss did not improve from 1.06591
Epoch 696/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0372 - acc: 0.5498 - val_loss: 1.0785 - val_acc: 0.5323

Epoch 00696: val_loss did not improve from 1.06591
Epoch 697/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0559 - acc: 0.5313 - val_loss: 1.0737 - val_acc: 0.5431

Epoch 00697: val_loss did not improve from 1.06591
Epoch 698/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0206 - acc: 0.5533 - val_loss: 1.0705 - val_acc: 0.5426

Epoch 00698: val_loss did not improve from 1.06591
Epoch 699/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0159 - acc: 0.5593 - val_loss: 1.0674 - val_acc: 0.5497

Epoch 00699: val_loss did not improve from 1.06591
Epoch 700/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0131 - acc: 0.5577 - val_loss: 1.0754 - val_acc: 0.5313

Epoch 00700: val_loss did not improve from 1.06591
Epoch 701/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0160 - acc: 0.5597 - val_loss: 1.0730 - val_acc: 0.5385

Epoch 00701: val_loss did not improve from 1.06591
Epoch 702/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0191 - acc: 0.5571 - val_loss: 1.0736 - val_acc: 0.5456

Epoch 00702: val_loss did not improve from 1.06591
Epoch 703/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0152 - acc: 0.5580 - val_loss: 1.1043 - val_acc: 0.5292

Epoch 00703: val_loss did not improve from 1.06591
Epoch 704/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0255 - acc: 0.5509 - val_loss: 1.0691 - val_acc: 0.5431

Epoch 00704: val_loss did not improve from 1.06591
Epoch 705/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0269 - acc: 0.5496 - val_loss: 1.0805 - val_acc: 0.5400

Epoch 00705: val_loss did not improve from 1.06591
Epoch 706/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0232 - acc: 0.5529 - val_loss: 1.0720 - val_acc: 0.5390

Epoch 00706: val_loss did not improve from 1.06591
Epoch 707/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0119 - acc: 0.5623 - val_loss: 1.0762 - val_acc: 0.5379

Epoch 00707: val_loss did not improve from 1.06591
Epoch 708/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0129 - acc: 0.5597 - val_loss: 1.0722 - val_acc: 0.5421

Epoch 00708: val_loss did not improve from 1.06591
Epoch 709/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0182 - acc: 0.5536 - val_loss: 1.0708 - val_acc: 0.5421

Epoch 00709: val_loss did not improve from 1.06591
Epoch 710/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0192 - acc: 0.5511 - val_loss: 1.0910 - val_acc: 0.5344

Epoch 00710: val_loss did not improve from 1.06591
Epoch 711/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0242 - acc: 0.5527 - val_loss: 1.0773 - val_acc: 0.5405

Epoch 00711: val_loss did not improve from 1.06591
Epoch 712/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0116 - acc: 0.5577 - val_loss: 1.1104 - val_acc: 0.5185

Epoch 00712: val_loss did not improve from 1.06591
Epoch 713/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0231 - acc: 0.5562 - val_loss: 1.0810 - val_acc: 0.5487

Epoch 00713: val_loss did not improve from 1.06591
Epoch 714/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0294 - acc: 0.5500 - val_loss: 1.0736 - val_acc: 0.5523

Epoch 00714: val_loss did not improve from 1.06591
Epoch 715/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0130 - acc: 0.5553 - val_loss: 1.0692 - val_acc: 0.5477

Epoch 00715: val_loss did not improve from 1.06591
Epoch 716/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0129 - acc: 0.5547 - val_loss: 1.0676 - val_acc: 0.5441

Epoch 00716: val_loss did not improve from 1.06591
Epoch 717/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0144 - acc: 0.5588 - val_loss: 1.0809 - val_acc: 0.5354

Epoch 00717: val_loss did not improve from 1.06591
Epoch 718/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0237 - acc: 0.5527 - val_loss: 1.0667 - val_acc: 0.5497

Epoch 00718: val_loss did not improve from 1.06591
Epoch 719/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0107 - acc: 0.5547 - val_loss: 1.0677 - val_acc: 0.5415

Epoch 00719: val_loss did not improve from 1.06591
Epoch 720/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0100 - acc: 0.5606 - val_loss: 1.0692 - val_acc: 0.5441

Epoch 00720: val_loss did not improve from 1.06591
Epoch 721/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0121 - acc: 0.5608 - val_loss: 1.0846 - val_acc: 0.5338

Epoch 00721: val_loss did not improve from 1.06591
Epoch 722/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0164 - acc: 0.5623 - val_loss: 1.0693 - val_acc: 0.5441

Epoch 00722: val_loss did not improve from 1.06591
Epoch 723/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0091 - acc: 0.5623 - val_loss: 1.0785 - val_acc: 0.5400

Epoch 00723: val_loss did not improve from 1.06591
Epoch 724/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0115 - acc: 0.5612 - val_loss: 1.0782 - val_acc: 0.5374

Epoch 00724: val_loss did not improve from 1.06591
Epoch 725/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0233 - acc: 0.5456 - val_loss: 1.0666 - val_acc: 0.5426

Epoch 00725: val_loss did not improve from 1.06591
Epoch 726/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0239 - acc: 0.5476 - val_loss: 1.0715 - val_acc: 0.5421

Epoch 00726: val_loss did not improve from 1.06591
Epoch 727/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0207 - acc: 0.5529 - val_loss: 1.0984 - val_acc: 0.5395

Epoch 00727: val_loss did not improve from 1.06591
Epoch 728/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0202 - acc: 0.5575 - val_loss: 1.0752 - val_acc: 0.5338

Epoch 00728: val_loss did not improve from 1.06591
Epoch 729/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0137 - acc: 0.5562 - val_loss: 1.0708 - val_acc: 0.5374

Epoch 00729: val_loss did not improve from 1.06591
Epoch 730/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0114 - acc: 0.5588 - val_loss: 1.0759 - val_acc: 0.5431

Epoch 00730: val_loss did not improve from 1.06591
Epoch 731/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0159 - acc: 0.5553 - val_loss: 1.0793 - val_acc: 0.5308

Epoch 00731: val_loss did not improve from 1.06591
Epoch 732/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0143 - acc: 0.5558 - val_loss: 1.0983 - val_acc: 0.5395

Epoch 00732: val_loss did not improve from 1.06591
Epoch 733/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0153 - acc: 0.5582 - val_loss: 1.0681 - val_acc: 0.5487

Epoch 00733: val_loss did not improve from 1.06591
Epoch 734/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0091 - acc: 0.5601 - val_loss: 1.0681 - val_acc: 0.5456

Epoch 00734: val_loss did not improve from 1.06591
Epoch 735/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0114 - acc: 0.5619 - val_loss: 1.0752 - val_acc: 0.5354

Epoch 00735: val_loss did not improve from 1.06591
Epoch 736/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0102 - acc: 0.5641 - val_loss: 1.0886 - val_acc: 0.5390

Epoch 00736: val_loss did not improve from 1.06591
Epoch 737/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0138 - acc: 0.5542 - val_loss: 1.0726 - val_acc: 0.5374

Epoch 00737: val_loss did not improve from 1.06591
Epoch 738/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0123 - acc: 0.5582 - val_loss: 1.0726 - val_acc: 0.5400

Epoch 00738: val_loss did not improve from 1.06591
Epoch 739/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0094 - acc: 0.5582 - val_loss: 1.0691 - val_acc: 0.5482

Epoch 00739: val_loss did not improve from 1.06591
Epoch 740/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0111 - acc: 0.5558 - val_loss: 1.0765 - val_acc: 0.5395

Epoch 00740: val_loss did not improve from 1.06591
Epoch 741/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0155 - acc: 0.5514 - val_loss: 1.0842 - val_acc: 0.5405

Epoch 00741: val_loss did not improve from 1.06591
Epoch 742/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0187 - acc: 0.5498 - val_loss: 1.1159 - val_acc: 0.5328

Epoch 00742: val_loss did not improve from 1.06591
Epoch 743/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0249 - acc: 0.5465 - val_loss: 1.0740 - val_acc: 0.5467

Epoch 00743: val_loss did not improve from 1.06591
Epoch 744/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0102 - acc: 0.5586 - val_loss: 1.0759 - val_acc: 0.5456

Epoch 00744: val_loss did not improve from 1.06591
Epoch 745/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0170 - acc: 0.5555 - val_loss: 1.0729 - val_acc: 0.5374

Epoch 00745: val_loss did not improve from 1.06591
Epoch 746/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0180 - acc: 0.5553 - val_loss: 1.0901 - val_acc: 0.5415

Epoch 00746: val_loss did not improve from 1.06591
Epoch 747/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0158 - acc: 0.5536 - val_loss: 1.1273 - val_acc: 0.5210

Epoch 00747: val_loss did not improve from 1.06591
Epoch 748/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0314 - acc: 0.5470 - val_loss: 1.0683 - val_acc: 0.5472

Epoch 00748: val_loss did not improve from 1.06591
Epoch 749/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0311 - acc: 0.5514 - val_loss: 1.0849 - val_acc: 0.5369

Epoch 00749: val_loss did not improve from 1.06591
Epoch 750/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0190 - acc: 0.5507 - val_loss: 1.0714 - val_acc: 0.5379

Epoch 00750: val_loss did not improve from 1.06591
Epoch 751/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0121 - acc: 0.5588 - val_loss: 1.0660 - val_acc: 0.5477

Epoch 00751: val_loss did not improve from 1.06591
Epoch 752/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0094 - acc: 0.5562 - val_loss: 1.0683 - val_acc: 0.5467

Epoch 00752: val_loss did not improve from 1.06591
Epoch 753/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0083 - acc: 0.5582 - val_loss: 1.0713 - val_acc: 0.5421

Epoch 00753: val_loss did not improve from 1.06591
Epoch 754/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0080 - acc: 0.5569 - val_loss: 1.0758 - val_acc: 0.5400

Epoch 00754: val_loss did not improve from 1.06591
Epoch 755/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0210 - acc: 0.5538 - val_loss: 1.0860 - val_acc: 0.5390

Epoch 00755: val_loss did not improve from 1.06591
Epoch 756/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0236 - acc: 0.5454 - val_loss: 1.0715 - val_acc: 0.5462

Epoch 00756: val_loss did not improve from 1.06591
Epoch 757/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0136 - acc: 0.5562 - val_loss: 1.0698 - val_acc: 0.5559

Epoch 00757: val_loss did not improve from 1.06591
Epoch 758/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0148 - acc: 0.5527 - val_loss: 1.0938 - val_acc: 0.5349

Epoch 00758: val_loss did not improve from 1.06591
Epoch 759/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0244 - acc: 0.5571 - val_loss: 1.0852 - val_acc: 0.5349

Epoch 00759: val_loss did not improve from 1.06591
Epoch 760/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0166 - acc: 0.5542 - val_loss: 1.0659 - val_acc: 0.5415

Epoch 00760: val_loss did not improve from 1.06591
Epoch 761/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0080 - acc: 0.5566 - val_loss: 1.0659 - val_acc: 0.5395

Epoch 00761: val_loss improved from 1.06591 to 1.06588, saving model to model3/761-1.0659.hdf5
Epoch 762/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0074 - acc: 0.5566 - val_loss: 1.0664 - val_acc: 0.5405

Epoch 00762: val_loss did not improve from 1.06588
Epoch 763/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0092 - acc: 0.5652 - val_loss: 1.0670 - val_acc: 0.5477

Epoch 00763: val_loss did not improve from 1.06588
Epoch 764/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0125 - acc: 0.5560 - val_loss: 1.0696 - val_acc: 0.5467

Epoch 00764: val_loss did not improve from 1.06588
Epoch 765/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0078 - acc: 0.5630 - val_loss: 1.0738 - val_acc: 0.5379

Epoch 00765: val_loss did not improve from 1.06588
Epoch 766/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0130 - acc: 0.5623 - val_loss: 1.0757 - val_acc: 0.5421

Epoch 00766: val_loss did not improve from 1.06588
Epoch 767/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0129 - acc: 0.5573 - val_loss: 1.0745 - val_acc: 0.5451

Epoch 00767: val_loss did not improve from 1.06588
Epoch 768/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0109 - acc: 0.5584 - val_loss: 1.0765 - val_acc: 0.5451

Epoch 00768: val_loss did not improve from 1.06588
Epoch 769/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0144 - acc: 0.5586 - val_loss: 1.0866 - val_acc: 0.5297

Epoch 00769: val_loss did not improve from 1.06588
Epoch 770/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0321 - acc: 0.5566 - val_loss: 1.0839 - val_acc: 0.5338

Epoch 00770: val_loss did not improve from 1.06588
Epoch 771/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0130 - acc: 0.5623 - val_loss: 1.0728 - val_acc: 0.5441

Epoch 00771: val_loss did not improve from 1.06588
Epoch 772/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0103 - acc: 0.5542 - val_loss: 1.0883 - val_acc: 0.5349

Epoch 00772: val_loss did not improve from 1.06588
Epoch 773/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0137 - acc: 0.5542 - val_loss: 1.1176 - val_acc: 0.5174

Epoch 00773: val_loss did not improve from 1.06588
Epoch 774/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0230 - acc: 0.5509 - val_loss: 1.1043 - val_acc: 0.5354

Epoch 00774: val_loss did not improve from 1.06588
Epoch 775/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0245 - acc: 0.5474 - val_loss: 1.0764 - val_acc: 0.5415

Epoch 00775: val_loss did not improve from 1.06588
Epoch 776/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0134 - acc: 0.5586 - val_loss: 1.0773 - val_acc: 0.5354

Epoch 00776: val_loss did not improve from 1.06588
Epoch 777/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0129 - acc: 0.5564 - val_loss: 1.0735 - val_acc: 0.5523

Epoch 00777: val_loss did not improve from 1.06588
Epoch 778/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0177 - acc: 0.5525 - val_loss: 1.0719 - val_acc: 0.5390

Epoch 00778: val_loss did not improve from 1.06588
Epoch 779/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0112 - acc: 0.5522 - val_loss: 1.1379 - val_acc: 0.5282

Epoch 00779: val_loss did not improve from 1.06588
Epoch 780/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0304 - acc: 0.5432 - val_loss: 1.0965 - val_acc: 0.5210

Epoch 00780: val_loss did not improve from 1.06588
Epoch 781/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0152 - acc: 0.5500 - val_loss: 1.0710 - val_acc: 0.5487

Epoch 00781: val_loss did not improve from 1.06588
Epoch 782/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0075 - acc: 0.5569 - val_loss: 1.1084 - val_acc: 0.5262

Epoch 00782: val_loss did not improve from 1.06588
Epoch 783/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0224 - acc: 0.5505 - val_loss: 1.1092 - val_acc: 0.5185

Epoch 00783: val_loss did not improve from 1.06588
Epoch 784/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0197 - acc: 0.5443 - val_loss: 1.0693 - val_acc: 0.5421

Epoch 00784: val_loss did not improve from 1.06588
Epoch 785/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0279 - acc: 0.5386 - val_loss: 1.0924 - val_acc: 0.5323

Epoch 00785: val_loss did not improve from 1.06588
Epoch 786/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0210 - acc: 0.5584 - val_loss: 1.0684 - val_acc: 0.5451

Epoch 00786: val_loss did not improve from 1.06588
Epoch 787/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0134 - acc: 0.5612 - val_loss: 1.0741 - val_acc: 0.5359

Epoch 00787: val_loss did not improve from 1.06588
Epoch 788/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0087 - acc: 0.5560 - val_loss: 1.0747 - val_acc: 0.5390

Epoch 00788: val_loss did not improve from 1.06588
Epoch 789/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0076 - acc: 0.5621 - val_loss: 1.0696 - val_acc: 0.5426

Epoch 00789: val_loss did not improve from 1.06588
Epoch 790/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0068 - acc: 0.5586 - val_loss: 1.0676 - val_acc: 0.5441

Epoch 00790: val_loss did not improve from 1.06588
Epoch 791/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0098 - acc: 0.5511 - val_loss: 1.0833 - val_acc: 0.5385

Epoch 00791: val_loss did not improve from 1.06588
Epoch 792/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0202 - acc: 0.5503 - val_loss: 1.0679 - val_acc: 0.5482

Epoch 00792: val_loss did not improve from 1.06588
Epoch 793/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0013 - acc: 0.520 - 0s 3us/step - loss: 1.0079 - acc: 0.5538 - val_loss: 1.0697 - val_acc: 0.5462

Epoch 00793: val_loss did not improve from 1.06588
Epoch 794/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0132 - acc: 0.5593 - val_loss: 1.0840 - val_acc: 0.5344

Epoch 00794: val_loss did not improve from 1.06588
Epoch 795/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0204 - acc: 0.5481 - val_loss: 1.1014 - val_acc: 0.5369

Epoch 00795: val_loss did not improve from 1.06588
Epoch 796/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0202 - acc: 0.5509 - val_loss: 1.0711 - val_acc: 0.5538

Epoch 00796: val_loss did not improve from 1.06588
Epoch 797/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0179 - acc: 0.5507 - val_loss: 1.0723 - val_acc: 0.5431

Epoch 00797: val_loss did not improve from 1.06588
Epoch 798/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0138 - acc: 0.5569 - val_loss: 1.0706 - val_acc: 0.5467

Epoch 00798: val_loss did not improve from 1.06588
Epoch 799/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0063 - acc: 0.5650 - val_loss: 1.0801 - val_acc: 0.5323

Epoch 00799: val_loss did not improve from 1.06588
Epoch 800/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0173 - acc: 0.5608 - val_loss: 1.0917 - val_acc: 0.5313

Epoch 00800: val_loss did not improve from 1.06588
Epoch 801/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0119 - acc: 0.5573 - val_loss: 1.0738 - val_acc: 0.5472

Epoch 00801: val_loss did not improve from 1.06588
Epoch 802/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0223 - acc: 0.5560 - val_loss: 1.0756 - val_acc: 0.5400

Epoch 00802: val_loss did not improve from 1.06588
Epoch 803/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0087 - acc: 0.5643 - val_loss: 1.0714 - val_acc: 0.5467

Epoch 00803: val_loss did not improve from 1.06588
Epoch 804/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0072 - acc: 0.5628 - val_loss: 1.0698 - val_acc: 0.5426

Epoch 00804: val_loss did not improve from 1.06588
Epoch 805/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0116 - acc: 0.5577 - val_loss: 1.0693 - val_acc: 0.5544

Epoch 00805: val_loss did not improve from 1.06588
Epoch 806/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0099 - acc: 0.5555 - val_loss: 1.0667 - val_acc: 0.5518

Epoch 00806: val_loss did not improve from 1.06588
Epoch 807/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0085 - acc: 0.5621 - val_loss: 1.0707 - val_acc: 0.5400

Epoch 00807: val_loss did not improve from 1.06588
Epoch 808/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0067 - acc: 0.5582 - val_loss: 1.0688 - val_acc: 0.5456

Epoch 00808: val_loss did not improve from 1.06588
Epoch 809/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0076 - acc: 0.5639 - val_loss: 1.0749 - val_acc: 0.5431

Epoch 00809: val_loss did not improve from 1.06588
Epoch 810/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0069 - acc: 0.5573 - val_loss: 1.0768 - val_acc: 0.5431

Epoch 00810: val_loss did not improve from 1.06588
Epoch 811/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0120 - acc: 0.5630 - val_loss: 1.0744 - val_acc: 0.5421

Epoch 00811: val_loss did not improve from 1.06588
Epoch 812/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0073 - acc: 0.5608 - val_loss: 1.0728 - val_acc: 0.5421

Epoch 00812: val_loss did not improve from 1.06588
Epoch 813/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0084 - acc: 0.5670 - val_loss: 1.0785 - val_acc: 0.5446

Epoch 00813: val_loss did not improve from 1.06588
Epoch 814/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0168 - acc: 0.5547 - val_loss: 1.0732 - val_acc: 0.5456

Epoch 00814: val_loss did not improve from 1.06588
Epoch 815/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0098 - acc: 0.5606 - val_loss: 1.0904 - val_acc: 0.5426

Epoch 00815: val_loss did not improve from 1.06588
Epoch 816/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0122 - acc: 0.5577 - val_loss: 1.1269 - val_acc: 0.5123

Epoch 00816: val_loss did not improve from 1.06588
Epoch 817/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0285 - acc: 0.5472 - val_loss: 1.0908 - val_acc: 0.5297

Epoch 00817: val_loss did not improve from 1.06588
Epoch 818/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0132 - acc: 0.5527 - val_loss: 1.0851 - val_acc: 0.5390

Epoch 00818: val_loss did not improve from 1.06588
Epoch 819/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0200 - acc: 0.5505 - val_loss: 1.0695 - val_acc: 0.5421

Epoch 00819: val_loss did not improve from 1.06588
Epoch 820/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0072 - acc: 0.5606 - val_loss: 1.0717 - val_acc: 0.5467

Epoch 00820: val_loss did not improve from 1.06588
Epoch 821/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0108 - acc: 0.5571 - val_loss: 1.0724 - val_acc: 0.5421

Epoch 00821: val_loss did not improve from 1.06588
Epoch 822/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0114 - acc: 0.5604 - val_loss: 1.0847 - val_acc: 0.5369

Epoch 00822: val_loss did not improve from 1.06588
Epoch 823/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0096 - acc: 0.5571 - val_loss: 1.0773 - val_acc: 0.5410

Epoch 00823: val_loss did not improve from 1.06588
Epoch 824/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0136 - acc: 0.5549 - val_loss: 1.0710 - val_acc: 0.5451

Epoch 00824: val_loss did not improve from 1.06588
Epoch 825/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0109 - acc: 0.5610 - val_loss: 1.0725 - val_acc: 0.5410

Epoch 00825: val_loss did not improve from 1.06588
Epoch 826/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0094 - acc: 0.5610 - val_loss: 1.1010 - val_acc: 0.5400

Epoch 00826: val_loss did not improve from 1.06588
Epoch 827/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0153 - acc: 0.5478 - val_loss: 1.0750 - val_acc: 0.5415

Epoch 00827: val_loss did not improve from 1.06588
Epoch 828/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0075 - acc: 0.5582 - val_loss: 1.0855 - val_acc: 0.5395

Epoch 00828: val_loss did not improve from 1.06588
Epoch 829/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0183 - acc: 0.5540 - val_loss: 1.0892 - val_acc: 0.5390

Epoch 00829: val_loss did not improve from 1.06588
Epoch 830/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0074 - acc: 0.5588 - val_loss: 1.0817 - val_acc: 0.5405

Epoch 00830: val_loss did not improve from 1.06588
Epoch 831/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0138 - acc: 0.5601 - val_loss: 1.0761 - val_acc: 0.5405

Epoch 00831: val_loss did not improve from 1.06588
Epoch 832/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0100 - acc: 0.5610 - val_loss: 1.0784 - val_acc: 0.5379

Epoch 00832: val_loss did not improve from 1.06588
Epoch 833/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0108 - acc: 0.5597 - val_loss: 1.0794 - val_acc: 0.5441

Epoch 00833: val_loss did not improve from 1.06588
Epoch 834/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0088 - acc: 0.5590 - val_loss: 1.0792 - val_acc: 0.5400

Epoch 00834: val_loss did not improve from 1.06588
Epoch 835/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0068 - acc: 0.5606 - val_loss: 1.0824 - val_acc: 0.5467

Epoch 00835: val_loss did not improve from 1.06588
Epoch 836/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0158 - acc: 0.5584 - val_loss: 1.0788 - val_acc: 0.5364

Epoch 00836: val_loss did not improve from 1.06588
Epoch 837/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0124 - acc: 0.5558 - val_loss: 1.0685 - val_acc: 0.5415

Epoch 00837: val_loss did not improve from 1.06588
Epoch 838/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0071 - acc: 0.5590 - val_loss: 1.0708 - val_acc: 0.5385

Epoch 00838: val_loss did not improve from 1.06588
Epoch 839/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0088 - acc: 0.5588 - val_loss: 1.0771 - val_acc: 0.5338

Epoch 00839: val_loss did not improve from 1.06588
Epoch 840/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0165 - acc: 0.5553 - val_loss: 1.0717 - val_acc: 0.5436

Epoch 00840: val_loss did not improve from 1.06588
Epoch 841/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0096 - acc: 0.5560 - val_loss: 1.0699 - val_acc: 0.5421

Epoch 00841: val_loss did not improve from 1.06588
Epoch 842/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0146 - acc: 0.5551 - val_loss: 1.0693 - val_acc: 0.5472

Epoch 00842: val_loss did not improve from 1.06588
Epoch 843/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0191 - acc: 0.5547 - val_loss: 1.0715 - val_acc: 0.5533

Epoch 00843: val_loss did not improve from 1.06588
Epoch 844/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0071 - acc: 0.5639 - val_loss: 1.0722 - val_acc: 0.5431

Epoch 00844: val_loss did not improve from 1.06588
Epoch 845/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0128 - acc: 0.5573 - val_loss: 1.0693 - val_acc: 0.5549

Epoch 00845: val_loss did not improve from 1.06588
Epoch 846/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0081 - acc: 0.5582 - val_loss: 1.0684 - val_acc: 0.5451

Epoch 00846: val_loss did not improve from 1.06588
Epoch 847/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0056 - acc: 0.5595 - val_loss: 1.0731 - val_acc: 0.5467

Epoch 00847: val_loss did not improve from 1.06588
Epoch 848/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0076 - acc: 0.5606 - val_loss: 1.0726 - val_acc: 0.5415

Epoch 00848: val_loss did not improve from 1.06588
Epoch 849/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0155 - acc: 0.5527 - val_loss: 1.0761 - val_acc: 0.5482

Epoch 00849: val_loss did not improve from 1.06588
Epoch 850/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0145 - acc: 0.5505 - val_loss: 1.0711 - val_acc: 0.5421

Epoch 00850: val_loss did not improve from 1.06588
Epoch 851/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0172 - acc: 0.5590 - val_loss: 1.0682 - val_acc: 0.5446

Epoch 00851: val_loss did not improve from 1.06588
Epoch 852/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0084 - acc: 0.5575 - val_loss: 1.0678 - val_acc: 0.5467

Epoch 00852: val_loss did not improve from 1.06588
Epoch 853/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0075 - acc: 0.5593 - val_loss: 1.0812 - val_acc: 0.5400

Epoch 00853: val_loss did not improve from 1.06588
Epoch 854/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0079 - acc: 0.5645 - val_loss: 1.0991 - val_acc: 0.5354

Epoch 00854: val_loss did not improve from 1.06588
Epoch 855/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0226 - acc: 0.5481 - val_loss: 1.1043 - val_acc: 0.5169

Epoch 00855: val_loss did not improve from 1.06588
Epoch 856/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0231 - acc: 0.5434 - val_loss: 1.0819 - val_acc: 0.5467

Epoch 00856: val_loss did not improve from 1.06588
Epoch 857/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0148 - acc: 0.5538 - val_loss: 1.0683 - val_acc: 0.5456

Epoch 00857: val_loss did not improve from 1.06588
Epoch 858/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0151 - acc: 0.5518 - val_loss: 1.0754 - val_acc: 0.5410

Epoch 00858: val_loss did not improve from 1.06588
Epoch 859/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0112 - acc: 0.5612 - val_loss: 1.0750 - val_acc: 0.5400

Epoch 00859: val_loss did not improve from 1.06588
Epoch 860/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0079 - acc: 0.5615 - val_loss: 1.0728 - val_acc: 0.5446

Epoch 00860: val_loss did not improve from 1.06588
Epoch 861/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0068 - acc: 0.5586 - val_loss: 1.0726 - val_acc: 0.5400

Epoch 00861: val_loss did not improve from 1.06588
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[17]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># save model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;result/my_model3.h5&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;result/my_model3.h5&#39;</span><span class="p">)</span>

<span class="c1"># Accuracy result</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Accuracy: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>

<span class="k">del</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>6497/6497 [==============================] - 0s 23us/step

 Accuracy: 0.5518
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="model-4">model 4<a class="anchor-link" href="#model-4">&#182;</a></h4><ul>
<li>input 12</li>
<li>4 hidden layer , 30 <em> 10 </em> 10 * 11 node</li>
<li>activation function : softplus -&gt; softplus -&gt; softplus -&gt; softmax</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[18]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># modeling</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softplus&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;softmax&#39;</span><span class="p">))</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;categorical_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[19]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model update</span>
<span class="n">MODEL_DIR</span> <span class="o">=</span> <span class="s1">&#39;model4/&#39;</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">):</span>
    <span class="n">os</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">MODEL_DIR</span><span class="p">)</span>

<span class="n">modelpath</span> <span class="o">=</span> <span class="s2">&quot;model4/</span><span class="si">{epoch:02d}</span><span class="s2">-</span><span class="si">{val_loss:.4f}</span><span class="s2">.hdf5&quot;</span>
<span class="n">checkpointer</span> <span class="o">=</span> <span class="n">ModelCheckpoint</span><span class="p">(</span><span class="n">filepath</span><span class="o">=</span><span class="n">modelpath</span><span class="p">,</span> <span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_best_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">early_stopping_callback</span> <span class="o">=</span> <span class="n">EarlyStopping</span><span class="p">(</span><span class="n">monitor</span><span class="o">=</span><span class="s1">&#39;val_loss&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="n">history4</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">3000</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">early_stopping_callback</span><span class="p">,</span> <span class="n">checkpointer</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Train on 4547 samples, validate on 1950 samples
Epoch 1/3000
4547/4547 [==============================] - 0s 88us/step - loss: 11.7683 - acc: 0.1674 - val_loss: 10.8906 - val_acc: 0.1631

Epoch 00001: val_loss improved from inf to 10.89063, saving model to model4/01-10.8906.hdf5
Epoch 2/3000
4547/4547 [==============================] - 0s 4us/step - loss: 9.6691 - acc: 0.1674 - val_loss: 6.8114 - val_acc: 0.1631

Epoch 00002: val_loss improved from 10.89063 to 6.81142, saving model to model4/02-6.8114.hdf5
Epoch 3/3000
4547/4547 [==============================] - 0s 4us/step - loss: 4.1222 - acc: 0.2138 - val_loss: 1.8792 - val_acc: 0.4359

Epoch 00003: val_loss improved from 6.81142 to 1.87916, saving model to model4/03-1.8792.hdf5
Epoch 4/3000
4547/4547 [==============================] - 0s 4us/step - loss: 2.1084 - acc: 0.4302 - val_loss: 2.2338 - val_acc: 0.4446

Epoch 00004: val_loss did not improve from 1.87916
Epoch 5/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.9217 - acc: 0.4291 - val_loss: 1.6465 - val_acc: 0.4087

Epoch 00005: val_loss improved from 1.87916 to 1.64648, saving model to model4/05-1.6465.hdf5
Epoch 6/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.5101 - acc: 0.3717 - val_loss: 1.5852 - val_acc: 0.3364

Epoch 00006: val_loss improved from 1.64648 to 1.58521, saving model to model4/06-1.5852.hdf5
Epoch 7/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.4652 - acc: 0.3754 - val_loss: 1.4914 - val_acc: 0.4426

Epoch 00007: val_loss improved from 1.58521 to 1.49140, saving model to model4/07-1.4914.hdf5
Epoch 8/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.4204 - acc: 0.4328 - val_loss: 1.4524 - val_acc: 0.4400

Epoch 00008: val_loss improved from 1.49140 to 1.45239, saving model to model4/08-1.4524.hdf5
Epoch 9/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3858 - acc: 0.4174 - val_loss: 1.4278 - val_acc: 0.4231

Epoch 00009: val_loss improved from 1.45239 to 1.42779, saving model to model4/09-1.4278.hdf5
Epoch 10/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3672 - acc: 0.4238 - val_loss: 1.4123 - val_acc: 0.4359

Epoch 00010: val_loss improved from 1.42779 to 1.41235, saving model to model4/10-1.4123.hdf5
Epoch 11/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.3477 - acc: 0.420 - 0s 4us/step - loss: 1.3518 - acc: 0.4302 - val_loss: 1.3903 - val_acc: 0.4364

Epoch 00011: val_loss improved from 1.41235 to 1.39028, saving model to model4/11-1.3903.hdf5
Epoch 12/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.3361 - acc: 0.4300 - val_loss: 1.3738 - val_acc: 0.4410

Epoch 00012: val_loss improved from 1.39028 to 1.37384, saving model to model4/12-1.3738.hdf5
Epoch 13/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.3217 - acc: 0.4328 - val_loss: 1.3617 - val_acc: 0.4354

Epoch 00013: val_loss improved from 1.37384 to 1.36173, saving model to model4/13-1.3617.hdf5
Epoch 14/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.3084 - acc: 0.4368 - val_loss: 1.3493 - val_acc: 0.4421

Epoch 00014: val_loss improved from 1.36173 to 1.34927, saving model to model4/14-1.3493.hdf5
Epoch 15/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2971 - acc: 0.4355 - val_loss: 1.3368 - val_acc: 0.4421

Epoch 00015: val_loss improved from 1.34927 to 1.33684, saving model to model4/15-1.3368.hdf5
Epoch 16/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2843 - acc: 0.4385 - val_loss: 1.3315 - val_acc: 0.4390

Epoch 00016: val_loss improved from 1.33684 to 1.33155, saving model to model4/16-1.3315.hdf5
Epoch 17/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2755 - acc: 0.4442 - val_loss: 1.3223 - val_acc: 0.4426

Epoch 00017: val_loss improved from 1.33155 to 1.32231, saving model to model4/17-1.3223.hdf5
Epoch 18/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2676 - acc: 0.4436 - val_loss: 1.3158 - val_acc: 0.4503

Epoch 00018: val_loss improved from 1.32231 to 1.31583, saving model to model4/18-1.3158.hdf5
Epoch 19/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2609 - acc: 0.4405 - val_loss: 1.3083 - val_acc: 0.4467

Epoch 00019: val_loss improved from 1.31583 to 1.30834, saving model to model4/19-1.3083.hdf5
Epoch 20/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2554 - acc: 0.4425 - val_loss: 1.3039 - val_acc: 0.4523

Epoch 00020: val_loss improved from 1.30834 to 1.30393, saving model to model4/20-1.3039.hdf5
Epoch 21/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2498 - acc: 0.4462 - val_loss: 1.2976 - val_acc: 0.4487

Epoch 00021: val_loss improved from 1.30393 to 1.29756, saving model to model4/21-1.2976.hdf5
Epoch 22/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2452 - acc: 0.4482 - val_loss: 1.2943 - val_acc: 0.4559

Epoch 00022: val_loss improved from 1.29756 to 1.29428, saving model to model4/22-1.2943.hdf5
Epoch 23/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2415 - acc: 0.4410 - val_loss: 1.3014 - val_acc: 0.4569

Epoch 00023: val_loss did not improve from 1.29428
Epoch 24/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2414 - acc: 0.4453 - val_loss: 1.2875 - val_acc: 0.4487

Epoch 00024: val_loss improved from 1.29428 to 1.28753, saving model to model4/24-1.2875.hdf5
Epoch 25/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2320 - acc: 0.4555 - val_loss: 1.2819 - val_acc: 0.4636

Epoch 00025: val_loss improved from 1.28753 to 1.28187, saving model to model4/25-1.2819.hdf5
Epoch 26/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2280 - acc: 0.4541 - val_loss: 1.2785 - val_acc: 0.4600

Epoch 00026: val_loss improved from 1.28187 to 1.27855, saving model to model4/26-1.2785.hdf5
Epoch 27/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2222 - acc: 0.4513 - val_loss: 1.2694 - val_acc: 0.4472

Epoch 00027: val_loss improved from 1.27855 to 1.26937, saving model to model4/27-1.2694.hdf5
Epoch 28/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2197 - acc: 0.4462 - val_loss: 1.2710 - val_acc: 0.4682

Epoch 00028: val_loss did not improve from 1.26937
Epoch 29/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.2148 - acc: 0.4544 - val_loss: 1.2631 - val_acc: 0.4656

Epoch 00029: val_loss improved from 1.26937 to 1.26314, saving model to model4/29-1.2631.hdf5
Epoch 30/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2153 - acc: 0.4440 - val_loss: 1.2596 - val_acc: 0.4590

Epoch 00030: val_loss improved from 1.26314 to 1.25962, saving model to model4/30-1.2596.hdf5
Epoch 31/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2144 - acc: 0.4704 - val_loss: 1.2577 - val_acc: 0.4682

Epoch 00031: val_loss improved from 1.25962 to 1.25770, saving model to model4/31-1.2577.hdf5
Epoch 32/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2110 - acc: 0.4497 - val_loss: 1.2660 - val_acc: 0.4692

Epoch 00032: val_loss did not improve from 1.25770
Epoch 33/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.2092 - acc: 0.4517 - val_loss: 1.2509 - val_acc: 0.4769

Epoch 00033: val_loss improved from 1.25770 to 1.25093, saving model to model4/33-1.2509.hdf5
Epoch 34/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.1982 - acc: 0.4684 - val_loss: 1.2446 - val_acc: 0.4687

Epoch 00034: val_loss improved from 1.25093 to 1.24465, saving model to model4/34-1.2446.hdf5
Epoch 35/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.1950 - acc: 0.4530 - val_loss: 1.2490 - val_acc: 0.4800

Epoch 00035: val_loss did not improve from 1.24465
Epoch 36/3000
4547/4547 [==============================] - 0s 5us/step - loss: 1.1931 - acc: 0.4702 - val_loss: 1.2451 - val_acc: 0.4831

Epoch 00036: val_loss did not improve from 1.24465
Epoch 37/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1929 - acc: 0.4821 - val_loss: 1.2373 - val_acc: 0.4703

Epoch 00037: val_loss improved from 1.24465 to 1.23725, saving model to model4/37-1.2373.hdf5
Epoch 38/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1872 - acc: 0.4574 - val_loss: 1.2414 - val_acc: 0.4867

Epoch 00038: val_loss did not improve from 1.23725
Epoch 39/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1825 - acc: 0.4717 - val_loss: 1.2341 - val_acc: 0.4831

Epoch 00039: val_loss improved from 1.23725 to 1.23412, saving model to model4/39-1.2341.hdf5
Epoch 40/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1805 - acc: 0.4768 - val_loss: 1.2312 - val_acc: 0.4826

Epoch 00040: val_loss improved from 1.23412 to 1.23115, saving model to model4/40-1.2312.hdf5
Epoch 41/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1768 - acc: 0.4728 - val_loss: 1.2300 - val_acc: 0.4851

Epoch 00041: val_loss improved from 1.23115 to 1.23005, saving model to model4/41-1.2300.hdf5
Epoch 42/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1742 - acc: 0.4610 - val_loss: 1.2471 - val_acc: 0.4938

Epoch 00042: val_loss did not improve from 1.23005
Epoch 43/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1829 - acc: 0.4904 - val_loss: 1.2252 - val_acc: 0.4662

Epoch 00043: val_loss improved from 1.23005 to 1.22524, saving model to model4/43-1.2252.hdf5
Epoch 44/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1710 - acc: 0.4814 - val_loss: 1.2201 - val_acc: 0.4703

Epoch 00044: val_loss improved from 1.22524 to 1.22014, saving model to model4/44-1.2201.hdf5
Epoch 45/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1674 - acc: 0.4709 - val_loss: 1.2225 - val_acc: 0.5005

Epoch 00045: val_loss did not improve from 1.22014
Epoch 46/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1648 - acc: 0.4799 - val_loss: 1.2309 - val_acc: 0.4959

Epoch 00046: val_loss did not improve from 1.22014
Epoch 47/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1703 - acc: 0.4856 - val_loss: 1.2115 - val_acc: 0.4769

Epoch 00047: val_loss improved from 1.22014 to 1.21152, saving model to model4/47-1.2115.hdf5
Epoch 48/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1583 - acc: 0.4924 - val_loss: 1.2114 - val_acc: 0.4867

Epoch 00048: val_loss improved from 1.21152 to 1.21145, saving model to model4/48-1.2114.hdf5
Epoch 49/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1562 - acc: 0.4878 - val_loss: 1.2127 - val_acc: 0.5118

Epoch 00049: val_loss did not improve from 1.21145
Epoch 50/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1556 - acc: 0.4933 - val_loss: 1.2018 - val_acc: 0.4856

Epoch 00050: val_loss improved from 1.21145 to 1.20183, saving model to model4/50-1.2018.hdf5
Epoch 51/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1493 - acc: 0.4882 - val_loss: 1.2143 - val_acc: 0.5108

Epoch 00051: val_loss did not improve from 1.20183
Epoch 52/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1530 - acc: 0.4988 - val_loss: 1.2032 - val_acc: 0.4974

Epoch 00052: val_loss did not improve from 1.20183
Epoch 53/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1490 - acc: 0.4882 - val_loss: 1.1987 - val_acc: 0.4877

Epoch 00053: val_loss improved from 1.20183 to 1.19865, saving model to model4/53-1.1987.hdf5
Epoch 54/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1547 - acc: 0.4966 - val_loss: 1.1920 - val_acc: 0.4846

Epoch 00054: val_loss improved from 1.19865 to 1.19202, saving model to model4/54-1.1920.hdf5
Epoch 55/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1553 - acc: 0.4887 - val_loss: 1.1939 - val_acc: 0.5077

Epoch 00055: val_loss did not improve from 1.19202
Epoch 56/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1471 - acc: 0.4854 - val_loss: 1.2047 - val_acc: 0.5164

Epoch 00056: val_loss did not improve from 1.19202
Epoch 57/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1419 - acc: 0.4966 - val_loss: 1.1878 - val_acc: 0.5005

Epoch 00057: val_loss improved from 1.19202 to 1.18781, saving model to model4/57-1.1878.hdf5
Epoch 58/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1369 - acc: 0.5058 - val_loss: 1.1872 - val_acc: 0.5031

Epoch 00058: val_loss improved from 1.18781 to 1.18720, saving model to model4/58-1.1872.hdf5
Epoch 59/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1356 - acc: 0.4926 - val_loss: 1.1964 - val_acc: 0.5056

Epoch 00059: val_loss did not improve from 1.18720
Epoch 60/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.1347 - acc: 0.4964 - val_loss: 1.1820 - val_acc: 0.5056

Epoch 00060: val_loss improved from 1.18720 to 1.18198, saving model to model4/60-1.1820.hdf5
Epoch 61/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1288 - acc: 0.5049 - val_loss: 1.1813 - val_acc: 0.5067

Epoch 00061: val_loss improved from 1.18198 to 1.18132, saving model to model4/61-1.1813.hdf5
Epoch 62/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1263 - acc: 0.5076 - val_loss: 1.1745 - val_acc: 0.4995

Epoch 00062: val_loss improved from 1.18132 to 1.17451, saving model to model4/62-1.1745.hdf5
Epoch 63/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1253 - acc: 0.5065 - val_loss: 1.1823 - val_acc: 0.5190

Epoch 00063: val_loss did not improve from 1.17451
Epoch 64/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1234 - acc: 0.5104 - val_loss: 1.1727 - val_acc: 0.5056

Epoch 00064: val_loss improved from 1.17451 to 1.17266, saving model to model4/64-1.1727.hdf5
Epoch 65/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1200 - acc: 0.5164 - val_loss: 1.1761 - val_acc: 0.4974

Epoch 00065: val_loss did not improve from 1.17266
Epoch 66/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1306 - acc: 0.5054 - val_loss: 1.1679 - val_acc: 0.5005

Epoch 00066: val_loss improved from 1.17266 to 1.16794, saving model to model4/66-1.1679.hdf5
Epoch 67/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1177 - acc: 0.5111 - val_loss: 1.1636 - val_acc: 0.5113

Epoch 00067: val_loss improved from 1.16794 to 1.16362, saving model to model4/67-1.1636.hdf5
Epoch 68/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1171 - acc: 0.5120 - val_loss: 1.1742 - val_acc: 0.5205

Epoch 00068: val_loss did not improve from 1.16362
Epoch 69/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1179 - acc: 0.5104 - val_loss: 1.1755 - val_acc: 0.5256

Epoch 00069: val_loss did not improve from 1.16362
Epoch 70/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1116 - acc: 0.5135 - val_loss: 1.1732 - val_acc: 0.5226

Epoch 00070: val_loss did not improve from 1.16362
Epoch 71/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1133 - acc: 0.5210 - val_loss: 1.1674 - val_acc: 0.5108

Epoch 00071: val_loss did not improve from 1.16362
Epoch 72/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1311 - acc: 0.4964 - val_loss: 1.1656 - val_acc: 0.5077

Epoch 00072: val_loss did not improve from 1.16362
Epoch 73/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1157 - acc: 0.5089 - val_loss: 1.1603 - val_acc: 0.5144

Epoch 00073: val_loss improved from 1.16362 to 1.16025, saving model to model4/73-1.1603.hdf5
Epoch 74/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1154 - acc: 0.5045 - val_loss: 1.1556 - val_acc: 0.5226

Epoch 00074: val_loss improved from 1.16025 to 1.15561, saving model to model4/74-1.1556.hdf5
Epoch 75/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1116 - acc: 0.5175 - val_loss: 1.1750 - val_acc: 0.5195

Epoch 00075: val_loss did not improve from 1.15561
Epoch 76/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1093 - acc: 0.5267 - val_loss: 1.1513 - val_acc: 0.5282

Epoch 00076: val_loss improved from 1.15561 to 1.15133, saving model to model4/76-1.1513.hdf5
Epoch 77/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1084 - acc: 0.5131 - val_loss: 1.1527 - val_acc: 0.5215

Epoch 00077: val_loss did not improve from 1.15133
Epoch 78/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1067 - acc: 0.5203 - val_loss: 1.1596 - val_acc: 0.5262

Epoch 00078: val_loss did not improve from 1.15133
Epoch 79/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1064 - acc: 0.5109 - val_loss: 1.1559 - val_acc: 0.5159

Epoch 00079: val_loss did not improve from 1.15133
Epoch 80/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1038 - acc: 0.5177 - val_loss: 1.1610 - val_acc: 0.5226

Epoch 00080: val_loss did not improve from 1.15133
Epoch 81/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1051 - acc: 0.5146 - val_loss: 1.1598 - val_acc: 0.5169

Epoch 00081: val_loss did not improve from 1.15133
Epoch 82/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0991 - acc: 0.5170 - val_loss: 1.1490 - val_acc: 0.5246

Epoch 00082: val_loss improved from 1.15133 to 1.14904, saving model to model4/82-1.1490.hdf5
Epoch 83/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0968 - acc: 0.5258 - val_loss: 1.1456 - val_acc: 0.5328

Epoch 00083: val_loss improved from 1.14904 to 1.14564, saving model to model4/83-1.1456.hdf5
Epoch 84/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0977 - acc: 0.5192 - val_loss: 1.1551 - val_acc: 0.5087

Epoch 00084: val_loss did not improve from 1.14564
Epoch 85/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1031 - acc: 0.5100 - val_loss: 1.1511 - val_acc: 0.5262

Epoch 00085: val_loss did not improve from 1.14564
Epoch 86/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1000 - acc: 0.5208 - val_loss: 1.1740 - val_acc: 0.5123

Epoch 00086: val_loss did not improve from 1.14564
Epoch 87/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1103 - acc: 0.5115 - val_loss: 1.1460 - val_acc: 0.5277

Epoch 00087: val_loss did not improve from 1.14564
Epoch 88/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1009 - acc: 0.5232 - val_loss: 1.1455 - val_acc: 0.5179

Epoch 00088: val_loss improved from 1.14564 to 1.14545, saving model to model4/88-1.1455.hdf5
Epoch 89/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0946 - acc: 0.5195 - val_loss: 1.1588 - val_acc: 0.5159

Epoch 00089: val_loss did not improve from 1.14545
Epoch 90/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0957 - acc: 0.5214 - val_loss: 1.1494 - val_acc: 0.5251

Epoch 00090: val_loss did not improve from 1.14545
Epoch 91/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0936 - acc: 0.5214 - val_loss: 1.1403 - val_acc: 0.5241

Epoch 00091: val_loss improved from 1.14545 to 1.14026, saving model to model4/91-1.1403.hdf5
Epoch 92/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0969 - acc: 0.5206 - val_loss: 1.1353 - val_acc: 0.5369

Epoch 00092: val_loss improved from 1.14026 to 1.13528, saving model to model4/92-1.1353.hdf5
Epoch 93/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0992 - acc: 0.5175 - val_loss: 1.1603 - val_acc: 0.5277

Epoch 00093: val_loss did not improve from 1.13528
Epoch 94/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0893 - acc: 0.5252 - val_loss: 1.1419 - val_acc: 0.5287

Epoch 00094: val_loss did not improve from 1.13528
Epoch 95/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0881 - acc: 0.5247 - val_loss: 1.1454 - val_acc: 0.5303

Epoch 00095: val_loss did not improve from 1.13528
Epoch 96/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0891 - acc: 0.5236 - val_loss: 1.1342 - val_acc: 0.5277

Epoch 00096: val_loss improved from 1.13528 to 1.13424, saving model to model4/96-1.1342.hdf5
Epoch 97/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0862 - acc: 0.5331 - val_loss: 1.1357 - val_acc: 0.5344

Epoch 00097: val_loss did not improve from 1.13424
Epoch 98/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0851 - acc: 0.5287 - val_loss: 1.1382 - val_acc: 0.5195

Epoch 00098: val_loss did not improve from 1.13424
Epoch 99/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0898 - acc: 0.5243 - val_loss: 1.1357 - val_acc: 0.5297

Epoch 00099: val_loss did not improve from 1.13424
Epoch 100/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0852 - acc: 0.5291 - val_loss: 1.1469 - val_acc: 0.5092

Epoch 00100: val_loss did not improve from 1.13424
Epoch 101/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0944 - acc: 0.5208 - val_loss: 1.1382 - val_acc: 0.5364

Epoch 00101: val_loss did not improve from 1.13424
Epoch 102/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0830 - acc: 0.5307 - val_loss: 1.1291 - val_acc: 0.5359

Epoch 00102: val_loss improved from 1.13424 to 1.12908, saving model to model4/102-1.1291.hdf5
Epoch 103/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0843 - acc: 0.5274 - val_loss: 1.1751 - val_acc: 0.5118

Epoch 00103: val_loss did not improve from 1.12908
Epoch 104/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1042 - acc: 0.5113 - val_loss: 1.1312 - val_acc: 0.5333

Epoch 00104: val_loss did not improve from 1.12908
Epoch 105/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0924 - acc: 0.5195 - val_loss: 1.1417 - val_acc: 0.5338

Epoch 00105: val_loss did not improve from 1.12908
Epoch 106/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0854 - acc: 0.5269 - val_loss: 1.1322 - val_acc: 0.5210

Epoch 00106: val_loss did not improve from 1.12908
Epoch 107/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0875 - acc: 0.5155 - val_loss: 1.1300 - val_acc: 0.5303

Epoch 00107: val_loss did not improve from 1.12908
Epoch 108/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0834 - acc: 0.5327 - val_loss: 1.1838 - val_acc: 0.5097

Epoch 00108: val_loss did not improve from 1.12908
Epoch 109/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.1502 - acc: 0.500 - 0s 4us/step - loss: 1.0977 - acc: 0.5115 - val_loss: 1.1367 - val_acc: 0.5267

Epoch 00109: val_loss did not improve from 1.12908
Epoch 110/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0833 - acc: 0.5245 - val_loss: 1.1295 - val_acc: 0.5338

Epoch 00110: val_loss did not improve from 1.12908
Epoch 111/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0789 - acc: 0.5320 - val_loss: 1.1288 - val_acc: 0.5308

Epoch 00111: val_loss improved from 1.12908 to 1.12878, saving model to model4/111-1.1288.hdf5
Epoch 112/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0775 - acc: 0.5324 - val_loss: 1.1294 - val_acc: 0.5297

Epoch 00112: val_loss did not improve from 1.12878
Epoch 113/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0772 - acc: 0.5344 - val_loss: 1.1330 - val_acc: 0.5338

Epoch 00113: val_loss did not improve from 1.12878
Epoch 114/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0773 - acc: 0.5375 - val_loss: 1.1272 - val_acc: 0.5246

Epoch 00114: val_loss improved from 1.12878 to 1.12717, saving model to model4/114-1.1272.hdf5
Epoch 115/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0879 - acc: 0.5236 - val_loss: 1.1552 - val_acc: 0.5246

Epoch 00115: val_loss did not improve from 1.12717
Epoch 116/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0944 - acc: 0.5142 - val_loss: 1.1218 - val_acc: 0.5344

Epoch 00116: val_loss improved from 1.12717 to 1.12177, saving model to model4/116-1.1218.hdf5
Epoch 117/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0755 - acc: 0.5355 - val_loss: 1.1228 - val_acc: 0.5364

Epoch 00117: val_loss did not improve from 1.12177
Epoch 118/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0793 - acc: 0.5302 - val_loss: 1.1390 - val_acc: 0.5159

Epoch 00118: val_loss did not improve from 1.12177
Epoch 119/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0966 - acc: 0.5111 - val_loss: 1.1261 - val_acc: 0.5328

Epoch 00119: val_loss did not improve from 1.12177
Epoch 120/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0774 - acc: 0.5335 - val_loss: 1.1252 - val_acc: 0.5374

Epoch 00120: val_loss did not improve from 1.12177
Epoch 121/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0795 - acc: 0.5318 - val_loss: 1.1255 - val_acc: 0.5328

Epoch 00121: val_loss did not improve from 1.12177
Epoch 122/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0750 - acc: 0.5327 - val_loss: 1.1405 - val_acc: 0.5251

Epoch 00122: val_loss did not improve from 1.12177
Epoch 123/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0805 - acc: 0.5289 - val_loss: 1.1527 - val_acc: 0.5072

Epoch 00123: val_loss did not improve from 1.12177
Epoch 124/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.1053 - acc: 0.5124 - val_loss: 1.1284 - val_acc: 0.5185

Epoch 00124: val_loss did not improve from 1.12177
Epoch 125/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0858 - acc: 0.5197 - val_loss: 1.1346 - val_acc: 0.5415

Epoch 00125: val_loss did not improve from 1.12177
Epoch 126/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0732 - acc: 0.5344 - val_loss: 1.1244 - val_acc: 0.5354

Epoch 00126: val_loss did not improve from 1.12177
Epoch 127/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0720 - acc: 0.5307 - val_loss: 1.1327 - val_acc: 0.5374

Epoch 00127: val_loss did not improve from 1.12177
Epoch 128/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0710 - acc: 0.5344 - val_loss: 1.1511 - val_acc: 0.5133

Epoch 00128: val_loss did not improve from 1.12177
Epoch 129/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0743 - acc: 0.5318 - val_loss: 1.1245 - val_acc: 0.5390

Epoch 00129: val_loss did not improve from 1.12177
Epoch 130/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0733 - acc: 0.5384 - val_loss: 1.1262 - val_acc: 0.5277

Epoch 00130: val_loss did not improve from 1.12177
Epoch 131/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0727 - acc: 0.5331 - val_loss: 1.1212 - val_acc: 0.5297

Epoch 00131: val_loss improved from 1.12177 to 1.12121, saving model to model4/131-1.1212.hdf5
Epoch 132/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0734 - acc: 0.5338 - val_loss: 1.1214 - val_acc: 0.5374

Epoch 00132: val_loss did not improve from 1.12121
Epoch 133/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0698 - acc: 0.5311 - val_loss: 1.1330 - val_acc: 0.5251

Epoch 00133: val_loss did not improve from 1.12121
Epoch 134/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0705 - acc: 0.5410 - val_loss: 1.1335 - val_acc: 0.5256

Epoch 00134: val_loss did not improve from 1.12121
Epoch 135/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0754 - acc: 0.5340 - val_loss: 1.1227 - val_acc: 0.5369

Epoch 00135: val_loss did not improve from 1.12121
Epoch 136/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0714 - acc: 0.5355 - val_loss: 1.1387 - val_acc: 0.5123

Epoch 00136: val_loss did not improve from 1.12121
Epoch 137/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0818 - acc: 0.5245 - val_loss: 1.1214 - val_acc: 0.5395

Epoch 00137: val_loss did not improve from 1.12121
Epoch 138/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0775 - acc: 0.5335 - val_loss: 1.1231 - val_acc: 0.5395

Epoch 00138: val_loss did not improve from 1.12121
Epoch 139/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0788 - acc: 0.5232 - val_loss: 1.1201 - val_acc: 0.5303

Epoch 00139: val_loss improved from 1.12121 to 1.12007, saving model to model4/139-1.1201.hdf5
Epoch 140/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0719 - acc: 0.5344 - val_loss: 1.1234 - val_acc: 0.5251

Epoch 00140: val_loss did not improve from 1.12007
Epoch 141/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0699 - acc: 0.5289 - val_loss: 1.1306 - val_acc: 0.5364

Epoch 00141: val_loss did not improve from 1.12007
Epoch 142/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0659 - acc: 0.5406 - val_loss: 1.1292 - val_acc: 0.5282

Epoch 00142: val_loss did not improve from 1.12007
Epoch 143/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0701 - acc: 0.5340 - val_loss: 1.1232 - val_acc: 0.5400

Epoch 00143: val_loss did not improve from 1.12007
Epoch 144/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0784 - acc: 0.5307 - val_loss: 1.1292 - val_acc: 0.5195

Epoch 00144: val_loss did not improve from 1.12007
Epoch 145/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0793 - acc: 0.5256 - val_loss: 1.1249 - val_acc: 0.5328

Epoch 00145: val_loss did not improve from 1.12007
Epoch 146/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0752 - acc: 0.5280 - val_loss: 1.1339 - val_acc: 0.5287

Epoch 00146: val_loss did not improve from 1.12007
Epoch 147/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0672 - acc: 0.5388 - val_loss: 1.1536 - val_acc: 0.5236

Epoch 00147: val_loss did not improve from 1.12007
Epoch 148/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0749 - acc: 0.5305 - val_loss: 1.1144 - val_acc: 0.5272

Epoch 00148: val_loss improved from 1.12007 to 1.11439, saving model to model4/148-1.1144.hdf5
Epoch 149/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0689 - acc: 0.5428 - val_loss: 1.1201 - val_acc: 0.5431

Epoch 00149: val_loss did not improve from 1.11439
Epoch 150/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0669 - acc: 0.5401 - val_loss: 1.1378 - val_acc: 0.5272

Epoch 00150: val_loss did not improve from 1.11439
Epoch 151/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0654 - acc: 0.5344 - val_loss: 1.1173 - val_acc: 0.5344

Epoch 00151: val_loss did not improve from 1.11439
Epoch 152/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0625 - acc: 0.5459 - val_loss: 1.1150 - val_acc: 0.5405

Epoch 00152: val_loss did not improve from 1.11439
Epoch 153/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0628 - acc: 0.5412 - val_loss: 1.1234 - val_acc: 0.5205

Epoch 00153: val_loss did not improve from 1.11439
Epoch 154/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0672 - acc: 0.5327 - val_loss: 1.1238 - val_acc: 0.5323

Epoch 00154: val_loss did not improve from 1.11439
Epoch 155/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0714 - acc: 0.5276 - val_loss: 1.1414 - val_acc: 0.5297

Epoch 00155: val_loss did not improve from 1.11439
Epoch 156/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0726 - acc: 0.5276 - val_loss: 1.1146 - val_acc: 0.5374

Epoch 00156: val_loss did not improve from 1.11439
Epoch 157/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0630 - acc: 0.5428 - val_loss: 1.1178 - val_acc: 0.5379

Epoch 00157: val_loss did not improve from 1.11439
Epoch 158/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0628 - acc: 0.5406 - val_loss: 1.1263 - val_acc: 0.5338

Epoch 00158: val_loss did not improve from 1.11439
Epoch 159/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0652 - acc: 0.5397 - val_loss: 1.1123 - val_acc: 0.5323

Epoch 00159: val_loss improved from 1.11439 to 1.11230, saving model to model4/159-1.1123.hdf5
Epoch 160/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0595 - acc: 0.5415 - val_loss: 1.1133 - val_acc: 0.5462

Epoch 00160: val_loss did not improve from 1.11230
Epoch 161/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0592 - acc: 0.5412 - val_loss: 1.1403 - val_acc: 0.5231

Epoch 00161: val_loss did not improve from 1.11230
Epoch 162/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0762 - acc: 0.5320 - val_loss: 1.1129 - val_acc: 0.5354

Epoch 00162: val_loss did not improve from 1.11230
Epoch 163/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0605 - acc: 0.5388 - val_loss: 1.1130 - val_acc: 0.5441

Epoch 00163: val_loss did not improve from 1.11230
Epoch 164/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0581 - acc: 0.5408 - val_loss: 1.1232 - val_acc: 0.5133

Epoch 00164: val_loss did not improve from 1.11230
Epoch 165/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0799 - acc: 0.5223 - val_loss: 1.1119 - val_acc: 0.5379

Epoch 00165: val_loss improved from 1.11230 to 1.11191, saving model to model4/165-1.1119.hdf5
Epoch 166/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0599 - acc: 0.5384 - val_loss: 1.1179 - val_acc: 0.5323

Epoch 00166: val_loss did not improve from 1.11191
Epoch 167/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0618 - acc: 0.5412 - val_loss: 1.1138 - val_acc: 0.5349

Epoch 00167: val_loss did not improve from 1.11191
Epoch 168/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0595 - acc: 0.5335 - val_loss: 1.1258 - val_acc: 0.5292

Epoch 00168: val_loss did not improve from 1.11191
Epoch 169/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0658 - acc: 0.5419 - val_loss: 1.1263 - val_acc: 0.5221

Epoch 00169: val_loss did not improve from 1.11191
Epoch 170/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0717 - acc: 0.5322 - val_loss: 1.1280 - val_acc: 0.5333

Epoch 00170: val_loss did not improve from 1.11191
Epoch 171/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0670 - acc: 0.5342 - val_loss: 1.1159 - val_acc: 0.5282

Epoch 00171: val_loss did not improve from 1.11191
Epoch 172/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0660 - acc: 0.5375 - val_loss: 1.1150 - val_acc: 0.5333

Epoch 00172: val_loss did not improve from 1.11191
Epoch 173/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0562 - acc: 0.5386 - val_loss: 1.1175 - val_acc: 0.5313

Epoch 00173: val_loss did not improve from 1.11191
Epoch 174/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0564 - acc: 0.5432 - val_loss: 1.1198 - val_acc: 0.5338

Epoch 00174: val_loss did not improve from 1.11191
Epoch 175/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0554 - acc: 0.5459 - val_loss: 1.1171 - val_acc: 0.5323

Epoch 00175: val_loss did not improve from 1.11191
Epoch 176/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0593 - acc: 0.5344 - val_loss: 1.1124 - val_acc: 0.5477

Epoch 00176: val_loss did not improve from 1.11191
Epoch 177/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0552 - acc: 0.5419 - val_loss: 1.1114 - val_acc: 0.5369

Epoch 00177: val_loss improved from 1.11191 to 1.11140, saving model to model4/177-1.1114.hdf5
Epoch 178/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0549 - acc: 0.5439 - val_loss: 1.1300 - val_acc: 0.5256

Epoch 00178: val_loss did not improve from 1.11140
Epoch 179/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0698 - acc: 0.5375 - val_loss: 1.1110 - val_acc: 0.5231

Epoch 00179: val_loss improved from 1.11140 to 1.11101, saving model to model4/179-1.1110.hdf5
Epoch 180/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0590 - acc: 0.5417 - val_loss: 1.1089 - val_acc: 0.5374

Epoch 00180: val_loss improved from 1.11101 to 1.10893, saving model to model4/180-1.1089.hdf5
Epoch 181/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0592 - acc: 0.5386 - val_loss: 1.1186 - val_acc: 0.5359

Epoch 00181: val_loss did not improve from 1.10893
Epoch 182/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0611 - acc: 0.5371 - val_loss: 1.1221 - val_acc: 0.5164

Epoch 00182: val_loss did not improve from 1.10893
Epoch 183/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0669 - acc: 0.5329 - val_loss: 1.1156 - val_acc: 0.5410

Epoch 00183: val_loss did not improve from 1.10893
Epoch 184/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0622 - acc: 0.5351 - val_loss: 1.1202 - val_acc: 0.5200

Epoch 00184: val_loss did not improve from 1.10893
Epoch 185/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0706 - acc: 0.5313 - val_loss: 1.1114 - val_acc: 0.5287

Epoch 00185: val_loss did not improve from 1.10893
Epoch 186/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0595 - acc: 0.5375 - val_loss: 1.1742 - val_acc: 0.5036

Epoch 00186: val_loss did not improve from 1.10893
Epoch 187/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0755 - acc: 0.5250 - val_loss: 1.1129 - val_acc: 0.5421

Epoch 00187: val_loss did not improve from 1.10893
Epoch 188/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0599 - acc: 0.5375 - val_loss: 1.1085 - val_acc: 0.5349

Epoch 00188: val_loss improved from 1.10893 to 1.10852, saving model to model4/188-1.1085.hdf5
Epoch 189/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0595 - acc: 0.5395 - val_loss: 1.1309 - val_acc: 0.5241

Epoch 00189: val_loss did not improve from 1.10852
Epoch 190/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0823 - acc: 0.5280 - val_loss: 1.1094 - val_acc: 0.5359

Epoch 00190: val_loss did not improve from 1.10852
Epoch 191/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0644 - acc: 0.5344 - val_loss: 1.1164 - val_acc: 0.5226

Epoch 00191: val_loss did not improve from 1.10852
Epoch 192/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0568 - acc: 0.5408 - val_loss: 1.1297 - val_acc: 0.5256

Epoch 00192: val_loss did not improve from 1.10852
Epoch 193/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0657 - acc: 0.5245 - val_loss: 1.1560 - val_acc: 0.5133

Epoch 00193: val_loss did not improve from 1.10852
Epoch 194/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0700 - acc: 0.5316 - val_loss: 1.1201 - val_acc: 0.5308

Epoch 00194: val_loss did not improve from 1.10852
Epoch 195/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0693 - acc: 0.5287 - val_loss: 1.1243 - val_acc: 0.5221

Epoch 00195: val_loss did not improve from 1.10852
Epoch 196/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0726 - acc: 0.5274 - val_loss: 1.1101 - val_acc: 0.5349

Epoch 00196: val_loss did not improve from 1.10852
Epoch 197/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0589 - acc: 0.5371 - val_loss: 1.1102 - val_acc: 0.5421

Epoch 00197: val_loss did not improve from 1.10852
Epoch 198/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0537 - acc: 0.5461 - val_loss: 1.1071 - val_acc: 0.5421

Epoch 00198: val_loss improved from 1.10852 to 1.10712, saving model to model4/198-1.1071.hdf5
Epoch 199/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0536 - acc: 0.5430 - val_loss: 1.1142 - val_acc: 0.5323

Epoch 00199: val_loss did not improve from 1.10712
Epoch 200/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0527 - acc: 0.5434 - val_loss: 1.1044 - val_acc: 0.5446

Epoch 00200: val_loss improved from 1.10712 to 1.10439, saving model to model4/200-1.1044.hdf5
Epoch 201/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0524 - acc: 0.5452 - val_loss: 1.1081 - val_acc: 0.5256

Epoch 00201: val_loss did not improve from 1.10439
Epoch 202/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0618 - acc: 0.5324 - val_loss: 1.1292 - val_acc: 0.5287

Epoch 00202: val_loss did not improve from 1.10439
Epoch 203/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0613 - acc: 0.5316 - val_loss: 1.1027 - val_acc: 0.5303

Epoch 00203: val_loss improved from 1.10439 to 1.10272, saving model to model4/203-1.1027.hdf5
Epoch 204/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0596 - acc: 0.5426 - val_loss: 1.1036 - val_acc: 0.5323

Epoch 00204: val_loss did not improve from 1.10272
Epoch 205/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0544 - acc: 0.5450 - val_loss: 1.1082 - val_acc: 0.5421

Epoch 00205: val_loss did not improve from 1.10272
Epoch 206/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0533 - acc: 0.5461 - val_loss: 1.1036 - val_acc: 0.5292

Epoch 00206: val_loss did not improve from 1.10272
Epoch 207/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0620 - acc: 0.5307 - val_loss: 1.1065 - val_acc: 0.5333

Epoch 00207: val_loss did not improve from 1.10272
Epoch 208/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0633 - acc: 0.5346 - val_loss: 1.1039 - val_acc: 0.5374

Epoch 00208: val_loss did not improve from 1.10272
Epoch 209/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0553 - acc: 0.5388 - val_loss: 1.1141 - val_acc: 0.5390

Epoch 00209: val_loss did not improve from 1.10272
Epoch 210/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0563 - acc: 0.5408 - val_loss: 1.1170 - val_acc: 0.5354

Epoch 00210: val_loss did not improve from 1.10272
Epoch 211/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0513 - acc: 0.5393 - val_loss: 1.1051 - val_acc: 0.5467

Epoch 00211: val_loss did not improve from 1.10272
Epoch 212/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0503 - acc: 0.5441 - val_loss: 1.1038 - val_acc: 0.5303

Epoch 00212: val_loss did not improve from 1.10272
Epoch 213/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0514 - acc: 0.5412 - val_loss: 1.1025 - val_acc: 0.5451

Epoch 00213: val_loss improved from 1.10272 to 1.10253, saving model to model4/213-1.1025.hdf5
Epoch 214/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0530 - acc: 0.5452 - val_loss: 1.1042 - val_acc: 0.5410

Epoch 00214: val_loss did not improve from 1.10253
Epoch 215/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0524 - acc: 0.5426 - val_loss: 1.1046 - val_acc: 0.5369

Epoch 00215: val_loss did not improve from 1.10253
Epoch 216/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0559 - acc: 0.5406 - val_loss: 1.1110 - val_acc: 0.5323

Epoch 00216: val_loss did not improve from 1.10253
Epoch 217/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0537 - acc: 0.5406 - val_loss: 1.1431 - val_acc: 0.5082

Epoch 00217: val_loss did not improve from 1.10253
Epoch 218/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0533 - acc: 0.5406 - val_loss: 1.1368 - val_acc: 0.5221

Epoch 00218: val_loss did not improve from 1.10253
Epoch 219/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0563 - acc: 0.5364 - val_loss: 1.1114 - val_acc: 0.5164

Epoch 00219: val_loss did not improve from 1.10253
Epoch 220/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0621 - acc: 0.5263 - val_loss: 1.1202 - val_acc: 0.5200

Epoch 00220: val_loss did not improve from 1.10253
Epoch 221/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0592 - acc: 0.5351 - val_loss: 1.1090 - val_acc: 0.5385

Epoch 00221: val_loss did not improve from 1.10253
Epoch 222/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0557 - acc: 0.5399 - val_loss: 1.1064 - val_acc: 0.5221

Epoch 00222: val_loss did not improve from 1.10253
Epoch 223/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0547 - acc: 0.5395 - val_loss: 1.1041 - val_acc: 0.5323

Epoch 00223: val_loss did not improve from 1.10253
Epoch 224/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0490 - acc: 0.5373 - val_loss: 1.1208 - val_acc: 0.5323

Epoch 00224: val_loss did not improve from 1.10253
Epoch 225/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0576 - acc: 0.5386 - val_loss: 1.1150 - val_acc: 0.5297

Epoch 00225: val_loss did not improve from 1.10253
Epoch 226/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0504 - acc: 0.5476 - val_loss: 1.1118 - val_acc: 0.5226

Epoch 00226: val_loss did not improve from 1.10253
Epoch 227/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0617 - acc: 0.5298 - val_loss: 1.1192 - val_acc: 0.5333

Epoch 00227: val_loss did not improve from 1.10253
Epoch 228/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0581 - acc: 0.5410 - val_loss: 1.1019 - val_acc: 0.5364

Epoch 00228: val_loss improved from 1.10253 to 1.10195, saving model to model4/228-1.1019.hdf5
Epoch 229/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0524 - acc: 0.5386 - val_loss: 1.1010 - val_acc: 0.5421

Epoch 00229: val_loss improved from 1.10195 to 1.10104, saving model to model4/229-1.1010.hdf5
Epoch 230/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0492 - acc: 0.5467 - val_loss: 1.1107 - val_acc: 0.5323

Epoch 00230: val_loss did not improve from 1.10104
Epoch 231/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0485 - acc: 0.5417 - val_loss: 1.1100 - val_acc: 0.5338

Epoch 00231: val_loss did not improve from 1.10104
Epoch 232/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0469 - acc: 0.5461 - val_loss: 1.1228 - val_acc: 0.5313

Epoch 00232: val_loss did not improve from 1.10104
Epoch 233/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0516 - acc: 0.5439 - val_loss: 1.0991 - val_acc: 0.5385

Epoch 00233: val_loss improved from 1.10104 to 1.09907, saving model to model4/233-1.0991.hdf5
Epoch 234/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0497 - acc: 0.5454 - val_loss: 1.1132 - val_acc: 0.5379

Epoch 00234: val_loss did not improve from 1.09907
Epoch 235/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0457 - acc: 0.5419 - val_loss: 1.0995 - val_acc: 0.5400

Epoch 00235: val_loss did not improve from 1.09907
Epoch 236/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0465 - acc: 0.5492 - val_loss: 1.0998 - val_acc: 0.5323

Epoch 00236: val_loss did not improve from 1.09907
Epoch 237/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0508 - acc: 0.5344 - val_loss: 1.1040 - val_acc: 0.5472

Epoch 00237: val_loss did not improve from 1.09907
Epoch 238/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0448 - acc: 0.5487 - val_loss: 1.1012 - val_acc: 0.5431

Epoch 00238: val_loss did not improve from 1.09907
Epoch 239/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0438 - acc: 0.5478 - val_loss: 1.1265 - val_acc: 0.5256

Epoch 00239: val_loss did not improve from 1.09907
Epoch 240/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0483 - acc: 0.5395 - val_loss: 1.0996 - val_acc: 0.5385

Epoch 00240: val_loss did not improve from 1.09907
Epoch 241/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0512 - acc: 0.5483 - val_loss: 1.1112 - val_acc: 0.5390

Epoch 00241: val_loss did not improve from 1.09907
Epoch 242/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0496 - acc: 0.5452 - val_loss: 1.1407 - val_acc: 0.5179

Epoch 00242: val_loss did not improve from 1.09907
Epoch 243/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0534 - acc: 0.5470 - val_loss: 1.1016 - val_acc: 0.5369

Epoch 00243: val_loss did not improve from 1.09907
Epoch 244/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0504 - acc: 0.5406 - val_loss: 1.1023 - val_acc: 0.5344

Epoch 00244: val_loss did not improve from 1.09907
Epoch 245/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0481 - acc: 0.5406 - val_loss: 1.1237 - val_acc: 0.5333

Epoch 00245: val_loss did not improve from 1.09907
Epoch 246/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0487 - acc: 0.5404 - val_loss: 1.0957 - val_acc: 0.5390

Epoch 00246: val_loss improved from 1.09907 to 1.09567, saving model to model4/246-1.0957.hdf5
Epoch 247/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0487 - acc: 0.5408 - val_loss: 1.1219 - val_acc: 0.5226

Epoch 00247: val_loss did not improve from 1.09567
Epoch 248/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0534 - acc: 0.5419 - val_loss: 1.1010 - val_acc: 0.5385

Epoch 00248: val_loss did not improve from 1.09567
Epoch 249/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0520 - acc: 0.5368 - val_loss: 1.1052 - val_acc: 0.5338

Epoch 00249: val_loss did not improve from 1.09567
Epoch 250/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0449 - acc: 0.5428 - val_loss: 1.1114 - val_acc: 0.5400

Epoch 00250: val_loss did not improve from 1.09567
Epoch 251/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0517 - acc: 0.5503 - val_loss: 1.1109 - val_acc: 0.5210

Epoch 00251: val_loss did not improve from 1.09567
Epoch 252/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0642 - acc: 0.5300 - val_loss: 1.1008 - val_acc: 0.5410

Epoch 00252: val_loss did not improve from 1.09567
Epoch 253/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0518 - acc: 0.5404 - val_loss: 1.1055 - val_acc: 0.5338

Epoch 00253: val_loss did not improve from 1.09567
Epoch 254/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0422 - acc: 0.5478 - val_loss: 1.1038 - val_acc: 0.5379

Epoch 00254: val_loss did not improve from 1.09567
Epoch 255/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0399 - acc: 0.5531 - val_loss: 1.1054 - val_acc: 0.5251

Epoch 00255: val_loss did not improve from 1.09567
Epoch 256/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0507 - acc: 0.5399 - val_loss: 1.1043 - val_acc: 0.5405

Epoch 00256: val_loss did not improve from 1.09567
Epoch 257/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0425 - acc: 0.5472 - val_loss: 1.1036 - val_acc: 0.5246

Epoch 00257: val_loss did not improve from 1.09567
Epoch 258/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0502 - acc: 0.5390 - val_loss: 1.1162 - val_acc: 0.5338

Epoch 00258: val_loss did not improve from 1.09567
Epoch 259/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0589 - acc: 0.5362 - val_loss: 1.1005 - val_acc: 0.5446

Epoch 00259: val_loss did not improve from 1.09567
Epoch 260/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0553 - acc: 0.5377 - val_loss: 1.1219 - val_acc: 0.5092

Epoch 00260: val_loss did not improve from 1.09567
Epoch 261/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0717 - acc: 0.5305 - val_loss: 1.1077 - val_acc: 0.5241

Epoch 00261: val_loss did not improve from 1.09567
Epoch 262/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0638 - acc: 0.5316 - val_loss: 1.0981 - val_acc: 0.5303

Epoch 00262: val_loss did not improve from 1.09567
Epoch 263/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0476 - acc: 0.5426 - val_loss: 1.1074 - val_acc: 0.5344

Epoch 00263: val_loss did not improve from 1.09567
Epoch 264/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0528 - acc: 0.5285 - val_loss: 1.1301 - val_acc: 0.5262

Epoch 00264: val_loss did not improve from 1.09567
Epoch 265/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0533 - acc: 0.5404 - val_loss: 1.1020 - val_acc: 0.5390

Epoch 00265: val_loss did not improve from 1.09567
Epoch 266/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0428 - acc: 0.5430 - val_loss: 1.0938 - val_acc: 0.5395

Epoch 00266: val_loss improved from 1.09567 to 1.09383, saving model to model4/266-1.0938.hdf5
Epoch 267/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0436 - acc: 0.5461 - val_loss: 1.1001 - val_acc: 0.5364

Epoch 00267: val_loss did not improve from 1.09383
Epoch 268/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0491 - acc: 0.5417 - val_loss: 1.1310 - val_acc: 0.5256

Epoch 00268: val_loss did not improve from 1.09383
Epoch 269/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0474 - acc: 0.5465 - val_loss: 1.0984 - val_acc: 0.5323

Epoch 00269: val_loss did not improve from 1.09383
Epoch 270/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0470 - acc: 0.5404 - val_loss: 1.1004 - val_acc: 0.5374

Epoch 00270: val_loss did not improve from 1.09383
Epoch 271/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0451 - acc: 0.5450 - val_loss: 1.0957 - val_acc: 0.5369

Epoch 00271: val_loss did not improve from 1.09383
Epoch 272/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0395 - acc: 0.5509 - val_loss: 1.1009 - val_acc: 0.5287

Epoch 00272: val_loss did not improve from 1.09383
Epoch 273/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0507 - acc: 0.5467 - val_loss: 1.0938 - val_acc: 0.5390

Epoch 00273: val_loss improved from 1.09383 to 1.09377, saving model to model4/273-1.0938.hdf5
Epoch 274/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0445 - acc: 0.5470 - val_loss: 1.1442 - val_acc: 0.5179

Epoch 00274: val_loss did not improve from 1.09377
Epoch 275/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0556 - acc: 0.5377 - val_loss: 1.0978 - val_acc: 0.5359

Epoch 00275: val_loss did not improve from 1.09377
Epoch 276/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0449 - acc: 0.5434 - val_loss: 1.0960 - val_acc: 0.5318

Epoch 00276: val_loss did not improve from 1.09377
Epoch 277/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0474 - acc: 0.5474 - val_loss: 1.1085 - val_acc: 0.5405

Epoch 00277: val_loss did not improve from 1.09377
Epoch 278/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0529 - acc: 0.5340 - val_loss: 1.1055 - val_acc: 0.5205

Epoch 00278: val_loss did not improve from 1.09377
Epoch 279/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0468 - acc: 0.5412 - val_loss: 1.0941 - val_acc: 0.5467

Epoch 00279: val_loss did not improve from 1.09377
Epoch 280/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0405 - acc: 0.5456 - val_loss: 1.0913 - val_acc: 0.5431

Epoch 00280: val_loss improved from 1.09377 to 1.09129, saving model to model4/280-1.0913.hdf5
Epoch 281/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0375 - acc: 0.5503 - val_loss: 1.1035 - val_acc: 0.5328

Epoch 00281: val_loss did not improve from 1.09129
Epoch 282/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0406 - acc: 0.5470 - val_loss: 1.1040 - val_acc: 0.5200

Epoch 00282: val_loss did not improve from 1.09129
Epoch 283/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0514 - acc: 0.5327 - val_loss: 1.0945 - val_acc: 0.5405

Epoch 00283: val_loss did not improve from 1.09129
Epoch 284/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0475 - acc: 0.5443 - val_loss: 1.1292 - val_acc: 0.5236

Epoch 00284: val_loss did not improve from 1.09129
Epoch 285/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0451 - acc: 0.5423 - val_loss: 1.1031 - val_acc: 0.5338

Epoch 00285: val_loss did not improve from 1.09129
Epoch 286/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0406 - acc: 0.5443 - val_loss: 1.0910 - val_acc: 0.5395

Epoch 00286: val_loss improved from 1.09129 to 1.09101, saving model to model4/286-1.0910.hdf5
Epoch 287/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0463 - acc: 0.5467 - val_loss: 1.0960 - val_acc: 0.5267

Epoch 00287: val_loss did not improve from 1.09101
Epoch 288/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0418 - acc: 0.5428 - val_loss: 1.1037 - val_acc: 0.5395

Epoch 00288: val_loss did not improve from 1.09101
Epoch 289/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0451 - acc: 0.5509 - val_loss: 1.1073 - val_acc: 0.5287

Epoch 00289: val_loss did not improve from 1.09101
Epoch 290/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0419 - acc: 0.5450 - val_loss: 1.0924 - val_acc: 0.5369

Epoch 00290: val_loss did not improve from 1.09101
Epoch 291/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0471 - acc: 0.5373 - val_loss: 1.1067 - val_acc: 0.5349

Epoch 00291: val_loss did not improve from 1.09101
Epoch 292/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0457 - acc: 0.5481 - val_loss: 1.0903 - val_acc: 0.5390

Epoch 00292: val_loss improved from 1.09101 to 1.09025, saving model to model4/292-1.0903.hdf5
Epoch 293/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0382 - acc: 0.5503 - val_loss: 1.0896 - val_acc: 0.5354

Epoch 00293: val_loss improved from 1.09025 to 1.08962, saving model to model4/293-1.0896.hdf5
Epoch 294/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0386 - acc: 0.5542 - val_loss: 1.0988 - val_acc: 0.5390

Epoch 00294: val_loss did not improve from 1.08962
Epoch 295/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0397 - acc: 0.5487 - val_loss: 1.0932 - val_acc: 0.5369

Epoch 00295: val_loss did not improve from 1.08962
Epoch 296/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0416 - acc: 0.5478 - val_loss: 1.0973 - val_acc: 0.5446

Epoch 00296: val_loss did not improve from 1.08962
Epoch 297/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0381 - acc: 0.5489 - val_loss: 1.0908 - val_acc: 0.5297

Epoch 00297: val_loss did not improve from 1.08962
Epoch 298/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0470 - acc: 0.5421 - val_loss: 1.0894 - val_acc: 0.5354

Epoch 00298: val_loss improved from 1.08962 to 1.08941, saving model to model4/298-1.0894.hdf5
Epoch 299/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0372 - acc: 0.5459 - val_loss: 1.1149 - val_acc: 0.5308

Epoch 00299: val_loss did not improve from 1.08941
Epoch 300/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0505 - acc: 0.5456 - val_loss: 1.1403 - val_acc: 0.5149

Epoch 00300: val_loss did not improve from 1.08941
Epoch 301/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0459 - acc: 0.5364 - val_loss: 1.0985 - val_acc: 0.5374

Epoch 00301: val_loss did not improve from 1.08941
Epoch 302/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0426 - acc: 0.5522 - val_loss: 1.0976 - val_acc: 0.5205

Epoch 00302: val_loss did not improve from 1.08941
Epoch 303/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0541 - acc: 0.5382 - val_loss: 1.1003 - val_acc: 0.5185

Epoch 00303: val_loss did not improve from 1.08941
Epoch 304/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0480 - acc: 0.5445 - val_loss: 1.0916 - val_acc: 0.5390

Epoch 00304: val_loss did not improve from 1.08941
Epoch 305/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0380 - acc: 0.5514 - val_loss: 1.1009 - val_acc: 0.5344

Epoch 00305: val_loss did not improve from 1.08941
Epoch 306/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0376 - acc: 0.5571 - val_loss: 1.0949 - val_acc: 0.5415

Epoch 00306: val_loss did not improve from 1.08941
Epoch 307/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0405 - acc: 0.5472 - val_loss: 1.0891 - val_acc: 0.5415

Epoch 00307: val_loss improved from 1.08941 to 1.08914, saving model to model4/307-1.0891.hdf5
Epoch 308/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0418 - acc: 0.5478 - val_loss: 1.1440 - val_acc: 0.5133

Epoch 00308: val_loss did not improve from 1.08914
Epoch 309/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0554 - acc: 0.5448 - val_loss: 1.1008 - val_acc: 0.5359

Epoch 00309: val_loss did not improve from 1.08914
Epoch 310/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0415 - acc: 0.5401 - val_loss: 1.0942 - val_acc: 0.5267

Epoch 00310: val_loss did not improve from 1.08914
Epoch 311/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0352 - acc: 0.5503 - val_loss: 1.0948 - val_acc: 0.5415

Epoch 00311: val_loss did not improve from 1.08914
Epoch 312/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0360 - acc: 0.5498 - val_loss: 1.1072 - val_acc: 0.5364

Epoch 00312: val_loss did not improve from 1.08914
Epoch 313/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0391 - acc: 0.5531 - val_loss: 1.0873 - val_acc: 0.5405

Epoch 00313: val_loss improved from 1.08914 to 1.08729, saving model to model4/313-1.0873.hdf5
Epoch 314/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0369 - acc: 0.5496 - val_loss: 1.0890 - val_acc: 0.5344

Epoch 00314: val_loss did not improve from 1.08729
Epoch 315/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0419 - acc: 0.5470 - val_loss: 1.0932 - val_acc: 0.5364

Epoch 00315: val_loss did not improve from 1.08729
Epoch 316/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0374 - acc: 0.5481 - val_loss: 1.0962 - val_acc: 0.5328

Epoch 00316: val_loss did not improve from 1.08729
Epoch 317/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0357 - acc: 0.5520 - val_loss: 1.0942 - val_acc: 0.5400

Epoch 00317: val_loss did not improve from 1.08729
Epoch 318/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0446 - acc: 0.5439 - val_loss: 1.1108 - val_acc: 0.5354

Epoch 00318: val_loss did not improve from 1.08729
Epoch 319/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0417 - acc: 0.5430 - val_loss: 1.0941 - val_acc: 0.5241

Epoch 00319: val_loss did not improve from 1.08729
Epoch 320/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0451 - acc: 0.5421 - val_loss: 1.1133 - val_acc: 0.5318

Epoch 00320: val_loss did not improve from 1.08729
Epoch 321/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0413 - acc: 0.5487 - val_loss: 1.0898 - val_acc: 0.5395

Epoch 00321: val_loss did not improve from 1.08729
Epoch 322/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0361 - acc: 0.5492 - val_loss: 1.0881 - val_acc: 0.5421

Epoch 00322: val_loss did not improve from 1.08729
Epoch 323/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0340 - acc: 0.5564 - val_loss: 1.0905 - val_acc: 0.5369

Epoch 00323: val_loss did not improve from 1.08729
Epoch 324/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0359 - acc: 0.5518 - val_loss: 1.0896 - val_acc: 0.5421

Epoch 00324: val_loss did not improve from 1.08729
Epoch 325/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0338 - acc: 0.5549 - val_loss: 1.0869 - val_acc: 0.5451

Epoch 00325: val_loss improved from 1.08729 to 1.08691, saving model to model4/325-1.0869.hdf5
Epoch 326/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0356 - acc: 0.5511 - val_loss: 1.0903 - val_acc: 0.5385

Epoch 00326: val_loss did not improve from 1.08691
Epoch 327/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0457 - acc: 0.5430 - val_loss: 1.0874 - val_acc: 0.5436

Epoch 00327: val_loss did not improve from 1.08691
Epoch 328/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0368 - acc: 0.5503 - val_loss: 1.1009 - val_acc: 0.5364

Epoch 00328: val_loss did not improve from 1.08691
Epoch 329/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0402 - acc: 0.5509 - val_loss: 1.0963 - val_acc: 0.5328

Epoch 00329: val_loss did not improve from 1.08691
Epoch 330/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0382 - acc: 0.5470 - val_loss: 1.1114 - val_acc: 0.5359

Epoch 00330: val_loss did not improve from 1.08691
Epoch 331/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0363 - acc: 0.5511 - val_loss: 1.0928 - val_acc: 0.5385

Epoch 00331: val_loss did not improve from 1.08691
Epoch 332/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0381 - acc: 0.5514 - val_loss: 1.1224 - val_acc: 0.5195

Epoch 00332: val_loss did not improve from 1.08691
Epoch 333/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0491 - acc: 0.5487 - val_loss: 1.0903 - val_acc: 0.5344

Epoch 00333: val_loss did not improve from 1.08691
Epoch 334/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0370 - acc: 0.5518 - val_loss: 1.0951 - val_acc: 0.5451

Epoch 00334: val_loss did not improve from 1.08691
Epoch 335/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0357 - acc: 0.5500 - val_loss: 1.0897 - val_acc: 0.5451

Epoch 00335: val_loss did not improve from 1.08691
Epoch 336/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0364 - acc: 0.5505 - val_loss: 1.0927 - val_acc: 0.5395

Epoch 00336: val_loss did not improve from 1.08691
Epoch 337/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0349 - acc: 0.5536 - val_loss: 1.1059 - val_acc: 0.5318

Epoch 00337: val_loss did not improve from 1.08691
Epoch 338/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0473 - acc: 0.5470 - val_loss: 1.0859 - val_acc: 0.5508

Epoch 00338: val_loss improved from 1.08691 to 1.08587, saving model to model4/338-1.0859.hdf5
Epoch 339/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0342 - acc: 0.5505 - val_loss: 1.0890 - val_acc: 0.5354

Epoch 00339: val_loss did not improve from 1.08587
Epoch 340/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0357 - acc: 0.5538 - val_loss: 1.0890 - val_acc: 0.5487

Epoch 00340: val_loss did not improve from 1.08587
Epoch 341/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0322 - acc: 0.5564 - val_loss: 1.0894 - val_acc: 0.5364

Epoch 00341: val_loss did not improve from 1.08587
Epoch 342/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0359 - acc: 0.5525 - val_loss: 1.0984 - val_acc: 0.5328

Epoch 00342: val_loss did not improve from 1.08587
Epoch 343/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0347 - acc: 0.5496 - val_loss: 1.0860 - val_acc: 0.5446

Epoch 00343: val_loss did not improve from 1.08587
Epoch 344/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0335 - acc: 0.5520 - val_loss: 1.0988 - val_acc: 0.5374

Epoch 00344: val_loss did not improve from 1.08587
Epoch 345/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0354 - acc: 0.5507 - val_loss: 1.0973 - val_acc: 0.5262

Epoch 00345: val_loss did not improve from 1.08587
Epoch 346/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0463 - acc: 0.5461 - val_loss: 1.0882 - val_acc: 0.5405

Epoch 00346: val_loss did not improve from 1.08587
Epoch 347/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0375 - acc: 0.5527 - val_loss: 1.0927 - val_acc: 0.5385

Epoch 00347: val_loss did not improve from 1.08587
Epoch 348/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0330 - acc: 0.5538 - val_loss: 1.0931 - val_acc: 0.5436

Epoch 00348: val_loss did not improve from 1.08587
Epoch 349/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0326 - acc: 0.5564 - val_loss: 1.0874 - val_acc: 0.5451

Epoch 00349: val_loss did not improve from 1.08587
Epoch 350/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0379 - acc: 0.5505 - val_loss: 1.1377 - val_acc: 0.5277

Epoch 00350: val_loss did not improve from 1.08587
Epoch 351/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0493 - acc: 0.5371 - val_loss: 1.1001 - val_acc: 0.5154

Epoch 00351: val_loss did not improve from 1.08587
Epoch 352/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0433 - acc: 0.5456 - val_loss: 1.0869 - val_acc: 0.5426

Epoch 00352: val_loss did not improve from 1.08587
Epoch 353/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0473 - acc: 0.5472 - val_loss: 1.1546 - val_acc: 0.5046

Epoch 00353: val_loss did not improve from 1.08587
Epoch 354/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0518 - acc: 0.5443 - val_loss: 1.1162 - val_acc: 0.5318

Epoch 00354: val_loss did not improve from 1.08587
Epoch 355/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0417 - acc: 0.5454 - val_loss: 1.0945 - val_acc: 0.5221

Epoch 00355: val_loss did not improve from 1.08587
Epoch 356/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0439 - acc: 0.5456 - val_loss: 1.0922 - val_acc: 0.5308

Epoch 00356: val_loss did not improve from 1.08587
Epoch 357/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0337 - acc: 0.5511 - val_loss: 1.0862 - val_acc: 0.5400

Epoch 00357: val_loss did not improve from 1.08587
Epoch 358/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0332 - acc: 0.5520 - val_loss: 1.0843 - val_acc: 0.5477

Epoch 00358: val_loss improved from 1.08587 to 1.08433, saving model to model4/358-1.0843.hdf5
Epoch 359/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0345 - acc: 0.5514 - val_loss: 1.0876 - val_acc: 0.5426

Epoch 00359: val_loss did not improve from 1.08433
Epoch 360/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0307 - acc: 0.5533 - val_loss: 1.0837 - val_acc: 0.5379

Epoch 00360: val_loss improved from 1.08433 to 1.08365, saving model to model4/360-1.0837.hdf5
Epoch 361/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0353 - acc: 0.5520 - val_loss: 1.0927 - val_acc: 0.5323

Epoch 00361: val_loss did not improve from 1.08365
Epoch 362/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0329 - acc: 0.5569 - val_loss: 1.0849 - val_acc: 0.5456

Epoch 00362: val_loss did not improve from 1.08365
Epoch 363/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0330 - acc: 0.5547 - val_loss: 1.0862 - val_acc: 0.5431

Epoch 00363: val_loss did not improve from 1.08365
Epoch 364/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0296 - acc: 0.5564 - val_loss: 1.0953 - val_acc: 0.5354

Epoch 00364: val_loss did not improve from 1.08365
Epoch 365/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0290 - acc: 0.5544 - val_loss: 1.0879 - val_acc: 0.5395

Epoch 00365: val_loss did not improve from 1.08365
Epoch 366/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0303 - acc: 0.5538 - val_loss: 1.0825 - val_acc: 0.5462

Epoch 00366: val_loss improved from 1.08365 to 1.08245, saving model to model4/366-1.0825.hdf5
Epoch 367/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0312 - acc: 0.5551 - val_loss: 1.1220 - val_acc: 0.5303

Epoch 00367: val_loss did not improve from 1.08245
Epoch 368/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0385 - acc: 0.5483 - val_loss: 1.0851 - val_acc: 0.5451

Epoch 00368: val_loss did not improve from 1.08245
Epoch 369/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0307 - acc: 0.5555 - val_loss: 1.0931 - val_acc: 0.5436

Epoch 00369: val_loss did not improve from 1.08245
Epoch 370/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0433 - acc: 0.5412 - val_loss: 1.0841 - val_acc: 0.5385

Epoch 00370: val_loss did not improve from 1.08245
Epoch 371/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0354 - acc: 0.5489 - val_loss: 1.0898 - val_acc: 0.5349

Epoch 00371: val_loss did not improve from 1.08245
Epoch 372/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0343 - acc: 0.5492 - val_loss: 1.0914 - val_acc: 0.5395

Epoch 00372: val_loss did not improve from 1.08245
Epoch 373/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0417 - acc: 0.5483 - val_loss: 1.1024 - val_acc: 0.5292

Epoch 00373: val_loss did not improve from 1.08245
Epoch 374/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0403 - acc: 0.5454 - val_loss: 1.0868 - val_acc: 0.5344

Epoch 00374: val_loss did not improve from 1.08245
Epoch 375/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0366 - acc: 0.5518 - val_loss: 1.0927 - val_acc: 0.5400

Epoch 00375: val_loss did not improve from 1.08245
Epoch 376/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0327 - acc: 0.5549 - val_loss: 1.0908 - val_acc: 0.5313

Epoch 00376: val_loss did not improve from 1.08245
Epoch 377/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0367 - acc: 0.5452 - val_loss: 1.1358 - val_acc: 0.5164

Epoch 00377: val_loss did not improve from 1.08245
Epoch 378/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0427 - acc: 0.5437 - val_loss: 1.0897 - val_acc: 0.5390

Epoch 00378: val_loss did not improve from 1.08245
Epoch 379/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0303 - acc: 0.5575 - val_loss: 1.1019 - val_acc: 0.5364

Epoch 00379: val_loss did not improve from 1.08245
Epoch 380/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0374 - acc: 0.5500 - val_loss: 1.0907 - val_acc: 0.5333

Epoch 00380: val_loss did not improve from 1.08245
Epoch 381/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0338 - acc: 0.5505 - val_loss: 1.0936 - val_acc: 0.5405

Epoch 00381: val_loss did not improve from 1.08245
Epoch 382/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0343 - acc: 0.5531 - val_loss: 1.0991 - val_acc: 0.5354

Epoch 00382: val_loss did not improve from 1.08245
Epoch 383/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0316 - acc: 0.5514 - val_loss: 1.0912 - val_acc: 0.5415

Epoch 00383: val_loss did not improve from 1.08245
Epoch 384/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0338 - acc: 0.5562 - val_loss: 1.0873 - val_acc: 0.5354

Epoch 00384: val_loss did not improve from 1.08245
Epoch 385/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0291 - acc: 0.5531 - val_loss: 1.0857 - val_acc: 0.5492

Epoch 00385: val_loss did not improve from 1.08245
Epoch 386/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0396 - acc: 0.5434 - val_loss: 1.1353 - val_acc: 0.5159

Epoch 00386: val_loss did not improve from 1.08245
Epoch 387/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0451 - acc: 0.5410 - val_loss: 1.0852 - val_acc: 0.5426

Epoch 00387: val_loss did not improve from 1.08245
Epoch 388/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0351 - acc: 0.5500 - val_loss: 1.0917 - val_acc: 0.5267

Epoch 00388: val_loss did not improve from 1.08245
Epoch 389/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0422 - acc: 0.5412 - val_loss: 1.0916 - val_acc: 0.5400

Epoch 00389: val_loss did not improve from 1.08245
Epoch 390/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0407 - acc: 0.5452 - val_loss: 1.0935 - val_acc: 0.5400

Epoch 00390: val_loss did not improve from 1.08245
Epoch 391/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0402 - acc: 0.5494 - val_loss: 1.0976 - val_acc: 0.5277

Epoch 00391: val_loss did not improve from 1.08245
Epoch 392/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0479 - acc: 0.5329 - val_loss: 1.1296 - val_acc: 0.5031

Epoch 00392: val_loss did not improve from 1.08245
Epoch 393/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0523 - acc: 0.5335 - val_loss: 1.0897 - val_acc: 0.5323

Epoch 00393: val_loss did not improve from 1.08245
Epoch 394/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0392 - acc: 0.5485 - val_loss: 1.1037 - val_acc: 0.5323

Epoch 00394: val_loss did not improve from 1.08245
Epoch 395/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0379 - acc: 0.5456 - val_loss: 1.0870 - val_acc: 0.5328

Epoch 00395: val_loss did not improve from 1.08245
Epoch 396/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0401 - acc: 0.5472 - val_loss: 1.0836 - val_acc: 0.5441

Epoch 00396: val_loss did not improve from 1.08245
Epoch 397/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0315 - acc: 0.5540 - val_loss: 1.0915 - val_acc: 0.5456

Epoch 00397: val_loss did not improve from 1.08245
Epoch 398/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0375 - acc: 0.5500 - val_loss: 1.0868 - val_acc: 0.5359

Epoch 00398: val_loss did not improve from 1.08245
Epoch 399/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0476 - acc: 0.5459 - val_loss: 1.0802 - val_acc: 0.5421

Epoch 00399: val_loss improved from 1.08245 to 1.08021, saving model to model4/399-1.0802.hdf5
Epoch 400/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0451 - acc: 0.5472 - val_loss: 1.0966 - val_acc: 0.5359

Epoch 00400: val_loss did not improve from 1.08021
Epoch 401/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0334 - acc: 0.5527 - val_loss: 1.1033 - val_acc: 0.5318

Epoch 00401: val_loss did not improve from 1.08021
Epoch 402/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0378 - acc: 0.5518 - val_loss: 1.0860 - val_acc: 0.5410

Epoch 00402: val_loss did not improve from 1.08021
Epoch 403/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0368 - acc: 0.5439 - val_loss: 1.0952 - val_acc: 0.5251

Epoch 00403: val_loss did not improve from 1.08021
Epoch 404/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0411 - acc: 0.5382 - val_loss: 1.0834 - val_acc: 0.5379

Epoch 00404: val_loss did not improve from 1.08021
Epoch 405/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0309 - acc: 0.5505 - val_loss: 1.0896 - val_acc: 0.5349

Epoch 00405: val_loss did not improve from 1.08021
Epoch 406/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0337 - acc: 0.5525 - val_loss: 1.0854 - val_acc: 0.5364

Epoch 00406: val_loss did not improve from 1.08021
Epoch 407/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0410 - acc: 0.5474 - val_loss: 1.0849 - val_acc: 0.5415

Epoch 00407: val_loss did not improve from 1.08021
Epoch 408/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0316 - acc: 0.5525 - val_loss: 1.0928 - val_acc: 0.5410

Epoch 00408: val_loss did not improve from 1.08021
Epoch 409/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0320 - acc: 0.5560 - val_loss: 1.0839 - val_acc: 0.5508

Epoch 00409: val_loss did not improve from 1.08021
Epoch 410/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0288 - acc: 0.5584 - val_loss: 1.0839 - val_acc: 0.5385

Epoch 00410: val_loss did not improve from 1.08021
Epoch 411/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0312 - acc: 0.5511 - val_loss: 1.0841 - val_acc: 0.5395

Epoch 00411: val_loss did not improve from 1.08021
Epoch 412/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0349 - acc: 0.5566 - val_loss: 1.0866 - val_acc: 0.5385

Epoch 00412: val_loss did not improve from 1.08021
Epoch 413/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0296 - acc: 0.5577 - val_loss: 1.1015 - val_acc: 0.5354

Epoch 00413: val_loss did not improve from 1.08021
Epoch 414/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0353 - acc: 0.5500 - val_loss: 1.0786 - val_acc: 0.5421

Epoch 00414: val_loss improved from 1.08021 to 1.07855, saving model to model4/414-1.0786.hdf5
Epoch 415/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0324 - acc: 0.5518 - val_loss: 1.0927 - val_acc: 0.5231

Epoch 00415: val_loss did not improve from 1.07855
Epoch 416/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0373 - acc: 0.5485 - val_loss: 1.0852 - val_acc: 0.5410

Epoch 00416: val_loss did not improve from 1.07855
Epoch 417/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0294 - acc: 0.5562 - val_loss: 1.1026 - val_acc: 0.5328

Epoch 00417: val_loss did not improve from 1.07855
Epoch 418/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0348 - acc: 0.5525 - val_loss: 1.0844 - val_acc: 0.5451

Epoch 00418: val_loss did not improve from 1.07855
Epoch 419/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0291 - acc: 0.5507 - val_loss: 1.0806 - val_acc: 0.5451

Epoch 00419: val_loss did not improve from 1.07855
Epoch 420/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0311 - acc: 0.5558 - val_loss: 1.0950 - val_acc: 0.5385

Epoch 00420: val_loss did not improve from 1.07855
Epoch 421/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0436 - acc: 0.5483 - val_loss: 1.1543 - val_acc: 0.5056

Epoch 00421: val_loss did not improve from 1.07855
Epoch 422/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0483 - acc: 0.5439 - val_loss: 1.0905 - val_acc: 0.5344

Epoch 00422: val_loss did not improve from 1.07855
Epoch 423/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0349 - acc: 0.5465 - val_loss: 1.0838 - val_acc: 0.5415

Epoch 00423: val_loss did not improve from 1.07855
Epoch 424/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0281 - acc: 0.5597 - val_loss: 1.1304 - val_acc: 0.5169

Epoch 00424: val_loss did not improve from 1.07855
Epoch 425/3000
4547/4547 [==============================] - ETA: 0s - loss: 1.0587 - acc: 0.542 - 0s 4us/step - loss: 1.0433 - acc: 0.5456 - val_loss: 1.1065 - val_acc: 0.5318

Epoch 00425: val_loss did not improve from 1.07855
Epoch 426/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0317 - acc: 0.5529 - val_loss: 1.0919 - val_acc: 0.5338

Epoch 00426: val_loss did not improve from 1.07855
Epoch 427/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0287 - acc: 0.5525 - val_loss: 1.1051 - val_acc: 0.5282

Epoch 00427: val_loss did not improve from 1.07855
Epoch 428/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0351 - acc: 0.5487 - val_loss: 1.1049 - val_acc: 0.5323

Epoch 00428: val_loss did not improve from 1.07855
Epoch 429/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0348 - acc: 0.5503 - val_loss: 1.0869 - val_acc: 0.5415

Epoch 00429: val_loss did not improve from 1.07855
Epoch 430/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0356 - acc: 0.5494 - val_loss: 1.0981 - val_acc: 0.5374

Epoch 00430: val_loss did not improve from 1.07855
Epoch 431/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0383 - acc: 0.5483 - val_loss: 1.0865 - val_acc: 0.5446

Epoch 00431: val_loss did not improve from 1.07855
Epoch 432/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0350 - acc: 0.5496 - val_loss: 1.1132 - val_acc: 0.5138

Epoch 00432: val_loss did not improve from 1.07855
Epoch 433/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0390 - acc: 0.5492 - val_loss: 1.0841 - val_acc: 0.5415

Epoch 00433: val_loss did not improve from 1.07855
Epoch 434/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0355 - acc: 0.5516 - val_loss: 1.1351 - val_acc: 0.5195

Epoch 00434: val_loss did not improve from 1.07855
Epoch 435/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0414 - acc: 0.5439 - val_loss: 1.0823 - val_acc: 0.5410

Epoch 00435: val_loss did not improve from 1.07855
Epoch 436/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0277 - acc: 0.5536 - val_loss: 1.0836 - val_acc: 0.5446

Epoch 00436: val_loss did not improve from 1.07855
Epoch 437/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0274 - acc: 0.5538 - val_loss: 1.0836 - val_acc: 0.5477

Epoch 00437: val_loss did not improve from 1.07855
Epoch 438/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0282 - acc: 0.5580 - val_loss: 1.0829 - val_acc: 0.5385

Epoch 00438: val_loss did not improve from 1.07855
Epoch 439/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5573 - val_loss: 1.0876 - val_acc: 0.5421

Epoch 00439: val_loss did not improve from 1.07855
Epoch 440/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0266 - acc: 0.5511 - val_loss: 1.1111 - val_acc: 0.5272

Epoch 00440: val_loss did not improve from 1.07855
Epoch 441/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0350 - acc: 0.5476 - val_loss: 1.0870 - val_acc: 0.5426

Epoch 00441: val_loss did not improve from 1.07855
Epoch 442/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0265 - acc: 0.5571 - val_loss: 1.0819 - val_acc: 0.5421

Epoch 00442: val_loss did not improve from 1.07855
Epoch 443/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0287 - acc: 0.5590 - val_loss: 1.0847 - val_acc: 0.5410

Epoch 00443: val_loss did not improve from 1.07855
Epoch 444/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0293 - acc: 0.5520 - val_loss: 1.1021 - val_acc: 0.5338

Epoch 00444: val_loss did not improve from 1.07855
Epoch 445/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0328 - acc: 0.5511 - val_loss: 1.0849 - val_acc: 0.5436

Epoch 00445: val_loss did not improve from 1.07855
Epoch 446/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0264 - acc: 0.5547 - val_loss: 1.0927 - val_acc: 0.5323

Epoch 00446: val_loss did not improve from 1.07855
Epoch 447/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0335 - acc: 0.5527 - val_loss: 1.1056 - val_acc: 0.5149

Epoch 00447: val_loss did not improve from 1.07855
Epoch 448/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0415 - acc: 0.5441 - val_loss: 1.0871 - val_acc: 0.5415

Epoch 00448: val_loss did not improve from 1.07855
Epoch 449/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0280 - acc: 0.5531 - val_loss: 1.0927 - val_acc: 0.5390

Epoch 00449: val_loss did not improve from 1.07855
Epoch 450/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0312 - acc: 0.5551 - val_loss: 1.0895 - val_acc: 0.5400

Epoch 00450: val_loss did not improve from 1.07855
Epoch 451/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0345 - acc: 0.5505 - val_loss: 1.0920 - val_acc: 0.5267

Epoch 00451: val_loss did not improve from 1.07855
Epoch 452/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0370 - acc: 0.5514 - val_loss: 1.0943 - val_acc: 0.5272

Epoch 00452: val_loss did not improve from 1.07855
Epoch 453/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0340 - acc: 0.5474 - val_loss: 1.0848 - val_acc: 0.5421

Epoch 00453: val_loss did not improve from 1.07855
Epoch 454/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0383 - acc: 0.5503 - val_loss: 1.0977 - val_acc: 0.5333

Epoch 00454: val_loss did not improve from 1.07855
Epoch 455/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0323 - acc: 0.5496 - val_loss: 1.0818 - val_acc: 0.5451

Epoch 00455: val_loss did not improve from 1.07855
Epoch 456/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0264 - acc: 0.5608 - val_loss: 1.0955 - val_acc: 0.5395

Epoch 00456: val_loss did not improve from 1.07855
Epoch 457/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0306 - acc: 0.5533 - val_loss: 1.0967 - val_acc: 0.5369

Epoch 00457: val_loss did not improve from 1.07855
Epoch 458/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0282 - acc: 0.5542 - val_loss: 1.0860 - val_acc: 0.5421

Epoch 00458: val_loss did not improve from 1.07855
Epoch 459/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0288 - acc: 0.5538 - val_loss: 1.0811 - val_acc: 0.5379

Epoch 00459: val_loss did not improve from 1.07855
Epoch 460/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0251 - acc: 0.5538 - val_loss: 1.1276 - val_acc: 0.5297

Epoch 00460: val_loss did not improve from 1.07855
Epoch 461/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0433 - acc: 0.5408 - val_loss: 1.0979 - val_acc: 0.5333

Epoch 00461: val_loss did not improve from 1.07855
Epoch 462/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0406 - acc: 0.5439 - val_loss: 1.0817 - val_acc: 0.5441

Epoch 00462: val_loss did not improve from 1.07855
Epoch 463/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0290 - acc: 0.5595 - val_loss: 1.0819 - val_acc: 0.5415

Epoch 00463: val_loss did not improve from 1.07855
Epoch 464/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0262 - acc: 0.5494 - val_loss: 1.0978 - val_acc: 0.5231

Epoch 00464: val_loss did not improve from 1.07855
Epoch 465/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0374 - acc: 0.5443 - val_loss: 1.0876 - val_acc: 0.5318

Epoch 00465: val_loss did not improve from 1.07855
Epoch 466/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0335 - acc: 0.5470 - val_loss: 1.0804 - val_acc: 0.5374

Epoch 00466: val_loss did not improve from 1.07855
Epoch 467/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0246 - acc: 0.5571 - val_loss: 1.0798 - val_acc: 0.5431

Epoch 00467: val_loss did not improve from 1.07855
Epoch 468/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0298 - acc: 0.5555 - val_loss: 1.0859 - val_acc: 0.5344

Epoch 00468: val_loss did not improve from 1.07855
Epoch 469/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0350 - acc: 0.5481 - val_loss: 1.0828 - val_acc: 0.5405

Epoch 00469: val_loss did not improve from 1.07855
Epoch 470/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0293 - acc: 0.5533 - val_loss: 1.0858 - val_acc: 0.5395

Epoch 00470: val_loss did not improve from 1.07855
Epoch 471/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0248 - acc: 0.5555 - val_loss: 1.0800 - val_acc: 0.5456

Epoch 00471: val_loss did not improve from 1.07855
Epoch 472/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0242 - acc: 0.5597 - val_loss: 1.0819 - val_acc: 0.5390

Epoch 00472: val_loss did not improve from 1.07855
Epoch 473/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0247 - acc: 0.5553 - val_loss: 1.0815 - val_acc: 0.5415

Epoch 00473: val_loss did not improve from 1.07855
Epoch 474/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0262 - acc: 0.5527 - val_loss: 1.0815 - val_acc: 0.5472

Epoch 00474: val_loss did not improve from 1.07855
Epoch 475/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5593 - val_loss: 1.0910 - val_acc: 0.5364

Epoch 00475: val_loss did not improve from 1.07855
Epoch 476/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0284 - acc: 0.5564 - val_loss: 1.0941 - val_acc: 0.5390

Epoch 00476: val_loss did not improve from 1.07855
Epoch 477/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0351 - acc: 0.5481 - val_loss: 1.0873 - val_acc: 0.5338

Epoch 00477: val_loss did not improve from 1.07855
Epoch 478/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0389 - acc: 0.5434 - val_loss: 1.0985 - val_acc: 0.5364

Epoch 00478: val_loss did not improve from 1.07855
Epoch 479/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0361 - acc: 0.5437 - val_loss: 1.0893 - val_acc: 0.5369

Epoch 00479: val_loss did not improve from 1.07855
Epoch 480/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0269 - acc: 0.5547 - val_loss: 1.0801 - val_acc: 0.5472

Epoch 00480: val_loss did not improve from 1.07855
Epoch 481/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0259 - acc: 0.5606 - val_loss: 1.0798 - val_acc: 0.5456

Epoch 00481: val_loss did not improve from 1.07855
Epoch 482/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0233 - acc: 0.5562 - val_loss: 1.0860 - val_acc: 0.5462

Epoch 00482: val_loss did not improve from 1.07855
Epoch 483/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0252 - acc: 0.5549 - val_loss: 1.0840 - val_acc: 0.5436

Epoch 00483: val_loss did not improve from 1.07855
Epoch 484/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0229 - acc: 0.5573 - val_loss: 1.1179 - val_acc: 0.5308

Epoch 00484: val_loss did not improve from 1.07855
Epoch 485/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0365 - acc: 0.5461 - val_loss: 1.1121 - val_acc: 0.5277

Epoch 00485: val_loss did not improve from 1.07855
Epoch 486/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0345 - acc: 0.5503 - val_loss: 1.0866 - val_acc: 0.5405

Epoch 00486: val_loss did not improve from 1.07855
Epoch 487/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0274 - acc: 0.5553 - val_loss: 1.0822 - val_acc: 0.5421

Epoch 00487: val_loss did not improve from 1.07855
Epoch 488/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0267 - acc: 0.5544 - val_loss: 1.0858 - val_acc: 0.5426

Epoch 00488: val_loss did not improve from 1.07855
Epoch 489/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0269 - acc: 0.5531 - val_loss: 1.1062 - val_acc: 0.5395

Epoch 00489: val_loss did not improve from 1.07855
Epoch 490/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0334 - acc: 0.5463 - val_loss: 1.0929 - val_acc: 0.5231

Epoch 00490: val_loss did not improve from 1.07855
Epoch 491/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0410 - acc: 0.5415 - val_loss: 1.0859 - val_acc: 0.5379

Epoch 00491: val_loss did not improve from 1.07855
Epoch 492/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0350 - acc: 0.5496 - val_loss: 1.0802 - val_acc: 0.5415

Epoch 00492: val_loss did not improve from 1.07855
Epoch 493/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0231 - acc: 0.5639 - val_loss: 1.0813 - val_acc: 0.5441

Epoch 00493: val_loss did not improve from 1.07855
Epoch 494/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0266 - acc: 0.5590 - val_loss: 1.0808 - val_acc: 0.5482

Epoch 00494: val_loss did not improve from 1.07855
Epoch 495/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0227 - acc: 0.5595 - val_loss: 1.0836 - val_acc: 0.5379

Epoch 00495: val_loss did not improve from 1.07855
Epoch 496/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0232 - acc: 0.5595 - val_loss: 1.0828 - val_acc: 0.5405

Epoch 00496: val_loss did not improve from 1.07855
Epoch 497/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0293 - acc: 0.5525 - val_loss: 1.0827 - val_acc: 0.5421

Epoch 00497: val_loss did not improve from 1.07855
Epoch 498/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0257 - acc: 0.5580 - val_loss: 1.1018 - val_acc: 0.5328

Epoch 00498: val_loss did not improve from 1.07855
Epoch 499/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0305 - acc: 0.5531 - val_loss: 1.0830 - val_acc: 0.5395

Epoch 00499: val_loss did not improve from 1.07855
Epoch 500/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0251 - acc: 0.5533 - val_loss: 1.0866 - val_acc: 0.5410

Epoch 00500: val_loss did not improve from 1.07855
Epoch 501/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0279 - acc: 0.5569 - val_loss: 1.1015 - val_acc: 0.5374

Epoch 00501: val_loss did not improve from 1.07855
Epoch 502/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0336 - acc: 0.5454 - val_loss: 1.0819 - val_acc: 0.5344

Epoch 00502: val_loss did not improve from 1.07855
Epoch 503/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0314 - acc: 0.5555 - val_loss: 1.0853 - val_acc: 0.5431

Epoch 00503: val_loss did not improve from 1.07855
Epoch 504/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0260 - acc: 0.5553 - val_loss: 1.0838 - val_acc: 0.5395

Epoch 00504: val_loss did not improve from 1.07855
Epoch 505/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0237 - acc: 0.5544 - val_loss: 1.0806 - val_acc: 0.5467

Epoch 00505: val_loss did not improve from 1.07855
Epoch 506/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0232 - acc: 0.5580 - val_loss: 1.0817 - val_acc: 0.5446

Epoch 00506: val_loss did not improve from 1.07855
Epoch 507/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0248 - acc: 0.5566 - val_loss: 1.0803 - val_acc: 0.5446

Epoch 00507: val_loss did not improve from 1.07855
Epoch 508/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0224 - acc: 0.5564 - val_loss: 1.0816 - val_acc: 0.5456

Epoch 00508: val_loss did not improve from 1.07855
Epoch 509/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0228 - acc: 0.5540 - val_loss: 1.0833 - val_acc: 0.5400

Epoch 00509: val_loss did not improve from 1.07855
Epoch 510/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0241 - acc: 0.5549 - val_loss: 1.0937 - val_acc: 0.5236

Epoch 00510: val_loss did not improve from 1.07855
Epoch 511/3000
4547/4547 [==============================] - 0s 3us/step - loss: 1.0349 - acc: 0.5474 - val_loss: 1.0850 - val_acc: 0.5354

Epoch 00511: val_loss did not improve from 1.07855
Epoch 512/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0296 - acc: 0.5489 - val_loss: 1.0883 - val_acc: 0.5405

Epoch 00512: val_loss did not improve from 1.07855
Epoch 513/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0262 - acc: 0.5540 - val_loss: 1.1009 - val_acc: 0.5374

Epoch 00513: val_loss did not improve from 1.07855
Epoch 514/3000
4547/4547 [==============================] - 0s 4us/step - loss: 1.0263 - acc: 0.5507 - val_loss: 1.0851 - val_acc: 0.5287

Epoch 00514: val_loss did not improve from 1.07855
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[20]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># save model</span>
<span class="n">model</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s1">&#39;result/my_model4.h5&#39;</span><span class="p">)</span>
<span class="k">del</span> <span class="n">model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span><span class="s1">&#39;result/my_model4.h5&#39;</span><span class="p">)</span>

<span class="c1"># Accuracy result</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2"> Accuracy: </span><span class="si">%.4f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)[</span><span class="mi">1</span><span class="p">]))</span>

<span class="k">del</span> <span class="n">model</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>6497/6497 [==============================] - 0s 29us/step

 Accuracy: 0.5432
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="plot-(&#44160;&#51613;&#49483;-&#50724;&#52264;,-&#54617;&#49845;&#49483;-&#50724;&#52264;,-&#54617;&#49845;&#49483;&#51032;-&#51221;&#54869;&#46020;)">plot (&#44160;&#51613;&#49483; &#50724;&#52264;, &#54617;&#49845;&#49483; &#50724;&#52264;, &#54617;&#49845;&#49483;&#51032; &#51221;&#54869;&#46020;)<a class="anchor-link" href="#plot-(&#44160;&#51613;&#49483;-&#50724;&#52264;,-&#54617;&#49845;&#49483;-&#50724;&#52264;,-&#54617;&#49845;&#49483;&#51032;-&#51221;&#54869;&#46020;)">&#182;</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[21]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># model 1</span>
<span class="n">y1_vloss</span> <span class="o">=</span> <span class="n">history1</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span> <span class="c1"># 검증셋으로 측정한 오차</span>
<span class="n">y1_loss</span> <span class="o">=</span> <span class="n">history1</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="c1"># 학습셋의 오차</span>
<span class="n">y1_acc</span> <span class="o">=</span> <span class="n">history1</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span> <span class="c1"># 학습셋의 정확도</span>
<span class="n">x1_len</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y1_loss</span><span class="p">))</span>

<span class="c1"># model 2</span>
<span class="n">y2_vloss</span> <span class="o">=</span> <span class="n">history2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span> 
<span class="n">y2_loss</span> <span class="o">=</span> <span class="n">history2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> 
<span class="n">y2_acc</span> <span class="o">=</span> <span class="n">history2</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span> 
<span class="n">x2_len</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y2_loss</span><span class="p">))</span>

<span class="c1"># model 3</span>
<span class="n">y3_vloss</span> <span class="o">=</span> <span class="n">history3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span> 
<span class="n">y3_loss</span> <span class="o">=</span> <span class="n">history3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> 
<span class="n">y3_acc</span> <span class="o">=</span> <span class="n">history3</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span> 
<span class="n">x3_len</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y3_loss</span><span class="p">))</span>

<span class="c1"># model 4</span>
<span class="n">y4_vloss</span> <span class="o">=</span> <span class="n">history4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;val_loss&#39;</span><span class="p">]</span> 
<span class="n">y4_loss</span> <span class="o">=</span> <span class="n">history4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> 
<span class="n">y4_acc</span> <span class="o">=</span> <span class="n">history4</span><span class="o">.</span><span class="n">history</span><span class="p">[</span><span class="s1">&#39;acc&#39;</span><span class="p">]</span> 
<span class="n">x4_len</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y4_loss</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="testset-loss,-trainset-accuracy">testset loss, trainset accuracy<a class="anchor-link" href="#testset-loss,-trainset-accuracy">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[22]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_len</span><span class="p">,</span> <span class="n">y1_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_len</span><span class="p">,</span> <span class="n">y1_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 1)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2_len</span><span class="p">,</span> <span class="n">y2_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2_len</span><span class="p">,</span> <span class="n">y2_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 2)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3_len</span><span class="p">,</span> <span class="n">y3_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3_len</span><span class="p">,</span> <span class="n">y3_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 3)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x4_len</span><span class="p">,</span> <span class="n">y4_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x4_len</span><span class="p">,</span> <span class="n">y4_acc</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_accuracy&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 4)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="testset-loss,-trainset-loss">testset loss, trainset loss<a class="anchor-link" href="#testset-loss,-trainset-loss">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[23]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">221</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_len</span><span class="p">,</span> <span class="n">y1_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_len</span><span class="p">,</span> <span class="n">y1_loss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 1)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">222</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2_len</span><span class="p">,</span> <span class="n">y2_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2_len</span><span class="p">,</span> <span class="n">y2_loss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 2)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">223</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3_len</span><span class="p">,</span> <span class="n">y3_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3_len</span><span class="p">,</span> <span class="n">y3_loss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 3)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">224</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x4_len</span><span class="p">,</span> <span class="n">y4_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x4_len</span><span class="p">,</span> <span class="n">y4_loss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Trainset_loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (model 4)&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h4 id="Compare-testset-loss-from-4-models">Compare testset loss from 4 models<a class="anchor-link" href="#Compare-testset-loss-from-4-models">&#182;</a></h4>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[29]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x1_len</span><span class="p">,</span> <span class="n">y1_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss (model1)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x2_len</span><span class="p">,</span> <span class="n">y2_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss (model2)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x3_len</span><span class="p">,</span> <span class="n">y3_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss (model3)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x4_len</span><span class="p">,</span> <span class="n">y4_vloss</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;.&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;yellow&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Testset_loss (model4)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;epoch&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;testset loss&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Wine data (testset loss)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
    </div>
  </div>
</body>

 


</html>
